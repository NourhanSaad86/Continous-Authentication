{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\HP\\\\Desktop\\\\continous-authentication1\\\\continous-authentication1\\\\continous-authentication\\\\continous-authentication\\\\src\\\\ContinuousAuth.js\",\n  _s = $RefreshSig$();\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\n// import * as faceapi from \"face-api.js\";\n// import Webcam from \"react-webcam\";\n// import axios from \"axios\";\n// import \"./ContinuousAuth.css\";\n\n// const ContinuousAuth = () => {\n//   const webcamRef = useRef(null);\n//   const [faceDetected, setFaceDetected] = useState(false);\n//   const [soundDetected, setSoundDetected] = useState(false);\n//   const [currentImage, setCurrentImage] = useState(null);\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\n//   const [examTerminated, setExamTerminated] = useState(false);\n//   const [mediaStream, setMediaStream] = useState(null);\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\n\n//   useEffect(() => {\n//     const loadModels = async () => {\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\n//       console.log(\"Face Detection Model Loaded\");\n//     };\n//     loadModels();\n//   }, []);\n\n//   const getPermissions = async () => {\n//     try {\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\n//       setMediaStream(stream);\n//       setPermissionsGranted(true);\n//       setShowPermissionMessage(false);\n//       fetchIpAddress(); // Call to fetch IP address when permissions are granted\n//     } catch (error) {\n//       alert(\"Please allow access to camera and microphone.\");\n//       setShowPermissionMessage(true);\n//     }\n//   };\n\n//   const fetchIpAddress = async () => {\n//     try {\n//       const response = await fetch(\"https://api.ipify.org?format=json\");\n//       const data = await response.json();\n//       alert(`Your IP Address: ${data.ip}`);\n//     } catch (error) {\n//       console.error(\"Error fetching IP address:\", error);\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (mediaStream) {\n//       const tracks = mediaStream.getTracks();\n//       tracks.forEach((track) => {\n//         track.enabled = true;\n//       });\n//     }\n//   }, [mediaStream]);\n\n//   const detectFace = async () => {\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\n//       const video = webcamRef.current.video;\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n//       const isFacePresent = detections.length > 0;\n//       setFaceDetected(isFacePresent);\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       const interval = setInterval(detectFace, 1000);\n//       return () => clearInterval(interval);\n//     }\n//   }, [permissionsGranted]);\n\n//   useEffect(() => {\n//     if (noFaceDuration >= 15) {\n//       alert(\"‚ö†Ô∏è Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\n//       setNoFaceDuration(0);\n//     }\n//   }, [noFaceDuration]);\n\n//   const detectSound = useCallback(() => {\n//     if (!mediaStream) return;\n\n//     const audioContext = new AudioContext();\n//     const analyser = audioContext.createAnalyser();\n//     const source = audioContext.createMediaStreamSource(mediaStream);\n//     source.connect(analyser);\n//     analyser.fftSize = 256;\n//     const bufferLength = analyser.frequencyBinCount;\n//     const dataArray = new Uint8Array(bufferLength);\n\n//     const checkSound = () => {\n//       analyser.getByteFrequencyData(dataArray);\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\n//       setSoundDetected(volume > 10);\n//       requestAnimationFrame(checkSound);\n//     };\n//     checkSound();\n//   }, [mediaStream]);\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       detectSound();\n//     }\n//   }, [permissionsGranted, detectSound]);\n\n//   return (\n//     <div className=\"continuous-auth-container\">\n//       <h2>Continuous Authentication</h2>\n\n//       {showPermissionMessage && (\n//         <div className=\"permission-message\">\n//           <p>Please allow access to your camera and microphone to start the exam.</p>\n//           <button onClick={getPermissions}>Allow Camera and Microphone</button>\n//         </div>\n//       )}\n\n//       {permissionsGranted ? (\n//         <>\n//           <Webcam\n//             audio={true}\n//             ref={webcamRef}\n//             screenshotFormat=\"image/jpeg\"\n//             className=\"webcam\"\n//             videoConstraints={{\n//               facingMode: \"user\",\n//               width: 720,\n//               height: 400,\n//             }}\n//           />\n//           <p>Camera and microphone are active for proctoring.</p>\n\n//           <div className=\"status-buttons-container\">\n//             <div className=\"status-buttons\">\n//               <button className={faceDetected ? \"detected-btn\" : \"not-detected-btn\"}>\n//                 {faceDetected ? \"Face Detected ‚úÖ\" : \"No Face Detected ‚ùå\"}\n//               </button>\n//               <button className={soundDetected ? \"detected-btn\" : \"not-detected-btn\"}>\n//                 {soundDetected ? \"Sound Detected üîä\" : \"No Sound Detected üîá\"}\n//               </button>\n//             </div>\n\n//             <div className=\"captured-images\">\n//               {currentImage && <img src={currentImage} alt=\"Captured\" className=\"small-image\" />}\n//             </div>\n//           </div>\n//         </>\n//       ) : (\n//         <p>Waiting for camera and microphone access...</p>\n//       )}\n\n//       {examTerminated && <p className=\"mismatch-count\">Exam Terminated due to 3 mismatches.</p>}\n//     </div>\n//   );\n// };\n\n// export default ContinuousAuth;\n\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\n// import * as faceapi from \"face-api.js\";\n// import Webcam from \"react-webcam\";\n// import \"./ContinuousAuth.css\";\n\n// const ContinuousAuth = () => {\n//   const webcamRef = useRef(null);\n//   const [faceDetected, setFaceDetected] = useState(false);\n//   const [soundDetected, setSoundDetected] = useState(false);\n//   const [currentImage, setCurrentImage] = useState(null);\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\n//   const [examTerminated, setExamTerminated] = useState(false);\n//   const [mediaStream, setMediaStream] = useState(null);\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\n//   const [transcript, setTranscript] = useState(\"\");\n//   const [violations, setViolations] = useState(0);\n//   const recognitionRef = useRef(null);\n\n//   // ŸÜÿ∏ÿßŸÖ ŸÉÿ¥ŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\n//   const [multipleVoicesDetected, setMultipleVoicesDetected] = useState(false);\n//   const audioContextRef = useRef(null);\n//   const analyserRef = useRef(null);\n//   const voiceProfileRef = useRef({\n//     baseline: null,\n//     lastAlert: 0,\n//     active: false\n//   });\n\n//   useEffect(() => {\n//     const loadModels = async () => {\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\n//       console.log(\"Face Detection Model Loaded\");\n//     };\n//     loadModels();\n//   }, []);\n\n//   const getPermissions = async () => {\n//     try {\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\n//       setMediaStream(stream);\n//       setPermissionsGranted(true);\n//       setShowPermissionMessage(false);\n//       initializeSpeechRecognition();\n//       setupVoiceAnalysis(stream);\n//     } catch (error) {\n//       alert(\"Please allow access to camera and microphone.\");\n//       setShowPermissionMessage(true);\n//     }\n//   };\n\n//   // ŸÜÿ∏ÿßŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\n//   const setupVoiceAnalysis = (stream) => {\n//     try {\n//       audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n//       analyserRef.current = audioContextRef.current.createAnalyser();\n//       analyserRef.current.fftSize = 4096;\n\n//       const source = audioContextRef.current.createMediaStreamSource(stream);\n//       source.connect(analyserRef.current);\n\n//       // ÿ•ŸÜÿ¥ÿßÿ° ÿ®ÿµŸÖÿ© ÿµŸàÿ™Ÿäÿ© ÿ£ŸàŸÑŸäÿ© ÿ®ÿπÿØ 3 ÿ´ŸàÿßŸÜŸä\n//       setTimeout(() => {\n//         voiceProfileRef.current.baseline = createVoiceProfile();\n//         voiceProfileRef.current.active = true;\n//       }, 3000);\n\n//       const analyzeVoice = () => {\n//         if (!voiceProfileRef.current.active) {\n//           requestAnimationFrame(analyzeVoice);\n//           return;\n//         }\n\n//         const currentProfile = createVoiceProfile();\n//         const isMultiple = compareVoiceProfiles(voiceProfileRef.current.baseline, currentProfile);\n\n//         if (isMultiple && Date.now() - voiceProfileRef.current.lastAlert > 5000) {\n//           setMultipleVoicesDetected(true);\n//           voiceProfileRef.current.lastAlert = Date.now();\n//         } else {\n//           setMultipleVoicesDetected(false);\n//         }\n\n//         requestAnimationFrame(analyzeVoice);\n//       };\n\n//       analyzeVoice();\n//     } catch (error) {\n//       console.error(\"Voice analysis error:\", error);\n//     }\n//   };\n\n//   const createVoiceProfile = () => {\n//     const bufferLength = analyserRef.current.frequencyBinCount;\n//     const dataArray = new Float32Array(bufferLength);\n//     analyserRef.current.getFloatFrequencyData(dataArray);\n\n//     const profile = {\n//       lowRange: 0,    // 85-300Hz\n//       midRange: 0,    // 300-1000Hz\n//       highRange: 0,   // 1000-4000Hz\n//       peakCount: 0,\n//       totalEnergy: 0\n//     };\n\n//     for (let i = 0; i < bufferLength; i++) {\n//       const freq = i * audioContextRef.current.sampleRate / analyserRef.current.fftSize;\n//       const value = Math.pow(10, dataArray[i]/20); // Convert dB to linear\n\n//       if (freq >= 85 && freq < 300) {\n//         profile.lowRange += value;\n//       } else if (freq >= 300 && freq < 1000) {\n//         profile.midRange += value;\n//       } else if (freq >= 1000 && freq < 4000) {\n//         profile.highRange += value;\n//       }\n\n//       if (dataArray[i] > -40) profile.peakCount++;\n//       profile.totalEnergy += value;\n//     }\n\n//     return profile;\n//   };\n\n//   const compareVoiceProfiles = (baseline, current) => {\n//     // ÿ≠ÿ≥ÿßÿ® ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ™ÿ∫Ÿäÿ± ŸÑŸÉŸÑ ŸÜÿ∑ÿßŸÇ ÿ™ÿ±ÿØÿØŸä\n//     const lowDiff = Math.abs(current.lowRange - baseline.lowRange) / baseline.lowRange;\n//     const midDiff = Math.abs(current.midRange - baseline.midRange) / baseline.midRange;\n//     const highDiff = Math.abs(current.highRange - baseline.highRange) / baseline.highRange;\n//     const energyDiff = Math.abs(current.totalEnergy - baseline.totalEnergy) / baseline.totalEnergy;\n//     const peakDiff = Math.abs(current.peakCount - baseline.peakCount);\n\n//     // ÿ¥ÿ±Ÿàÿ∑ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ©\n//     return (\n//       (lowDiff > 0.6 || midDiff > 0.6 || highDiff > 0.6) &&\n//       energyDiff > 0.4 &&\n//       peakDiff > 15\n//     );\n//   };\n\n//   const initializeSpeechRecognition = () => {\n//     const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n//     if (!SpeechRecognition) {\n//       console.error(\"Speech Recognition API not supported in this browser\");\n//       return;\n//     }\n\n//     recognitionRef.current = new SpeechRecognition();\n//     recognitionRef.current.continuous = true;\n//     recognitionRef.current.interimResults = false;\n//     recognitionRef.current.lang = \"ar-SA\";\n\n//     recognitionRef.current.onresult = (event) => {\n//       const last = event.results.length - 1;\n//       const text = event.results[last][0].transcript;\n//       setTranscript(text);\n//     };\n\n//     recognitionRef.current.onerror = (event) => {\n//       console.error(\"Speech recognition error\", event.error);\n//     };\n\n//     recognitionRef.current.start();\n//     recognitionRef.current.onend = () => {\n//       recognitionRef.current.start();\n//     };\n//   };\n\n//   useEffect(() => {\n//     if (mediaStream) {\n//       const tracks = mediaStream.getTracks();\n//       tracks.forEach((track) => {\n//         track.enabled = true;\n//       });\n//     }\n\n//     return () => {\n//       if (recognitionRef.current) {\n//         recognitionRef.current.stop();\n//       }\n//       if (audioContextRef.current) {\n//         audioContextRef.current.close();\n//       }\n//     };\n//   }, [mediaStream]);\n\n//   const detectFace = async () => {\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\n//       const video = webcamRef.current.video;\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n//       const isFacePresent = detections.length > 0;\n//       setFaceDetected(isFacePresent);\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       const interval = setInterval(detectFace, 1000);\n//       return () => clearInterval(interval);\n//     }\n//   }, [permissionsGranted]);\n\n//   useEffect(() => {\n//     if (noFaceDuration >= 15) {\n//       alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\n//       setNoFaceDuration(0);\n//     }\n//   }, [noFaceDuration]);\n\n//   const detectSound = useCallback(() => {\n//     if (!mediaStream) return;\n\n//     const audioContext = new AudioContext();\n//     const analyser = audioContext.createAnalyser();\n//     const source = audioContext.createMediaStreamSource(mediaStream);\n//     source.connect(analyser);\n//     analyser.fftSize = 256;\n//     const bufferLength = analyser.frequencyBinCount;\n//     const dataArray = new Uint8Array(bufferLength);\n\n//     const checkSound = () => {\n//       analyser.getByteFrequencyData(dataArray);\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\n//       setSoundDetected(volume > 10);\n//       requestAnimationFrame(checkSound);\n//     };\n//     checkSound();\n//   }, [mediaStream]);\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       detectSound();\n//     }\n//   }, [permissionsGranted, detectSound]);\n\n//   useEffect(() => {\n//     if (multipleVoicesDetected) {\n//       const newViolations = violations + 1;\n//       setViolations(newViolations);\n\n//       alert(`üö® MULTIPLE VOICES DETECTED! (Violation ${newViolations}/3)`);\n\n//       if (newViolations >= 3) {\n//         setExamTerminated(true);\n//       }\n//     }\n//   }, [multipleVoicesDetected]);\n\n//   return (\n//     <div className=\"continuous-auth-container\">\n//       <h2>Exam Proctoring System</h2>\n\n//       {showPermissionMessage && (\n//         <div className=\"permission-message\">\n//           <h3>Exam Proctoring Setup</h3>\n//           <p>This exam requires camera and microphone access for proctoring purposes.</p>\n//           <div className=\"permission-requirements\">\n//             <p>‚úì Face detection must be enabled</p>\n//             <p>‚úì Microphone must be active</p>\n//           </div>\n//           <button className=\"permission-button\" onClick={getPermissions}>\n//             Enable Camera & Microphone\n//           </button>\n//         </div>\n//       )}\n\n//       {permissionsGranted && !examTerminated && (\n//         <div className=\"monitoring-container\">\n//           <div className=\"video-section\">\n//             <Webcam\n//               audio={true}\n//               ref={webcamRef}\n//               screenshotFormat=\"image/jpeg\"\n//               className=\"webcam\"\n//               videoConstraints={{\n//                 facingMode: \"user\",\n//                 width: 480,\n//                 height: 360,\n//               }}\n//             />\n//             <div className=\"status-indicators\">\n//               <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\n//                 {faceDetected ? \"Face Detected\" : \"No Face Detected\"}\n//               </div>\n//               <div className={`status-indicator ${soundDetected ? \"active\" : \"\"}`}>\n//                 {soundDetected ? \"Sound Detected\" : \"No Sound Detected\"}\n//               </div>\n//               {multipleVoicesDetected && (\n//                 <div className=\"status-indicator warning\">\n//                   Multiple Voices Detected!\n//                 </div>\n//               )}\n//             </div>\n//           </div>\n\n//           <div className=\"transcript-section\">\n//             <div className=\"transcript-box\">\n//               <div className=\"transcript-header\">\n//                 <span>Arabic Speech Transcript</span>\n//                 <span className=\"violation-counter\">Violations: {violations}/3</span>\n//               </div>\n//               <div className=\"transcript-content\" dir=\"rtl\">\n//                 {transcript || \"Waiting for audio input...\"}\n//               </div>\n//               <div className={`voice-detection-status ${multipleVoicesDetected ? \"multiple\" : \"\"}`}>\n//                 {multipleVoicesDetected \n//                   ? \"Multiple voices detected!\" \n//                   : \"Voice analysis active\"}\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//       )}\n\n//       {examTerminated && (\n//         <div className=\"termination-message\">\n//           <h3>‚úñ Exam Terminated</h3>\n//           <p>Due to multiple violations detected. Please contact your instructor.</p>\n//           <p>Total violations: {violations}</p>\n//         </div>\n//       )}\n//     </div>\n//   );\n// };\n\n// export default ContinuousAuth;\n\n//////////////////////////////////////////////////////////////////////////////////// \n\nimport React, { useState, useEffect, useRef, useCallback } from \"react\";\nimport * as faceapi from \"face-api.js\";\nimport Webcam from \"react-webcam\";\nimport \"./ContinuousAuth.css\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst ContinuousAuth = () => {\n  _s();\n  const webcamRef = useRef(null);\n  const [faceDetected, setFaceDetected] = useState(false);\n  const [currentImage, setCurrentImage] = useState(null);\n  const [permissionsGranted, setPermissionsGranted] = useState(false);\n  const [examTerminated, setExamTerminated] = useState(false);\n  const [mediaStream, setMediaStream] = useState(null);\n  const [showPermissionMessage, setShowPermissionMessage] = useState(true);\n  const [noFaceDuration, setNoFaceDuration] = useState(0);\n  const [transcript, setTranscript] = useState(\"\");\n  const [violations, setViolations] = useState(0);\n  const recognitionRef = useRef(null);\n\n  // Enhanced Audio Monitoring State\n  const [audioAnalysis, setAudioAnalysis] = useState({\n    volumeLevel: 0,\n    voiceConsistency: 100,\n    backgroundNoiseLevel: 0,\n    audioAnomalies: 0,\n    speakingRate: 0,\n    pitchVariation: 0,\n    lastVoicePrint: null,\n    audioContextReady: false\n  });\n  const audioContextRef = useRef(null);\n  const analyserRef = useRef(null);\n  const voicePrintIntervalRef = useRef(null);\n  const audioCheckIntervalRef = useRef(null);\n  useEffect(() => {\n    const loadModels = async () => {\n      await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\n      console.log(\"Face Detection Model Loaded\");\n    };\n    loadModels();\n  }, []);\n  const getPermissions = async () => {\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({\n        video: true,\n        audio: {\n          echoCancellation: false,\n          noiseSuppression: false,\n          autoGainControl: false\n        }\n      });\n      setMediaStream(stream);\n      setPermissionsGranted(true);\n      setShowPermissionMessage(false);\n      initializeAudioAnalysis(stream);\n      initializeSpeechRecognition();\n    } catch (error) {\n      alert(\"Please allow access to camera and microphone.\");\n      setShowPermissionMessage(true);\n    }\n  };\n\n  // Advanced Audio Analysis Initialization\n  const initializeAudioAnalysis = stream => {\n    try {\n      // Create audio context\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({\n        latencyHint: \"interactive\",\n        sampleRate: 44100\n      });\n\n      // Create analyser node with higher precision\n      analyserRef.current = audioContextRef.current.createAnalyser();\n      analyserRef.current.fftSize = 8192;\n      analyserRef.current.smoothingTimeConstant = 0.8;\n\n      // Create media stream source\n      const source = audioContextRef.current.createMediaStreamSource(stream);\n      source.connect(analyserRef.current);\n\n      // Initialize voice print collection\n      startVoicePrintCollection();\n\n      // Start continuous audio monitoring\n      startAudioMonitoring();\n      setAudioAnalysis(prev => ({\n        ...prev,\n        audioContextReady: true\n      }));\n    } catch (error) {\n      console.error(\"Audio analysis initialization error:\", error);\n    }\n  };\n\n  // Voice Print Collection\n  const startVoicePrintCollection = () => {\n    const collectVoicePrint = () => {\n      if (!analyserRef.current) return;\n      const bufferLength = analyserRef.current.frequencyBinCount;\n      const frequencyData = new Float32Array(bufferLength);\n      const timeDomainData = new Float32Array(bufferLength);\n      analyserRef.current.getFloatFrequencyData(frequencyData);\n      analyserRef.current.getFloatTimeDomainData(timeDomainData);\n\n      // Calculate voice characteristics\n      const voicePrint = {\n        timestamp: Date.now(),\n        spectralCentroid: calculateSpectralCentroid(frequencyData),\n        spectralFlatness: calculateSpectralFlatness(frequencyData),\n        energy: calculateEnergy(timeDomainData),\n        zeroCrossingRate: calculateZeroCrossingRate(timeDomainData),\n        pitch: estimatePitch(timeDomainData),\n        formants: estimateFormants(frequencyData)\n      };\n      setAudioAnalysis(prev => ({\n        ...prev,\n        lastVoicePrint: voicePrint\n      }));\n    };\n    voicePrintIntervalRef.current = setInterval(collectVoicePrint, 2000);\n  };\n\n  // Continuous Audio Monitoring\n  const startAudioMonitoring = () => {\n    const monitorAudio = () => {\n      if (!analyserRef.current) return;\n      const bufferLength = analyserRef.current.frequencyBinCount;\n      const frequencyData = new Float32Array(bufferLength);\n      const timeDomainData = new Float32Array(bufferLength);\n      analyserRef.current.getFloatFrequencyData(frequencyData);\n      analyserRef.current.getFloatTimeDomainData(timeDomainData);\n\n      // Calculate current audio metrics\n      const currentVolume = calculateVolumeLevel(timeDomainData);\n      const currentNoise = calculateBackgroundNoise(frequencyData);\n      const currentAnomalies = detectAudioAnomalies(frequencyData);\n      const speakingRate = estimateSpeakingRate(timeDomainData);\n      const pitchVar = estimatePitchVariation(timeDomainData);\n\n      // Calculate voice consistency if we have a previous voice print\n      let consistency = 100;\n      if (audioAnalysis.lastVoicePrint) {\n        consistency = calculateVoiceConsistency(audioAnalysis.lastVoicePrint, {\n          spectralCentroid: calculateSpectralCentroid(frequencyData),\n          spectralFlatness: calculateSpectralFlatness(frequencyData),\n          energy: calculateEnergy(timeDomainData)\n        });\n      }\n      setAudioAnalysis(prev => ({\n        ...prev,\n        volumeLevel: currentVolume,\n        backgroundNoiseLevel: currentNoise,\n        audioAnomalies: prev.audioAnomalies + currentAnomalies,\n        voiceConsistency: consistency,\n        speakingRate: speakingRate,\n        pitchVariation: pitchVar\n      }));\n\n      // Check for potential violations\n      checkForAudioViolations(currentVolume, currentNoise, consistency, speakingRate, pitchVar);\n    };\n    audioCheckIntervalRef.current = setInterval(monitorAudio, 500);\n  };\n\n  // Audio Analysis Helper Functions\n  const calculateVolumeLevel = timeDomainData => {\n    let sum = 0;\n    for (let i = 0; i < timeDomainData.length; i++) {\n      sum += Math.abs(timeDomainData[i]);\n    }\n    return sum / timeDomainData.length;\n  };\n  const calculateBackgroundNoise = frequencyData => {\n    let sum = 0;\n    let count = 0;\n    for (let i = 0; i < frequencyData.length; i++) {\n      const freq = i * audioContextRef.current.sampleRate / analyserRef.current.fftSize;\n      if (freq > 5000) {\n        sum += Math.pow(10, frequencyData[i] / 20); // Convert dB to linear\n        count++;\n      }\n    }\n    return count > 0 ? sum / count : 0;\n  };\n  const detectAudioAnomalies = frequencyData => {\n    let anomalies = 0;\n    const bands = [{\n      low: 85,\n      high: 255\n    },\n    // Low male voice\n    {\n      low: 255,\n      high: 400\n    },\n    // Female voice fundamentals\n    {\n      low: 400,\n      high: 1000\n    },\n    // Voice harmonics\n    {\n      low: 1000,\n      high: 4000\n    } // Consonants and sibilance\n    ];\n    bands.forEach(band => {\n      const bandEnergy = calculateBandEnergy(frequencyData, band.low, band.high);\n      const threshold = audioAnalysis.lastVoicePrint ? audioAnalysis.lastVoicePrint.energy * 1.8 : 0.1;\n      if (bandEnergy > threshold) {\n        anomalies++;\n      }\n    });\n    return anomalies;\n  };\n  const calculateVoiceConsistency = (baseline, current) => {\n    const centroidDiff = Math.abs(current.spectralCentroid - baseline.spectralCentroid) / baseline.spectralCentroid;\n    const flatnessDiff = Math.abs(current.spectralFlatness - baseline.spectralFlatness);\n    const energyDiff = Math.abs(current.energy - baseline.energy) / baseline.energy;\n    const score = 100 - (Math.min(centroidDiff, 0.5) * 40 + Math.min(flatnessDiff, 0.3) * 30 + Math.min(energyDiff, 1.0) * 30);\n    return Math.max(0, Math.min(100, score));\n  };\n  const checkForAudioViolations = (volume, noise, consistency, speakingRate, pitchVar) => {\n    const multipleSpeakersDetected = consistency < 60 ||\n    // Voice characteristics changed significantly\n    noise > 0.15 && volume > 0.2 ||\n    // High noise with high volume\n    speakingRate > 10 ||\n    // Unusually fast speech\n    pitchVar > 100; // Extreme pitch variations\n\n    if (multipleSpeakersDetected) {\n      setViolations(prev => {\n        const newViolations = prev + 1;\n        if (newViolations >= 3) {\n          setExamTerminated(true);\n          clearInterval(voicePrintIntervalRef.current);\n          clearInterval(audioCheckIntervalRef.current);\n        } else if (newViolations % 1 === 0) {\n          alert(`Audio Anomaly Detected! (Violation ${newViolations}/3)\\nPlease ensure you're alone in a quiet environment.`);\n        }\n        return newViolations;\n      });\n    }\n  };\n  const initializeSpeechRecognition = () => {\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!SpeechRecognition) {\n      console.error(\"Speech Recognition API not supported in this browser\");\n      return;\n    }\n    recognitionRef.current = new SpeechRecognition();\n    recognitionRef.current.continuous = true;\n    recognitionRef.current.interimResults = true;\n    recognitionRef.current.lang = \"ar-SA\";\n    recognitionRef.current.maxAlternatives = 3;\n    recognitionRef.current.onresult = event => {\n      let finalTranscript = \"\";\n      let interimTranscript = \"\";\n      for (let i = event.resultIndex; i < event.results.length; i++) {\n        const transcript = event.results[i][0].transcript;\n        if (event.results[i].isFinal) {\n          finalTranscript += transcript + \" \";\n        } else {\n          interimTranscript += transcript;\n        }\n      }\n      setTranscript(finalTranscript || interimTranscript);\n\n      // Additional check for multiple speakers in transcript\n      if (finalTranscript.includes(\" Ÿà \") || finalTranscript.includes(\" ÿ´ŸÖ \")) {\n        setViolations(prev => prev + 0.5); // Partial violation for conjunction words\n      }\n    };\n    recognitionRef.current.onerror = event => {\n      console.error(\"Speech recognition error\", event.error);\n    };\n    recognitionRef.current.start();\n    recognitionRef.current.onend = () => {\n      recognitionRef.current.start();\n    };\n  };\n  const detectFace = async () => {\n    if (webcamRef.current && webcamRef.current.video.readyState === 4) {\n      const video = webcamRef.current.video;\n      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n      const isFacePresent = detections.length > 0;\n      setFaceDetected(isFacePresent);\n      setNoFaceDuration(prev => isFacePresent ? 0 : prev + 1);\n    }\n  };\n  useEffect(() => {\n    return () => {\n      if (recognitionRef.current) {\n        recognitionRef.current.stop();\n      }\n      if (voicePrintIntervalRef.current) {\n        clearInterval(voicePrintIntervalRef.current);\n      }\n      if (audioCheckIntervalRef.current) {\n        clearInterval(audioCheckIntervalRef.current);\n      }\n      if (audioContextRef.current) {\n        audioContextRef.current.close();\n      }\n    };\n  }, []);\n  useEffect(() => {\n    if (permissionsGranted) {\n      const interval = setInterval(detectFace, 1000);\n      return () => clearInterval(interval);\n    }\n  }, [permissionsGranted]);\n  useEffect(() => {\n    if (noFaceDuration >= 15) {\n      alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\n      setNoFaceDuration(0);\n    }\n  }, [noFaceDuration]);\n\n  // Helper functions\n  const calculateSpectralCentroid = frequencyData => {\n    let sum = 0;\n    let totalMagnitude = 0;\n    for (let i = 0; i < frequencyData.length; i++) {\n      const magnitude = Math.pow(10, frequencyData[i] / 20);\n      sum += i * magnitude;\n      totalMagnitude += magnitude;\n    }\n    return totalMagnitude > 0 ? sum / totalMagnitude : 0;\n  };\n  const calculateSpectralFlatness = frequencyData => {\n    let product = 1;\n    let sum = 0;\n    const count = frequencyData.length;\n    for (let i = 0; i < count; i++) {\n      const value = Math.pow(10, frequencyData[i] / 20);\n      product *= value;\n      sum += value;\n    }\n    return sum > 0 ? product / Math.pow(sum / count, count) : 0;\n  };\n  const calculateEnergy = timeDomainData => {\n    let sum = 0;\n    for (let i = 0; i < timeDomainData.length; i++) {\n      sum += Math.pow(timeDomainData[i], 2);\n    }\n    return Math.sqrt(sum / timeDomainData.length);\n  };\n  const calculateZeroCrossingRate = timeDomainData => {\n    let crossings = 0;\n    for (let i = 1; i < timeDomainData.length; i++) {\n      if (timeDomainData[i] * timeDomainData[i - 1] < 0) {\n        crossings++;\n      }\n    }\n    return crossings / timeDomainData.length;\n  };\n  const estimatePitch = timeDomainData => {\n    const maxLag = Math.floor(audioContextRef.current.sampleRate / 60); // Minimum pitch (60Hz)\n    const minLag = Math.floor(audioContextRef.current.sampleRate / 400); // Maximum pitch (400Hz)\n    let bestLag = 0;\n    let bestCorrelation = -1;\n    for (let lag = minLag; lag <= maxLag; lag++) {\n      let correlation = 0;\n      for (let i = 0; i < timeDomainData.length - lag; i++) {\n        correlation += timeDomainData[i] * timeDomainData[i + lag];\n      }\n      if (correlation > bestCorrelation) {\n        bestCorrelation = correlation;\n        bestLag = lag;\n      }\n    }\n    return bestLag > 0 ? audioContextRef.current.sampleRate / bestLag : 0;\n  };\n  const estimateFormants = frequencyData => {\n    const formants = [];\n    const binSize = audioContextRef.current.sampleRate / frequencyData.length;\n    for (let i = 1; i < frequencyData.length - 1; i++) {\n      const prev = frequencyData[i - 1];\n      const curr = frequencyData[i];\n      const next = frequencyData[i + 1];\n      if (curr > prev && curr > next && curr > -50) {\n        formants.push(i * binSize);\n        if (formants.length >= 3) break; // Only need first few formants\n      }\n    }\n    return formants;\n  };\n  const calculateBandEnergy = (frequencyData, lowFreq, highFreq) => {\n    const binSize = audioContextRef.current.sampleRate / frequencyData.length;\n    const startBin = Math.floor(lowFreq / binSize);\n    const endBin = Math.ceil(highFreq / binSize);\n    let energy = 0;\n    for (let i = startBin; i <= endBin; i++) {\n      energy += Math.pow(10, frequencyData[i] / 20);\n    }\n    return energy / (endBin - startBin + 1);\n  };\n  const estimateSpeakingRate = timeDomainData => {\n    let speechFrames = 0;\n    const threshold = 0.05;\n    for (let i = 0; i < timeDomainData.length; i++) {\n      if (Math.abs(timeDomainData[i]) > threshold) {\n        speechFrames++;\n      }\n    }\n    return speechFrames / timeDomainData.length * 100;\n  };\n  const estimatePitchVariation = timeDomainData => {\n    const segmentLength = Math.floor(audioContextRef.current.sampleRate / 100); // 10ms segments\n    const pitches = [];\n    for (let i = 0; i < timeDomainData.length - segmentLength; i += segmentLength) {\n      const segment = timeDomainData.slice(i, i + segmentLength);\n      const pitch = estimatePitch(segment);\n      if (pitch > 0) pitches.push(pitch);\n    }\n    if (pitches.length < 2) return 0;\n    let variation = 0;\n    for (let i = 1; i < pitches.length; i++) {\n      variation += Math.abs(pitches[i] - pitches[i - 1]);\n    }\n    return variation / (pitches.length - 1);\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"continuous-auth-container\",\n    children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n      children: \"Advanced Exam Proctoring System\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 972,\n      columnNumber: 7\n    }, this), showPermissionMessage && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"permission-message\",\n      children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n        children: \"Exam Proctoring Setup\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 975,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"This exam requires camera and microphone access for proctoring purposes.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 976,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"permission-requirements\",\n        children: [/*#__PURE__*/_jsxDEV(\"p\", {\n          children: \"\\u2713 Face detection must be enabled\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 978,\n          columnNumber: 13\n        }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n          children: \"\\u2713 Microphone must be active (raw audio preferred)\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 979,\n          columnNumber: 13\n        }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n          children: \"\\u2713 Quiet environment recommended\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 980,\n          columnNumber: 13\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 977,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n        className: \"permission-button\",\n        onClick: getPermissions,\n        children: \"Enable Camera & Microphone\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 982,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 974,\n      columnNumber: 9\n    }, this), permissionsGranted && !examTerminated && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"monitoring-container\",\n      children: [/*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"video-section\",\n        children: [/*#__PURE__*/_jsxDEV(Webcam, {\n          audio: true,\n          ref: webcamRef,\n          screenshotFormat: \"image/jpeg\",\n          className: \"webcam\",\n          videoConstraints: {\n            facingMode: \"user\",\n            width: 480,\n            height: 360\n          }\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 990,\n          columnNumber: 13\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"status-indicators\",\n          children: [/*#__PURE__*/_jsxDEV(\"div\", {\n            className: `status-indicator ${faceDetected ? \"active\" : \"\"}`,\n            children: faceDetected ? \"Face Detected\" : \"No Face Detected\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 1002,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: `status-indicator ${audioAnalysis.volumeLevel > 0.1 ? \"active\" : \"\"}`,\n            children: audioAnalysis.volumeLevel > 0.1 ? \"Audio Active\" : \"Audio Silent\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 1005,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"status-indicator\",\n            children: [\"Voice Consistency: \", Math.round(audioAnalysis.voiceConsistency), \"%\"]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 1008,\n            columnNumber: 15\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 1001,\n          columnNumber: 13\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 989,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"audio-analysis-section\",\n        children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n          children: \"Advanced Audio Monitoring\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 1014,\n          columnNumber: 13\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"audio-metrics\",\n          children: [/*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"metric\",\n            children: [/*#__PURE__*/_jsxDEV(\"span\", {\n              className: \"metric-label\",\n              children: \"Volume Level:\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 1017,\n              columnNumber: 17\n            }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n              className: \"metric-bar-container\",\n              children: /*#__PURE__*/_jsxDEV(\"div\", {\n                className: \"metric-bar\",\n                style: {\n                  width: `${Math.min(100, audioAnalysis.volumeLevel * 500)}%`\n                }\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 1019,\n                columnNumber: 19\n              }, this)\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 1018,\n              columnNumber: 17\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 1016,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"metric\",\n            children: [/*#__PURE__*/_jsxDEV(\"span\", {\n              className: \"metric-label\",\n              children: \"Background Noise:\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 1026,\n              columnNumber: 17\n            }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n              className: \"metric-bar-container\",\n              children: /*#__PURE__*/_jsxDEV(\"div\", {\n                className: \"metric-bar noise\",\n                style: {\n                  width: `${Math.min(100, audioAnalysis.backgroundNoiseLevel * 500)}%`\n                }\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 1028,\n                columnNumber: 19\n              }, this)\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 1027,\n              columnNumber: 17\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 1025,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"metric\",\n            children: [/*#__PURE__*/_jsxDEV(\"span\", {\n              className: \"metric-label\",\n              children: \"Voice Consistency:\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 1035,\n              columnNumber: 17\n            }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n              className: \"metric-bar-container\",\n              children: /*#__PURE__*/_jsxDEV(\"div\", {\n                className: \"metric-bar consistency\",\n                style: {\n                  width: `${audioAnalysis.voiceConsistency}%`\n                }\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 1037,\n                columnNumber: 19\n              }, this)\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 1036,\n              columnNumber: 17\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 1034,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"metric\",\n            children: [/*#__PURE__*/_jsxDEV(\"span\", {\n              className: \"metric-label\",\n              children: \"Audio Anomalies:\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 1044,\n              columnNumber: 17\n            }, this), /*#__PURE__*/_jsxDEV(\"span\", {\n              className: \"metric-value\",\n              children: audioAnalysis.audioAnomalies\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 1045,\n              columnNumber: 17\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 1043,\n            columnNumber: 15\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 1015,\n          columnNumber: 13\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 1013,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"transcript-section\",\n        children: /*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"transcript-box\",\n          children: [/*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"transcript-header\",\n            children: [/*#__PURE__*/_jsxDEV(\"span\", {\n              children: \"Arabic Speech Transcript\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 1052,\n              columnNumber: 17\n            }, this), /*#__PURE__*/_jsxDEV(\"span\", {\n              className: \"violation-counter\",\n              children: [\"Violations: \", Math.floor(violations), \"/3\"]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 1053,\n              columnNumber: 17\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 1051,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"transcript-content\",\n            dir: \"rtl\",\n            children: transcript || \"Waiting for audio input...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 1055,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"audio-warnings\",\n            children: [audioAnalysis.voiceConsistency < 70 && /*#__PURE__*/_jsxDEV(\"div\", {\n              className: \"warning-message\",\n              children: \"\\u26A0 Voice inconsistency detected. Please ensure you're the only speaker.\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 1060,\n              columnNumber: 19\n            }, this), audioAnalysis.backgroundNoiseLevel > 0.2 && /*#__PURE__*/_jsxDEV(\"div\", {\n              className: \"warning-message\",\n              children: \"\\u26A0 High background noise detected. Find a quieter environment.\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 1065,\n              columnNumber: 19\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 1058,\n            columnNumber: 15\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 1050,\n          columnNumber: 13\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 1049,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 988,\n      columnNumber: 9\n    }, this), examTerminated && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"termination-message\",\n      children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n        children: \"\\u2716 Exam Terminated\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 1076,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"Due to multiple audio violations detected. Please contact your instructor.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 1077,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"violation-details\",\n        children: [/*#__PURE__*/_jsxDEV(\"p\", {\n          children: [\"Total violations: \", violations]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 1079,\n          columnNumber: 13\n        }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n          children: [\"Final voice consistency: \", Math.round(audioAnalysis.voiceConsistency), \"%\"]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 1080,\n          columnNumber: 13\n        }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n          children: [\"Audio anomalies detected: \", audioAnalysis.audioAnomalies]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 1081,\n          columnNumber: 13\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 1078,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 1075,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 971,\n    columnNumber: 5\n  }, this);\n};\n_s(ContinuousAuth, \"piwYle3XS9UEK7M9aQ7f7Lo9YQ4=\");\n_c = ContinuousAuth;\nexport default ContinuousAuth;\nvar _c;\n$RefreshReg$(_c, \"ContinuousAuth\");","map":{"version":3,"names":["React","useState","useEffect","useRef","useCallback","faceapi","Webcam","jsxDEV","_jsxDEV","ContinuousAuth","_s","webcamRef","faceDetected","setFaceDetected","currentImage","setCurrentImage","permissionsGranted","setPermissionsGranted","examTerminated","setExamTerminated","mediaStream","setMediaStream","showPermissionMessage","setShowPermissionMessage","noFaceDuration","setNoFaceDuration","transcript","setTranscript","violations","setViolations","recognitionRef","audioAnalysis","setAudioAnalysis","volumeLevel","voiceConsistency","backgroundNoiseLevel","audioAnomalies","speakingRate","pitchVariation","lastVoicePrint","audioContextReady","audioContextRef","analyserRef","voicePrintIntervalRef","audioCheckIntervalRef","loadModels","nets","tinyFaceDetector","loadFromUri","console","log","getPermissions","stream","navigator","mediaDevices","getUserMedia","video","audio","echoCancellation","noiseSuppression","autoGainControl","initializeAudioAnalysis","initializeSpeechRecognition","error","alert","current","window","AudioContext","webkitAudioContext","latencyHint","sampleRate","createAnalyser","fftSize","smoothingTimeConstant","source","createMediaStreamSource","connect","startVoicePrintCollection","startAudioMonitoring","prev","collectVoicePrint","bufferLength","frequencyBinCount","frequencyData","Float32Array","timeDomainData","getFloatFrequencyData","getFloatTimeDomainData","voicePrint","timestamp","Date","now","spectralCentroid","calculateSpectralCentroid","spectralFlatness","calculateSpectralFlatness","energy","calculateEnergy","zeroCrossingRate","calculateZeroCrossingRate","pitch","estimatePitch","formants","estimateFormants","setInterval","monitorAudio","currentVolume","calculateVolumeLevel","currentNoise","calculateBackgroundNoise","currentAnomalies","detectAudioAnomalies","estimateSpeakingRate","pitchVar","estimatePitchVariation","consistency","calculateVoiceConsistency","checkForAudioViolations","sum","i","length","Math","abs","count","freq","pow","anomalies","bands","low","high","forEach","band","bandEnergy","calculateBandEnergy","threshold","baseline","centroidDiff","flatnessDiff","energyDiff","score","min","max","volume","noise","multipleSpeakersDetected","newViolations","clearInterval","SpeechRecognition","webkitSpeechRecognition","continuous","interimResults","lang","maxAlternatives","onresult","event","finalTranscript","interimTranscript","resultIndex","results","isFinal","includes","onerror","start","onend","detectFace","readyState","detections","detectAllFaces","TinyFaceDetectorOptions","isFacePresent","stop","close","interval","totalMagnitude","magnitude","product","value","sqrt","crossings","maxLag","floor","minLag","bestLag","bestCorrelation","lag","correlation","binSize","curr","next","push","lowFreq","highFreq","startBin","endBin","ceil","speechFrames","segmentLength","pitches","segment","slice","variation","className","children","fileName","_jsxFileName","lineNumber","columnNumber","onClick","ref","screenshotFormat","videoConstraints","facingMode","width","height","round","style","dir","_c","$RefreshReg$"],"sources":["C:/Users/HP/Desktop/continous-authentication1/continous-authentication1/continous-authentication/continous-authentication/src/ContinuousAuth.js"],"sourcesContent":["// import React, { useState, useEffect, useRef, useCallback } from \"react\";\r\n// import * as faceapi from \"face-api.js\";\r\n// import Webcam from \"react-webcam\";\r\n// import axios from \"axios\";\r\n// import \"./ContinuousAuth.css\";\r\n\r\n// const ContinuousAuth = () => {\r\n//   const webcamRef = useRef(null);\r\n//   const [faceDetected, setFaceDetected] = useState(false);\r\n//   const [soundDetected, setSoundDetected] = useState(false);\r\n//   const [currentImage, setCurrentImage] = useState(null);\r\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\r\n//   const [examTerminated, setExamTerminated] = useState(false);\r\n//   const [mediaStream, setMediaStream] = useState(null);\r\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\r\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\r\n\r\n//   useEffect(() => {\r\n//     const loadModels = async () => {\r\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\r\n//       console.log(\"Face Detection Model Loaded\");\r\n//     };\r\n//     loadModels();\r\n//   }, []);\r\n\r\n//   const getPermissions = async () => {\r\n//     try {\r\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\r\n//       setMediaStream(stream);\r\n//       setPermissionsGranted(true);\r\n//       setShowPermissionMessage(false);\r\n//       fetchIpAddress(); // Call to fetch IP address when permissions are granted\r\n//     } catch (error) {\r\n//       alert(\"Please allow access to camera and microphone.\");\r\n//       setShowPermissionMessage(true);\r\n//     }\r\n//   };\r\n\r\n//   const fetchIpAddress = async () => {\r\n//     try {\r\n//       const response = await fetch(\"https://api.ipify.org?format=json\");\r\n//       const data = await response.json();\r\n//       alert(`Your IP Address: ${data.ip}`);\r\n//     } catch (error) {\r\n//       console.error(\"Error fetching IP address:\", error);\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (mediaStream) {\r\n//       const tracks = mediaStream.getTracks();\r\n//       tracks.forEach((track) => {\r\n//         track.enabled = true;\r\n//       });\r\n//     }\r\n//   }, [mediaStream]);\r\n\r\n//   const detectFace = async () => {\r\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\r\n//       const video = webcamRef.current.video;\r\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\r\n//       const isFacePresent = detections.length > 0;\r\n//       setFaceDetected(isFacePresent);\r\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       const interval = setInterval(detectFace, 1000);\r\n//       return () => clearInterval(interval);\r\n//     }\r\n//   }, [permissionsGranted]);\r\n\r\n//   useEffect(() => {\r\n//     if (noFaceDuration >= 15) {\r\n//       alert(\"‚ö†Ô∏è Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\r\n//       setNoFaceDuration(0);\r\n//     }\r\n//   }, [noFaceDuration]);\r\n\r\n//   const detectSound = useCallback(() => {\r\n//     if (!mediaStream) return;\r\n\r\n//     const audioContext = new AudioContext();\r\n//     const analyser = audioContext.createAnalyser();\r\n//     const source = audioContext.createMediaStreamSource(mediaStream);\r\n//     source.connect(analyser);\r\n//     analyser.fftSize = 256;\r\n//     const bufferLength = analyser.frequencyBinCount;\r\n//     const dataArray = new Uint8Array(bufferLength);\r\n\r\n//     const checkSound = () => {\r\n//       analyser.getByteFrequencyData(dataArray);\r\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\r\n//       setSoundDetected(volume > 10);\r\n//       requestAnimationFrame(checkSound);\r\n//     };\r\n//     checkSound();\r\n//   }, [mediaStream]);\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       detectSound();\r\n//     }\r\n//   }, [permissionsGranted, detectSound]);\r\n\r\n//   return (\r\n//     <div className=\"continuous-auth-container\">\r\n//       <h2>Continuous Authentication</h2>\r\n\r\n//       {showPermissionMessage && (\r\n//         <div className=\"permission-message\">\r\n//           <p>Please allow access to your camera and microphone to start the exam.</p>\r\n//           <button onClick={getPermissions}>Allow Camera and Microphone</button>\r\n//         </div>\r\n//       )}\r\n\r\n//       {permissionsGranted ? (\r\n//         <>\r\n//           <Webcam\r\n//             audio={true}\r\n//             ref={webcamRef}\r\n//             screenshotFormat=\"image/jpeg\"\r\n//             className=\"webcam\"\r\n//             videoConstraints={{\r\n//               facingMode: \"user\",\r\n//               width: 720,\r\n//               height: 400,\r\n//             }}\r\n//           />\r\n//           <p>Camera and microphone are active for proctoring.</p>\r\n\r\n//           <div className=\"status-buttons-container\">\r\n//             <div className=\"status-buttons\">\r\n//               <button className={faceDetected ? \"detected-btn\" : \"not-detected-btn\"}>\r\n//                 {faceDetected ? \"Face Detected ‚úÖ\" : \"No Face Detected ‚ùå\"}\r\n//               </button>\r\n//               <button className={soundDetected ? \"detected-btn\" : \"not-detected-btn\"}>\r\n//                 {soundDetected ? \"Sound Detected üîä\" : \"No Sound Detected üîá\"}\r\n//               </button>\r\n//             </div>\r\n\r\n//             <div className=\"captured-images\">\r\n//               {currentImage && <img src={currentImage} alt=\"Captured\" className=\"small-image\" />}\r\n//             </div>\r\n//           </div>\r\n//         </>\r\n//       ) : (\r\n//         <p>Waiting for camera and microphone access...</p>\r\n//       )}\r\n\r\n//       {examTerminated && <p className=\"mismatch-count\">Exam Terminated due to 3 mismatches.</p>}\r\n//     </div>\r\n//   );\r\n// };\r\n\r\n// export default ContinuousAuth;\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\r\n// import * as faceapi from \"face-api.js\";\r\n// import Webcam from \"react-webcam\";\r\n// import \"./ContinuousAuth.css\";\r\n\r\n// const ContinuousAuth = () => {\r\n//   const webcamRef = useRef(null);\r\n//   const [faceDetected, setFaceDetected] = useState(false);\r\n//   const [soundDetected, setSoundDetected] = useState(false);\r\n//   const [currentImage, setCurrentImage] = useState(null);\r\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\r\n//   const [examTerminated, setExamTerminated] = useState(false);\r\n//   const [mediaStream, setMediaStream] = useState(null);\r\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\r\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\r\n//   const [transcript, setTranscript] = useState(\"\");\r\n//   const [violations, setViolations] = useState(0);\r\n//   const recognitionRef = useRef(null);\r\n\r\n//   // ŸÜÿ∏ÿßŸÖ ŸÉÿ¥ŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\r\n//   const [multipleVoicesDetected, setMultipleVoicesDetected] = useState(false);\r\n//   const audioContextRef = useRef(null);\r\n//   const analyserRef = useRef(null);\r\n//   const voiceProfileRef = useRef({\r\n//     baseline: null,\r\n//     lastAlert: 0,\r\n//     active: false\r\n//   });\r\n\r\n//   useEffect(() => {\r\n//     const loadModels = async () => {\r\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\r\n//       console.log(\"Face Detection Model Loaded\");\r\n//     };\r\n//     loadModels();\r\n//   }, []);\r\n\r\n//   const getPermissions = async () => {\r\n//     try {\r\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\r\n//       setMediaStream(stream);\r\n//       setPermissionsGranted(true);\r\n//       setShowPermissionMessage(false);\r\n//       initializeSpeechRecognition();\r\n//       setupVoiceAnalysis(stream);\r\n//     } catch (error) {\r\n//       alert(\"Please allow access to camera and microphone.\");\r\n//       setShowPermissionMessage(true);\r\n//     }\r\n//   };\r\n\r\n//   // ŸÜÿ∏ÿßŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\r\n//   const setupVoiceAnalysis = (stream) => {\r\n//     try {\r\n//       audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\r\n//       analyserRef.current = audioContextRef.current.createAnalyser();\r\n//       analyserRef.current.fftSize = 4096;\r\n      \r\n//       const source = audioContextRef.current.createMediaStreamSource(stream);\r\n//       source.connect(analyserRef.current);\r\n\r\n//       // ÿ•ŸÜÿ¥ÿßÿ° ÿ®ÿµŸÖÿ© ÿµŸàÿ™Ÿäÿ© ÿ£ŸàŸÑŸäÿ© ÿ®ÿπÿØ 3 ÿ´ŸàÿßŸÜŸä\r\n//       setTimeout(() => {\r\n//         voiceProfileRef.current.baseline = createVoiceProfile();\r\n//         voiceProfileRef.current.active = true;\r\n//       }, 3000);\r\n\r\n//       const analyzeVoice = () => {\r\n//         if (!voiceProfileRef.current.active) {\r\n//           requestAnimationFrame(analyzeVoice);\r\n//           return;\r\n//         }\r\n\r\n//         const currentProfile = createVoiceProfile();\r\n//         const isMultiple = compareVoiceProfiles(voiceProfileRef.current.baseline, currentProfile);\r\n        \r\n//         if (isMultiple && Date.now() - voiceProfileRef.current.lastAlert > 5000) {\r\n//           setMultipleVoicesDetected(true);\r\n//           voiceProfileRef.current.lastAlert = Date.now();\r\n//         } else {\r\n//           setMultipleVoicesDetected(false);\r\n//         }\r\n\r\n//         requestAnimationFrame(analyzeVoice);\r\n//       };\r\n\r\n//       analyzeVoice();\r\n//     } catch (error) {\r\n//       console.error(\"Voice analysis error:\", error);\r\n//     }\r\n//   };\r\n\r\n//   const createVoiceProfile = () => {\r\n//     const bufferLength = analyserRef.current.frequencyBinCount;\r\n//     const dataArray = new Float32Array(bufferLength);\r\n//     analyserRef.current.getFloatFrequencyData(dataArray);\r\n\r\n//     const profile = {\r\n//       lowRange: 0,    // 85-300Hz\r\n//       midRange: 0,    // 300-1000Hz\r\n//       highRange: 0,   // 1000-4000Hz\r\n//       peakCount: 0,\r\n//       totalEnergy: 0\r\n//     };\r\n\r\n//     for (let i = 0; i < bufferLength; i++) {\r\n//       const freq = i * audioContextRef.current.sampleRate / analyserRef.current.fftSize;\r\n//       const value = Math.pow(10, dataArray[i]/20); // Convert dB to linear\r\n\r\n//       if (freq >= 85 && freq < 300) {\r\n//         profile.lowRange += value;\r\n//       } else if (freq >= 300 && freq < 1000) {\r\n//         profile.midRange += value;\r\n//       } else if (freq >= 1000 && freq < 4000) {\r\n//         profile.highRange += value;\r\n//       }\r\n\r\n//       if (dataArray[i] > -40) profile.peakCount++;\r\n//       profile.totalEnergy += value;\r\n//     }\r\n\r\n//     return profile;\r\n//   };\r\n\r\n//   const compareVoiceProfiles = (baseline, current) => {\r\n//     // ÿ≠ÿ≥ÿßÿ® ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ™ÿ∫Ÿäÿ± ŸÑŸÉŸÑ ŸÜÿ∑ÿßŸÇ ÿ™ÿ±ÿØÿØŸä\r\n//     const lowDiff = Math.abs(current.lowRange - baseline.lowRange) / baseline.lowRange;\r\n//     const midDiff = Math.abs(current.midRange - baseline.midRange) / baseline.midRange;\r\n//     const highDiff = Math.abs(current.highRange - baseline.highRange) / baseline.highRange;\r\n//     const energyDiff = Math.abs(current.totalEnergy - baseline.totalEnergy) / baseline.totalEnergy;\r\n//     const peakDiff = Math.abs(current.peakCount - baseline.peakCount);\r\n\r\n//     // ÿ¥ÿ±Ÿàÿ∑ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ©\r\n//     return (\r\n//       (lowDiff > 0.6 || midDiff > 0.6 || highDiff > 0.6) &&\r\n//       energyDiff > 0.4 &&\r\n//       peakDiff > 15\r\n//     );\r\n//   };\r\n\r\n//   const initializeSpeechRecognition = () => {\r\n//     const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n//     if (!SpeechRecognition) {\r\n//       console.error(\"Speech Recognition API not supported in this browser\");\r\n//       return;\r\n//     }\r\n\r\n//     recognitionRef.current = new SpeechRecognition();\r\n//     recognitionRef.current.continuous = true;\r\n//     recognitionRef.current.interimResults = false;\r\n//     recognitionRef.current.lang = \"ar-SA\";\r\n\r\n//     recognitionRef.current.onresult = (event) => {\r\n//       const last = event.results.length - 1;\r\n//       const text = event.results[last][0].transcript;\r\n//       setTranscript(text);\r\n//     };\r\n\r\n//     recognitionRef.current.onerror = (event) => {\r\n//       console.error(\"Speech recognition error\", event.error);\r\n//     };\r\n\r\n//     recognitionRef.current.start();\r\n//     recognitionRef.current.onend = () => {\r\n//       recognitionRef.current.start();\r\n//     };\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (mediaStream) {\r\n//       const tracks = mediaStream.getTracks();\r\n//       tracks.forEach((track) => {\r\n//         track.enabled = true;\r\n//       });\r\n//     }\r\n\r\n//     return () => {\r\n//       if (recognitionRef.current) {\r\n//         recognitionRef.current.stop();\r\n//       }\r\n//       if (audioContextRef.current) {\r\n//         audioContextRef.current.close();\r\n//       }\r\n//     };\r\n//   }, [mediaStream]);\r\n\r\n//   const detectFace = async () => {\r\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\r\n//       const video = webcamRef.current.video;\r\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\r\n//       const isFacePresent = detections.length > 0;\r\n//       setFaceDetected(isFacePresent);\r\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       const interval = setInterval(detectFace, 1000);\r\n//       return () => clearInterval(interval);\r\n//     }\r\n//   }, [permissionsGranted]);\r\n\r\n//   useEffect(() => {\r\n//     if (noFaceDuration >= 15) {\r\n//       alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\r\n//       setNoFaceDuration(0);\r\n//     }\r\n//   }, [noFaceDuration]);\r\n\r\n//   const detectSound = useCallback(() => {\r\n//     if (!mediaStream) return;\r\n\r\n//     const audioContext = new AudioContext();\r\n//     const analyser = audioContext.createAnalyser();\r\n//     const source = audioContext.createMediaStreamSource(mediaStream);\r\n//     source.connect(analyser);\r\n//     analyser.fftSize = 256;\r\n//     const bufferLength = analyser.frequencyBinCount;\r\n//     const dataArray = new Uint8Array(bufferLength);\r\n\r\n//     const checkSound = () => {\r\n//       analyser.getByteFrequencyData(dataArray);\r\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\r\n//       setSoundDetected(volume > 10);\r\n//       requestAnimationFrame(checkSound);\r\n//     };\r\n//     checkSound();\r\n//   }, [mediaStream]);\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       detectSound();\r\n//     }\r\n//   }, [permissionsGranted, detectSound]);\r\n\r\n//   useEffect(() => {\r\n//     if (multipleVoicesDetected) {\r\n//       const newViolations = violations + 1;\r\n//       setViolations(newViolations);\r\n      \r\n//       alert(`üö® MULTIPLE VOICES DETECTED! (Violation ${newViolations}/3)`);\r\n      \r\n//       if (newViolations >= 3) {\r\n//         setExamTerminated(true);\r\n//       }\r\n//     }\r\n//   }, [multipleVoicesDetected]);\r\n\r\n//   return (\r\n//     <div className=\"continuous-auth-container\">\r\n//       <h2>Exam Proctoring System</h2>\r\n\r\n//       {showPermissionMessage && (\r\n//         <div className=\"permission-message\">\r\n//           <h3>Exam Proctoring Setup</h3>\r\n//           <p>This exam requires camera and microphone access for proctoring purposes.</p>\r\n//           <div className=\"permission-requirements\">\r\n//             <p>‚úì Face detection must be enabled</p>\r\n//             <p>‚úì Microphone must be active</p>\r\n//           </div>\r\n//           <button className=\"permission-button\" onClick={getPermissions}>\r\n//             Enable Camera & Microphone\r\n//           </button>\r\n//         </div>\r\n//       )}\r\n\r\n//       {permissionsGranted && !examTerminated && (\r\n//         <div className=\"monitoring-container\">\r\n//           <div className=\"video-section\">\r\n//             <Webcam\r\n//               audio={true}\r\n//               ref={webcamRef}\r\n//               screenshotFormat=\"image/jpeg\"\r\n//               className=\"webcam\"\r\n//               videoConstraints={{\r\n//                 facingMode: \"user\",\r\n//                 width: 480,\r\n//                 height: 360,\r\n//               }}\r\n//             />\r\n//             <div className=\"status-indicators\">\r\n//               <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\r\n//                 {faceDetected ? \"Face Detected\" : \"No Face Detected\"}\r\n//               </div>\r\n//               <div className={`status-indicator ${soundDetected ? \"active\" : \"\"}`}>\r\n//                 {soundDetected ? \"Sound Detected\" : \"No Sound Detected\"}\r\n//               </div>\r\n//               {multipleVoicesDetected && (\r\n//                 <div className=\"status-indicator warning\">\r\n//                   Multiple Voices Detected!\r\n//                 </div>\r\n//               )}\r\n//             </div>\r\n//           </div>\r\n\r\n//           <div className=\"transcript-section\">\r\n//             <div className=\"transcript-box\">\r\n//               <div className=\"transcript-header\">\r\n//                 <span>Arabic Speech Transcript</span>\r\n//                 <span className=\"violation-counter\">Violations: {violations}/3</span>\r\n//               </div>\r\n//               <div className=\"transcript-content\" dir=\"rtl\">\r\n//                 {transcript || \"Waiting for audio input...\"}\r\n//               </div>\r\n//               <div className={`voice-detection-status ${multipleVoicesDetected ? \"multiple\" : \"\"}`}>\r\n//                 {multipleVoicesDetected \r\n//                   ? \"Multiple voices detected!\" \r\n//                   : \"Voice analysis active\"}\r\n//               </div>\r\n//             </div>\r\n//           </div>\r\n//         </div>\r\n//       )}\r\n\r\n//       {examTerminated && (\r\n//         <div className=\"termination-message\">\r\n//           <h3>‚úñ Exam Terminated</h3>\r\n//           <p>Due to multiple violations detected. Please contact your instructor.</p>\r\n//           <p>Total violations: {violations}</p>\r\n//         </div>\r\n//       )}\r\n//     </div>\r\n//   );\r\n// };\r\n\r\n// export default ContinuousAuth;\r\n\r\n\r\n\r\n\r\n//////////////////////////////////////////////////////////////////////////////////// \r\n\r\n\r\n\r\nimport React, { useState, useEffect, useRef, useCallback } from \"react\";\r\nimport * as faceapi from \"face-api.js\";\r\nimport Webcam from \"react-webcam\";\r\nimport \"./ContinuousAuth.css\";\r\n\r\nconst ContinuousAuth = () => {\r\n  const webcamRef = useRef(null);\r\n  const [faceDetected, setFaceDetected] = useState(false);\r\n  const [currentImage, setCurrentImage] = useState(null);\r\n  const [permissionsGranted, setPermissionsGranted] = useState(false);\r\n  const [examTerminated, setExamTerminated] = useState(false);\r\n  const [mediaStream, setMediaStream] = useState(null);\r\n  const [showPermissionMessage, setShowPermissionMessage] = useState(true);\r\n  const [noFaceDuration, setNoFaceDuration] = useState(0);\r\n  const [transcript, setTranscript] = useState(\"\");\r\n  const [violations, setViolations] = useState(0);\r\n  const recognitionRef = useRef(null);\r\n\r\n  // Enhanced Audio Monitoring State\r\n  const [audioAnalysis, setAudioAnalysis] = useState({\r\n    volumeLevel: 0,\r\n    voiceConsistency: 100,\r\n    backgroundNoiseLevel: 0,\r\n    audioAnomalies: 0,\r\n    speakingRate: 0,\r\n    pitchVariation: 0,\r\n    lastVoicePrint: null,\r\n    audioContextReady: false,\r\n  });\r\n\r\n  const audioContextRef = useRef(null);\r\n  const analyserRef = useRef(null);\r\n  const voicePrintIntervalRef = useRef(null);\r\n  const audioCheckIntervalRef = useRef(null);\r\n\r\n  useEffect(() => {\r\n    const loadModels = async () => {\r\n      await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\r\n      console.log(\"Face Detection Model Loaded\");\r\n    };\r\n    loadModels();\r\n  }, []);\r\n\r\n  const getPermissions = async () => {\r\n    try {\r\n      const stream = await navigator.mediaDevices.getUserMedia({\r\n        video: true,\r\n        audio: {\r\n          echoCancellation: false,\r\n          noiseSuppression: false,\r\n          autoGainControl: false,\r\n        },\r\n      });\r\n      setMediaStream(stream);\r\n      setPermissionsGranted(true);\r\n      setShowPermissionMessage(false);\r\n      initializeAudioAnalysis(stream);\r\n      initializeSpeechRecognition();\r\n    } catch (error) {\r\n      alert(\"Please allow access to camera and microphone.\");\r\n      setShowPermissionMessage(true);\r\n    }\r\n  };\r\n\r\n  // Advanced Audio Analysis Initialization\r\n  const initializeAudioAnalysis = (stream) => {\r\n    try {\r\n      // Create audio context\r\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({\r\n        latencyHint: \"interactive\",\r\n        sampleRate: 44100,\r\n      });\r\n\r\n      // Create analyser node with higher precision\r\n      analyserRef.current = audioContextRef.current.createAnalyser();\r\n      analyserRef.current.fftSize = 8192;\r\n      analyserRef.current.smoothingTimeConstant = 0.8;\r\n\r\n      // Create media stream source\r\n      const source = audioContextRef.current.createMediaStreamSource(stream);\r\n      source.connect(analyserRef.current);\r\n\r\n      // Initialize voice print collection\r\n      startVoicePrintCollection();\r\n\r\n      // Start continuous audio monitoring\r\n      startAudioMonitoring();\r\n\r\n      setAudioAnalysis((prev) => ({\r\n        ...prev,\r\n        audioContextReady: true,\r\n      }));\r\n    } catch (error) {\r\n      console.error(\"Audio analysis initialization error:\", error);\r\n    }\r\n  };\r\n\r\n  // Voice Print Collection\r\n  const startVoicePrintCollection = () => {\r\n    const collectVoicePrint = () => {\r\n      if (!analyserRef.current) return;\r\n      const bufferLength = analyserRef.current.frequencyBinCount;\r\n      const frequencyData = new Float32Array(bufferLength);\r\n      const timeDomainData = new Float32Array(bufferLength);\r\n      analyserRef.current.getFloatFrequencyData(frequencyData);\r\n      analyserRef.current.getFloatTimeDomainData(timeDomainData);\r\n\r\n      // Calculate voice characteristics\r\n      const voicePrint = {\r\n        timestamp: Date.now(),\r\n        spectralCentroid: calculateSpectralCentroid(frequencyData),\r\n        spectralFlatness: calculateSpectralFlatness(frequencyData),\r\n        energy: calculateEnergy(timeDomainData),\r\n        zeroCrossingRate: calculateZeroCrossingRate(timeDomainData),\r\n        pitch: estimatePitch(timeDomainData),\r\n        formants: estimateFormants(frequencyData),\r\n      };\r\n\r\n      setAudioAnalysis((prev) => ({\r\n        ...prev,\r\n        lastVoicePrint: voicePrint,\r\n      }));\r\n    };\r\n\r\n    voicePrintIntervalRef.current = setInterval(collectVoicePrint, 2000);\r\n  };\r\n\r\n  // Continuous Audio Monitoring\r\n  const startAudioMonitoring = () => {\r\n    const monitorAudio = () => {\r\n      if (!analyserRef.current) return;\r\n      const bufferLength = analyserRef.current.frequencyBinCount;\r\n      const frequencyData = new Float32Array(bufferLength);\r\n      const timeDomainData = new Float32Array(bufferLength);\r\n      analyserRef.current.getFloatFrequencyData(frequencyData);\r\n      analyserRef.current.getFloatTimeDomainData(timeDomainData);\r\n\r\n      // Calculate current audio metrics\r\n      const currentVolume = calculateVolumeLevel(timeDomainData);\r\n      const currentNoise = calculateBackgroundNoise(frequencyData);\r\n      const currentAnomalies = detectAudioAnomalies(frequencyData);\r\n      const speakingRate = estimateSpeakingRate(timeDomainData);\r\n      const pitchVar = estimatePitchVariation(timeDomainData);\r\n\r\n      // Calculate voice consistency if we have a previous voice print\r\n      let consistency = 100;\r\n      if (audioAnalysis.lastVoicePrint) {\r\n        consistency = calculateVoiceConsistency(\r\n          audioAnalysis.lastVoicePrint,\r\n          {\r\n            spectralCentroid: calculateSpectralCentroid(frequencyData),\r\n            spectralFlatness: calculateSpectralFlatness(frequencyData),\r\n            energy: calculateEnergy(timeDomainData),\r\n          }\r\n        );\r\n      }\r\n\r\n      setAudioAnalysis((prev) => ({\r\n        ...prev,\r\n        volumeLevel: currentVolume,\r\n        backgroundNoiseLevel: currentNoise,\r\n        audioAnomalies: prev.audioAnomalies + currentAnomalies,\r\n        voiceConsistency: consistency,\r\n        speakingRate: speakingRate,\r\n        pitchVariation: pitchVar,\r\n      }));\r\n\r\n      // Check for potential violations\r\n      checkForAudioViolations(currentVolume, currentNoise, consistency, speakingRate, pitchVar);\r\n    };\r\n\r\n    audioCheckIntervalRef.current = setInterval(monitorAudio, 500);\r\n  };\r\n\r\n  // Audio Analysis Helper Functions\r\n  const calculateVolumeLevel = (timeDomainData) => {\r\n    let sum = 0;\r\n    for (let i = 0; i < timeDomainData.length; i++) {\r\n      sum += Math.abs(timeDomainData[i]);\r\n    }\r\n    return sum / timeDomainData.length;\r\n  };\r\n\r\n  const calculateBackgroundNoise = (frequencyData) => {\r\n    let sum = 0;\r\n    let count = 0;\r\n    for (let i = 0; i < frequencyData.length; i++) {\r\n      const freq = (i * audioContextRef.current.sampleRate) / analyserRef.current.fftSize;\r\n      if (freq > 5000) {\r\n        sum += Math.pow(10, frequencyData[i] / 20); // Convert dB to linear\r\n        count++;\r\n      }\r\n    }\r\n    return count > 0 ? sum / count : 0;\r\n  };\r\n\r\n  const detectAudioAnomalies = (frequencyData) => {\r\n    let anomalies = 0;\r\n    const bands = [\r\n      { low: 85, high: 255 }, // Low male voice\r\n      { low: 255, high: 400 }, // Female voice fundamentals\r\n      { low: 400, high: 1000 }, // Voice harmonics\r\n      { low: 1000, high: 4000 }, // Consonants and sibilance\r\n    ];\r\n\r\n    bands.forEach((band) => {\r\n      const bandEnergy = calculateBandEnergy(frequencyData, band.low, band.high);\r\n      const threshold = audioAnalysis.lastVoicePrint\r\n        ? audioAnalysis.lastVoicePrint.energy * 1.8\r\n        : 0.1;\r\n      if (bandEnergy > threshold) {\r\n        anomalies++;\r\n      }\r\n    });\r\n\r\n    return anomalies;\r\n  };\r\n\r\n  const calculateVoiceConsistency = (baseline, current) => {\r\n    const centroidDiff = Math.abs(current.spectralCentroid - baseline.spectralCentroid) / baseline.spectralCentroid;\r\n    const flatnessDiff = Math.abs(current.spectralFlatness - baseline.spectralFlatness);\r\n    const energyDiff = Math.abs(current.energy - baseline.energy) / baseline.energy;\r\n\r\n    const score = 100 - (\r\n      (Math.min(centroidDiff, 0.5) * 40) +\r\n      (Math.min(flatnessDiff, 0.3) * 30) +\r\n      (Math.min(energyDiff, 1.0) * 30)\r\n    );\r\n\r\n    return Math.max(0, Math.min(100, score));\r\n  };\r\n\r\n  const checkForAudioViolations = (volume, noise, consistency, speakingRate, pitchVar) => {\r\n    const multipleSpeakersDetected =\r\n      consistency < 60 || // Voice characteristics changed significantly\r\n      (noise > 0.15 && volume > 0.2) || // High noise with high volume\r\n      speakingRate > 10 || // Unusually fast speech\r\n      pitchVar > 100; // Extreme pitch variations\r\n\r\n    if (multipleSpeakersDetected) {\r\n      setViolations((prev) => {\r\n        const newViolations = prev + 1;\r\n        if (newViolations >= 3) {\r\n          setExamTerminated(true);\r\n          clearInterval(voicePrintIntervalRef.current);\r\n          clearInterval(audioCheckIntervalRef.current);\r\n        } else if (newViolations % 1 === 0) {\r\n          alert(`Audio Anomaly Detected! (Violation ${newViolations}/3)\\nPlease ensure you're alone in a quiet environment.`);\r\n        }\r\n        return newViolations;\r\n      });\r\n    }\r\n  };\r\n\r\n  const initializeSpeechRecognition = () => {\r\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n    if (!SpeechRecognition) {\r\n      console.error(\"Speech Recognition API not supported in this browser\");\r\n      return;\r\n    }\r\n\r\n    recognitionRef.current = new SpeechRecognition();\r\n    recognitionRef.current.continuous = true;\r\n    recognitionRef.current.interimResults = true;\r\n    recognitionRef.current.lang = \"ar-SA\";\r\n    recognitionRef.current.maxAlternatives = 3;\r\n\r\n    recognitionRef.current.onresult = (event) => {\r\n      let finalTranscript = \"\";\r\n      let interimTranscript = \"\";\r\n\r\n      for (let i = event.resultIndex; i < event.results.length; i++) {\r\n        const transcript = event.results[i][0].transcript;\r\n        if (event.results[i].isFinal) {\r\n          finalTranscript += transcript + \" \";\r\n        } else {\r\n          interimTranscript += transcript;\r\n        }\r\n      }\r\n\r\n      setTranscript(finalTranscript || interimTranscript);\r\n\r\n      // Additional check for multiple speakers in transcript\r\n      if (finalTranscript.includes(\" Ÿà \") || finalTranscript.includes(\" ÿ´ŸÖ \")) {\r\n        setViolations((prev) => prev + 0.5); // Partial violation for conjunction words\r\n      }\r\n    };\r\n\r\n    recognitionRef.current.onerror = (event) => {\r\n      console.error(\"Speech recognition error\", event.error);\r\n    };\r\n\r\n    recognitionRef.current.start();\r\n    recognitionRef.current.onend = () => {\r\n      recognitionRef.current.start();\r\n    };\r\n  };\r\n\r\n  const detectFace = async () => {\r\n    if (webcamRef.current && webcamRef.current.video.readyState === 4) {\r\n      const video = webcamRef.current.video;\r\n      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\r\n      const isFacePresent = detections.length > 0;\r\n      setFaceDetected(isFacePresent);\r\n      setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\r\n    }\r\n  };\r\n\r\n  useEffect(() => {\r\n    return () => {\r\n      if (recognitionRef.current) {\r\n        recognitionRef.current.stop();\r\n      }\r\n      if (voicePrintIntervalRef.current) {\r\n        clearInterval(voicePrintIntervalRef.current);\r\n      }\r\n      if (audioCheckIntervalRef.current) {\r\n        clearInterval(audioCheckIntervalRef.current);\r\n      }\r\n      if (audioContextRef.current) {\r\n        audioContextRef.current.close();\r\n      }\r\n    };\r\n  }, []);\r\n\r\n  useEffect(() => {\r\n    if (permissionsGranted) {\r\n      const interval = setInterval(detectFace, 1000);\r\n      return () => clearInterval(interval);\r\n    }\r\n  }, [permissionsGranted]);\r\n\r\n  useEffect(() => {\r\n    if (noFaceDuration >= 15) {\r\n      alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\r\n      setNoFaceDuration(0);\r\n    }\r\n  }, [noFaceDuration]);\r\n\r\n  // Helper functions\r\n  const calculateSpectralCentroid = (frequencyData) => {\r\n    let sum = 0;\r\n    let totalMagnitude = 0;\r\n    for (let i = 0; i < frequencyData.length; i++) {\r\n      const magnitude = Math.pow(10, frequencyData[i] / 20);\r\n      sum += i * magnitude;\r\n      totalMagnitude += magnitude;\r\n    }\r\n    return totalMagnitude > 0 ? sum / totalMagnitude : 0;\r\n  };\r\n\r\n  const calculateSpectralFlatness = (frequencyData) => {\r\n    let product = 1;\r\n    let sum = 0;\r\n    const count = frequencyData.length;\r\n    for (let i = 0; i < count; i++) {\r\n      const value = Math.pow(10, frequencyData[i] / 20);\r\n      product *= value;\r\n      sum += value;\r\n    }\r\n    return sum > 0 ? product / Math.pow(sum / count, count) : 0;\r\n  };\r\n\r\n  const calculateEnergy = (timeDomainData) => {\r\n    let sum = 0;\r\n    for (let i = 0; i < timeDomainData.length; i++) {\r\n      sum += Math.pow(timeDomainData[i], 2);\r\n    }\r\n    return Math.sqrt(sum / timeDomainData.length);\r\n  };\r\n\r\n  const calculateZeroCrossingRate = (timeDomainData) => {\r\n    let crossings = 0;\r\n    for (let i = 1; i < timeDomainData.length; i++) {\r\n      if (timeDomainData[i] * timeDomainData[i - 1] < 0) {\r\n        crossings++;\r\n      }\r\n    }\r\n    return crossings / timeDomainData.length;\r\n  };\r\n\r\n  const estimatePitch = (timeDomainData) => {\r\n    const maxLag = Math.floor(audioContextRef.current.sampleRate / 60); // Minimum pitch (60Hz)\r\n    const minLag = Math.floor(audioContextRef.current.sampleRate / 400); // Maximum pitch (400Hz)\r\n    let bestLag = 0;\r\n    let bestCorrelation = -1;\r\n\r\n    for (let lag = minLag; lag <= maxLag; lag++) {\r\n      let correlation = 0;\r\n      for (let i = 0; i < timeDomainData.length - lag; i++) {\r\n        correlation += timeDomainData[i] * timeDomainData[i + lag];\r\n      }\r\n      if (correlation > bestCorrelation) {\r\n        bestCorrelation = correlation;\r\n        bestLag = lag;\r\n      }\r\n    }\r\n\r\n    return bestLag > 0 ? audioContextRef.current.sampleRate / bestLag : 0;\r\n  };\r\n\r\n  const estimateFormants = (frequencyData) => {\r\n    const formants = [];\r\n    const binSize = audioContextRef.current.sampleRate / frequencyData.length;\r\n\r\n    for (let i = 1; i < frequencyData.length - 1; i++) {\r\n      const prev = frequencyData[i - 1];\r\n      const curr = frequencyData[i];\r\n      const next = frequencyData[i + 1];\r\n\r\n      if (curr > prev && curr > next && curr > -50) {\r\n        formants.push(i * binSize);\r\n        if (formants.length >= 3) break; // Only need first few formants\r\n      }\r\n    }\r\n\r\n    return formants;\r\n  };\r\n\r\n  const calculateBandEnergy = (frequencyData, lowFreq, highFreq) => {\r\n    const binSize = audioContextRef.current.sampleRate / frequencyData.length;\r\n    const startBin = Math.floor(lowFreq / binSize);\r\n    const endBin = Math.ceil(highFreq / binSize);\r\n    let energy = 0;\r\n\r\n    for (let i = startBin; i <= endBin; i++) {\r\n      energy += Math.pow(10, frequencyData[i] / 20);\r\n    }\r\n\r\n    return energy / (endBin - startBin + 1);\r\n  };\r\n\r\n  const estimateSpeakingRate = (timeDomainData) => {\r\n    let speechFrames = 0;\r\n    const threshold = 0.05;\r\n\r\n    for (let i = 0; i < timeDomainData.length; i++) {\r\n      if (Math.abs(timeDomainData[i]) > threshold) {\r\n        speechFrames++;\r\n      }\r\n    }\r\n\r\n    return (speechFrames / timeDomainData.length) * 100;\r\n  };\r\n\r\n  const estimatePitchVariation = (timeDomainData) => {\r\n    const segmentLength = Math.floor(audioContextRef.current.sampleRate / 100); // 10ms segments\r\n    const pitches = [];\r\n\r\n    for (let i = 0; i < timeDomainData.length - segmentLength; i += segmentLength) {\r\n      const segment = timeDomainData.slice(i, i + segmentLength);\r\n      const pitch = estimatePitch(segment);\r\n      if (pitch > 0) pitches.push(pitch);\r\n    }\r\n\r\n    if (pitches.length < 2) return 0;\r\n\r\n    let variation = 0;\r\n    for (let i = 1; i < pitches.length; i++) {\r\n      variation += Math.abs(pitches[i] - pitches[i - 1]);\r\n    }\r\n\r\n    return variation / (pitches.length - 1);\r\n  };\r\n\r\n  return (\r\n    <div className=\"continuous-auth-container\">\r\n      <h2>Advanced Exam Proctoring System</h2>\r\n      {showPermissionMessage && (\r\n        <div className=\"permission-message\">\r\n          <h3>Exam Proctoring Setup</h3>\r\n          <p>This exam requires camera and microphone access for proctoring purposes.</p>\r\n          <div className=\"permission-requirements\">\r\n            <p>‚úì Face detection must be enabled</p>\r\n            <p>‚úì Microphone must be active (raw audio preferred)</p>\r\n            <p>‚úì Quiet environment recommended</p>\r\n          </div>\r\n          <button className=\"permission-button\" onClick={getPermissions}>\r\n            Enable Camera & Microphone\r\n          </button>\r\n        </div>\r\n      )}\r\n      {permissionsGranted && !examTerminated && (\r\n        <div className=\"monitoring-container\">\r\n          <div className=\"video-section\">\r\n            <Webcam\r\n              audio={true}\r\n              ref={webcamRef}\r\n              screenshotFormat=\"image/jpeg\"\r\n              className=\"webcam\"\r\n              videoConstraints={{\r\n                facingMode: \"user\",\r\n                width: 480,\r\n                height: 360,\r\n              }}\r\n            />\r\n            <div className=\"status-indicators\">\r\n              <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\r\n                {faceDetected ? \"Face Detected\" : \"No Face Detected\"}\r\n              </div>\r\n              <div className={`status-indicator ${audioAnalysis.volumeLevel > 0.1 ? \"active\" : \"\"}`}>\r\n                {audioAnalysis.volumeLevel > 0.1 ? \"Audio Active\" : \"Audio Silent\"}\r\n              </div>\r\n              <div className=\"status-indicator\">\r\n                Voice Consistency: {Math.round(audioAnalysis.voiceConsistency)}%\r\n              </div>\r\n            </div>\r\n          </div>\r\n          <div className=\"audio-analysis-section\">\r\n            <h3>Advanced Audio Monitoring</h3>\r\n            <div className=\"audio-metrics\">\r\n              <div className=\"metric\">\r\n                <span className=\"metric-label\">Volume Level:</span>\r\n                <div className=\"metric-bar-container\">\r\n                  <div\r\n                    className=\"metric-bar\"\r\n                    style={{ width: `${Math.min(100, audioAnalysis.volumeLevel * 500)}%` }}\r\n                  ></div>\r\n                </div>\r\n              </div>\r\n              <div className=\"metric\">\r\n                <span className=\"metric-label\">Background Noise:</span>\r\n                <div className=\"metric-bar-container\">\r\n                  <div\r\n                    className=\"metric-bar noise\"\r\n                    style={{ width: `${Math.min(100, audioAnalysis.backgroundNoiseLevel * 500)}%` }}\r\n                  ></div>\r\n                </div>\r\n              </div>\r\n              <div className=\"metric\">\r\n                <span className=\"metric-label\">Voice Consistency:</span>\r\n                <div className=\"metric-bar-container\">\r\n                  <div\r\n                    className=\"metric-bar consistency\"\r\n                    style={{ width: `${audioAnalysis.voiceConsistency}%` }}\r\n                  ></div>\r\n                </div>\r\n              </div>\r\n              <div className=\"metric\">\r\n                <span className=\"metric-label\">Audio Anomalies:</span>\r\n                <span className=\"metric-value\">{audioAnalysis.audioAnomalies}</span>\r\n              </div>\r\n            </div>\r\n          </div>\r\n          <div className=\"transcript-section\">\r\n            <div className=\"transcript-box\">\r\n              <div className=\"transcript-header\">\r\n                <span>Arabic Speech Transcript</span>\r\n                <span className=\"violation-counter\">Violations: {Math.floor(violations)}/3</span>\r\n              </div>\r\n              <div className=\"transcript-content\" dir=\"rtl\">\r\n                {transcript || \"Waiting for audio input...\"}\r\n              </div>\r\n              <div className=\"audio-warnings\">\r\n                {audioAnalysis.voiceConsistency < 70 && (\r\n                  <div className=\"warning-message\">\r\n                    ‚ö† Voice inconsistency detected. Please ensure you're the only speaker.\r\n                  </div>\r\n                )}\r\n                {audioAnalysis.backgroundNoiseLevel > 0.2 && (\r\n                  <div className=\"warning-message\">\r\n                    ‚ö† High background noise detected. Find a quieter environment.\r\n                  </div>\r\n                )}\r\n              </div>\r\n            </div>\r\n          </div>\r\n        </div>\r\n      )}\r\n      {examTerminated && (\r\n        <div className=\"termination-message\">\r\n          <h3>‚úñ Exam Terminated</h3>\r\n          <p>Due to multiple audio violations detected. Please contact your instructor.</p>\r\n          <div className=\"violation-details\">\r\n            <p>Total violations: {violations}</p>\r\n            <p>Final voice consistency: {Math.round(audioAnalysis.voiceConsistency)}%</p>\r\n            <p>Audio anomalies detected: {audioAnalysis.audioAnomalies}</p>\r\n          </div>\r\n        </div>\r\n      )}\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default ContinuousAuth;\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"],"mappings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vE,OAAO,KAAKC,OAAO,MAAM,aAAa;AACtC,OAAOC,MAAM,MAAM,cAAc;AACjC,OAAO,sBAAsB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE9B,MAAMC,cAAc,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC3B,MAAMC,SAAS,GAAGR,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAM,CAACS,YAAY,EAAEC,eAAe,CAAC,GAAGZ,QAAQ,CAAC,KAAK,CAAC;EACvD,MAAM,CAACa,YAAY,EAAEC,eAAe,CAAC,GAAGd,QAAQ,CAAC,IAAI,CAAC;EACtD,MAAM,CAACe,kBAAkB,EAAEC,qBAAqB,CAAC,GAAGhB,QAAQ,CAAC,KAAK,CAAC;EACnE,MAAM,CAACiB,cAAc,EAAEC,iBAAiB,CAAC,GAAGlB,QAAQ,CAAC,KAAK,CAAC;EAC3D,MAAM,CAACmB,WAAW,EAAEC,cAAc,CAAC,GAAGpB,QAAQ,CAAC,IAAI,CAAC;EACpD,MAAM,CAACqB,qBAAqB,EAAEC,wBAAwB,CAAC,GAAGtB,QAAQ,CAAC,IAAI,CAAC;EACxE,MAAM,CAACuB,cAAc,EAAEC,iBAAiB,CAAC,GAAGxB,QAAQ,CAAC,CAAC,CAAC;EACvD,MAAM,CAACyB,UAAU,EAAEC,aAAa,CAAC,GAAG1B,QAAQ,CAAC,EAAE,CAAC;EAChD,MAAM,CAAC2B,UAAU,EAAEC,aAAa,CAAC,GAAG5B,QAAQ,CAAC,CAAC,CAAC;EAC/C,MAAM6B,cAAc,GAAG3B,MAAM,CAAC,IAAI,CAAC;;EAEnC;EACA,MAAM,CAAC4B,aAAa,EAAEC,gBAAgB,CAAC,GAAG/B,QAAQ,CAAC;IACjDgC,WAAW,EAAE,CAAC;IACdC,gBAAgB,EAAE,GAAG;IACrBC,oBAAoB,EAAE,CAAC;IACvBC,cAAc,EAAE,CAAC;IACjBC,YAAY,EAAE,CAAC;IACfC,cAAc,EAAE,CAAC;IACjBC,cAAc,EAAE,IAAI;IACpBC,iBAAiB,EAAE;EACrB,CAAC,CAAC;EAEF,MAAMC,eAAe,GAAGtC,MAAM,CAAC,IAAI,CAAC;EACpC,MAAMuC,WAAW,GAAGvC,MAAM,CAAC,IAAI,CAAC;EAChC,MAAMwC,qBAAqB,GAAGxC,MAAM,CAAC,IAAI,CAAC;EAC1C,MAAMyC,qBAAqB,GAAGzC,MAAM,CAAC,IAAI,CAAC;EAE1CD,SAAS,CAAC,MAAM;IACd,MAAM2C,UAAU,GAAG,MAAAA,CAAA,KAAY;MAC7B,MAAMxC,OAAO,CAACyC,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAAC,SAAS,CAAC;MAC1DC,OAAO,CAACC,GAAG,CAAC,6BAA6B,CAAC;IAC5C,CAAC;IACDL,UAAU,CAAC,CAAC;EACd,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMM,cAAc,GAAG,MAAAA,CAAA,KAAY;IACjC,IAAI;MACF,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QACvDC,KAAK,EAAE,IAAI;QACXC,KAAK,EAAE;UACLC,gBAAgB,EAAE,KAAK;UACvBC,gBAAgB,EAAE,KAAK;UACvBC,eAAe,EAAE;QACnB;MACF,CAAC,CAAC;MACFvC,cAAc,CAAC+B,MAAM,CAAC;MACtBnC,qBAAqB,CAAC,IAAI,CAAC;MAC3BM,wBAAwB,CAAC,KAAK,CAAC;MAC/BsC,uBAAuB,CAACT,MAAM,CAAC;MAC/BU,2BAA2B,CAAC,CAAC;IAC/B,CAAC,CAAC,OAAOC,KAAK,EAAE;MACdC,KAAK,CAAC,+CAA+C,CAAC;MACtDzC,wBAAwB,CAAC,IAAI,CAAC;IAChC;EACF,CAAC;;EAED;EACA,MAAMsC,uBAAuB,GAAIT,MAAM,IAAK;IAC1C,IAAI;MACF;MACAX,eAAe,CAACwB,OAAO,GAAG,KAAKC,MAAM,CAACC,YAAY,IAAID,MAAM,CAACE,kBAAkB,EAAE;QAC/EC,WAAW,EAAE,aAAa;QAC1BC,UAAU,EAAE;MACd,CAAC,CAAC;;MAEF;MACA5B,WAAW,CAACuB,OAAO,GAAGxB,eAAe,CAACwB,OAAO,CAACM,cAAc,CAAC,CAAC;MAC9D7B,WAAW,CAACuB,OAAO,CAACO,OAAO,GAAG,IAAI;MAClC9B,WAAW,CAACuB,OAAO,CAACQ,qBAAqB,GAAG,GAAG;;MAE/C;MACA,MAAMC,MAAM,GAAGjC,eAAe,CAACwB,OAAO,CAACU,uBAAuB,CAACvB,MAAM,CAAC;MACtEsB,MAAM,CAACE,OAAO,CAAClC,WAAW,CAACuB,OAAO,CAAC;;MAEnC;MACAY,yBAAyB,CAAC,CAAC;;MAE3B;MACAC,oBAAoB,CAAC,CAAC;MAEtB9C,gBAAgB,CAAE+C,IAAI,KAAM;QAC1B,GAAGA,IAAI;QACPvC,iBAAiB,EAAE;MACrB,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,OAAOuB,KAAK,EAAE;MACdd,OAAO,CAACc,KAAK,CAAC,sCAAsC,EAAEA,KAAK,CAAC;IAC9D;EACF,CAAC;;EAED;EACA,MAAMc,yBAAyB,GAAGA,CAAA,KAAM;IACtC,MAAMG,iBAAiB,GAAGA,CAAA,KAAM;MAC9B,IAAI,CAACtC,WAAW,CAACuB,OAAO,EAAE;MAC1B,MAAMgB,YAAY,GAAGvC,WAAW,CAACuB,OAAO,CAACiB,iBAAiB;MAC1D,MAAMC,aAAa,GAAG,IAAIC,YAAY,CAACH,YAAY,CAAC;MACpD,MAAMI,cAAc,GAAG,IAAID,YAAY,CAACH,YAAY,CAAC;MACrDvC,WAAW,CAACuB,OAAO,CAACqB,qBAAqB,CAACH,aAAa,CAAC;MACxDzC,WAAW,CAACuB,OAAO,CAACsB,sBAAsB,CAACF,cAAc,CAAC;;MAE1D;MACA,MAAMG,UAAU,GAAG;QACjBC,SAAS,EAAEC,IAAI,CAACC,GAAG,CAAC,CAAC;QACrBC,gBAAgB,EAAEC,yBAAyB,CAACV,aAAa,CAAC;QAC1DW,gBAAgB,EAAEC,yBAAyB,CAACZ,aAAa,CAAC;QAC1Da,MAAM,EAAEC,eAAe,CAACZ,cAAc,CAAC;QACvCa,gBAAgB,EAAEC,yBAAyB,CAACd,cAAc,CAAC;QAC3De,KAAK,EAAEC,aAAa,CAAChB,cAAc,CAAC;QACpCiB,QAAQ,EAAEC,gBAAgB,CAACpB,aAAa;MAC1C,CAAC;MAEDnD,gBAAgB,CAAE+C,IAAI,KAAM;QAC1B,GAAGA,IAAI;QACPxC,cAAc,EAAEiD;MAClB,CAAC,CAAC,CAAC;IACL,CAAC;IAED7C,qBAAqB,CAACsB,OAAO,GAAGuC,WAAW,CAACxB,iBAAiB,EAAE,IAAI,CAAC;EACtE,CAAC;;EAED;EACA,MAAMF,oBAAoB,GAAGA,CAAA,KAAM;IACjC,MAAM2B,YAAY,GAAGA,CAAA,KAAM;MACzB,IAAI,CAAC/D,WAAW,CAACuB,OAAO,EAAE;MAC1B,MAAMgB,YAAY,GAAGvC,WAAW,CAACuB,OAAO,CAACiB,iBAAiB;MAC1D,MAAMC,aAAa,GAAG,IAAIC,YAAY,CAACH,YAAY,CAAC;MACpD,MAAMI,cAAc,GAAG,IAAID,YAAY,CAACH,YAAY,CAAC;MACrDvC,WAAW,CAACuB,OAAO,CAACqB,qBAAqB,CAACH,aAAa,CAAC;MACxDzC,WAAW,CAACuB,OAAO,CAACsB,sBAAsB,CAACF,cAAc,CAAC;;MAE1D;MACA,MAAMqB,aAAa,GAAGC,oBAAoB,CAACtB,cAAc,CAAC;MAC1D,MAAMuB,YAAY,GAAGC,wBAAwB,CAAC1B,aAAa,CAAC;MAC5D,MAAM2B,gBAAgB,GAAGC,oBAAoB,CAAC5B,aAAa,CAAC;MAC5D,MAAM9C,YAAY,GAAG2E,oBAAoB,CAAC3B,cAAc,CAAC;MACzD,MAAM4B,QAAQ,GAAGC,sBAAsB,CAAC7B,cAAc,CAAC;;MAEvD;MACA,IAAI8B,WAAW,GAAG,GAAG;MACrB,IAAIpF,aAAa,CAACQ,cAAc,EAAE;QAChC4E,WAAW,GAAGC,yBAAyB,CACrCrF,aAAa,CAACQ,cAAc,EAC5B;UACEqD,gBAAgB,EAAEC,yBAAyB,CAACV,aAAa,CAAC;UAC1DW,gBAAgB,EAAEC,yBAAyB,CAACZ,aAAa,CAAC;UAC1Da,MAAM,EAAEC,eAAe,CAACZ,cAAc;QACxC,CACF,CAAC;MACH;MAEArD,gBAAgB,CAAE+C,IAAI,KAAM;QAC1B,GAAGA,IAAI;QACP9C,WAAW,EAAEyE,aAAa;QAC1BvE,oBAAoB,EAAEyE,YAAY;QAClCxE,cAAc,EAAE2C,IAAI,CAAC3C,cAAc,GAAG0E,gBAAgB;QACtD5E,gBAAgB,EAAEiF,WAAW;QAC7B9E,YAAY,EAAEA,YAAY;QAC1BC,cAAc,EAAE2E;MAClB,CAAC,CAAC,CAAC;;MAEH;MACAI,uBAAuB,CAACX,aAAa,EAAEE,YAAY,EAAEO,WAAW,EAAE9E,YAAY,EAAE4E,QAAQ,CAAC;IAC3F,CAAC;IAEDrE,qBAAqB,CAACqB,OAAO,GAAGuC,WAAW,CAACC,YAAY,EAAE,GAAG,CAAC;EAChE,CAAC;;EAED;EACA,MAAME,oBAAoB,GAAItB,cAAc,IAAK;IAC/C,IAAIiC,GAAG,GAAG,CAAC;IACX,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGlC,cAAc,CAACmC,MAAM,EAAED,CAAC,EAAE,EAAE;MAC9CD,GAAG,IAAIG,IAAI,CAACC,GAAG,CAACrC,cAAc,CAACkC,CAAC,CAAC,CAAC;IACpC;IACA,OAAOD,GAAG,GAAGjC,cAAc,CAACmC,MAAM;EACpC,CAAC;EAED,MAAMX,wBAAwB,GAAI1B,aAAa,IAAK;IAClD,IAAImC,GAAG,GAAG,CAAC;IACX,IAAIK,KAAK,GAAG,CAAC;IACb,KAAK,IAAIJ,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGpC,aAAa,CAACqC,MAAM,EAAED,CAAC,EAAE,EAAE;MAC7C,MAAMK,IAAI,GAAIL,CAAC,GAAG9E,eAAe,CAACwB,OAAO,CAACK,UAAU,GAAI5B,WAAW,CAACuB,OAAO,CAACO,OAAO;MACnF,IAAIoD,IAAI,GAAG,IAAI,EAAE;QACfN,GAAG,IAAIG,IAAI,CAACI,GAAG,CAAC,EAAE,EAAE1C,aAAa,CAACoC,CAAC,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC;QAC5CI,KAAK,EAAE;MACT;IACF;IACA,OAAOA,KAAK,GAAG,CAAC,GAAGL,GAAG,GAAGK,KAAK,GAAG,CAAC;EACpC,CAAC;EAED,MAAMZ,oBAAoB,GAAI5B,aAAa,IAAK;IAC9C,IAAI2C,SAAS,GAAG,CAAC;IACjB,MAAMC,KAAK,GAAG,CACZ;MAAEC,GAAG,EAAE,EAAE;MAAEC,IAAI,EAAE;IAAI,CAAC;IAAE;IACxB;MAAED,GAAG,EAAE,GAAG;MAAEC,IAAI,EAAE;IAAI,CAAC;IAAE;IACzB;MAAED,GAAG,EAAE,GAAG;MAAEC,IAAI,EAAE;IAAK,CAAC;IAAE;IAC1B;MAAED,GAAG,EAAE,IAAI;MAAEC,IAAI,EAAE;IAAK,CAAC,CAAE;IAAA,CAC5B;IAEDF,KAAK,CAACG,OAAO,CAAEC,IAAI,IAAK;MACtB,MAAMC,UAAU,GAAGC,mBAAmB,CAAClD,aAAa,EAAEgD,IAAI,CAACH,GAAG,EAAEG,IAAI,CAACF,IAAI,CAAC;MAC1E,MAAMK,SAAS,GAAGvG,aAAa,CAACQ,cAAc,GAC1CR,aAAa,CAACQ,cAAc,CAACyD,MAAM,GAAG,GAAG,GACzC,GAAG;MACP,IAAIoC,UAAU,GAAGE,SAAS,EAAE;QAC1BR,SAAS,EAAE;MACb;IACF,CAAC,CAAC;IAEF,OAAOA,SAAS;EAClB,CAAC;EAED,MAAMV,yBAAyB,GAAGA,CAACmB,QAAQ,EAAEtE,OAAO,KAAK;IACvD,MAAMuE,YAAY,GAAGf,IAAI,CAACC,GAAG,CAACzD,OAAO,CAAC2B,gBAAgB,GAAG2C,QAAQ,CAAC3C,gBAAgB,CAAC,GAAG2C,QAAQ,CAAC3C,gBAAgB;IAC/G,MAAM6C,YAAY,GAAGhB,IAAI,CAACC,GAAG,CAACzD,OAAO,CAAC6B,gBAAgB,GAAGyC,QAAQ,CAACzC,gBAAgB,CAAC;IACnF,MAAM4C,UAAU,GAAGjB,IAAI,CAACC,GAAG,CAACzD,OAAO,CAAC+B,MAAM,GAAGuC,QAAQ,CAACvC,MAAM,CAAC,GAAGuC,QAAQ,CAACvC,MAAM;IAE/E,MAAM2C,KAAK,GAAG,GAAG,IACdlB,IAAI,CAACmB,GAAG,CAACJ,YAAY,EAAE,GAAG,CAAC,GAAG,EAAE,GAChCf,IAAI,CAACmB,GAAG,CAACH,YAAY,EAAE,GAAG,CAAC,GAAG,EAAG,GACjChB,IAAI,CAACmB,GAAG,CAACF,UAAU,EAAE,GAAG,CAAC,GAAG,EAAG,CACjC;IAED,OAAOjB,IAAI,CAACoB,GAAG,CAAC,CAAC,EAAEpB,IAAI,CAACmB,GAAG,CAAC,GAAG,EAAED,KAAK,CAAC,CAAC;EAC1C,CAAC;EAED,MAAMtB,uBAAuB,GAAGA,CAACyB,MAAM,EAAEC,KAAK,EAAE5B,WAAW,EAAE9E,YAAY,EAAE4E,QAAQ,KAAK;IACtF,MAAM+B,wBAAwB,GAC5B7B,WAAW,GAAG,EAAE;IAAI;IACnB4B,KAAK,GAAG,IAAI,IAAID,MAAM,GAAG,GAAI;IAAI;IAClCzG,YAAY,GAAG,EAAE;IAAI;IACrB4E,QAAQ,GAAG,GAAG,CAAC,CAAC;;IAElB,IAAI+B,wBAAwB,EAAE;MAC5BnH,aAAa,CAAEkD,IAAI,IAAK;QACtB,MAAMkE,aAAa,GAAGlE,IAAI,GAAG,CAAC;QAC9B,IAAIkE,aAAa,IAAI,CAAC,EAAE;UACtB9H,iBAAiB,CAAC,IAAI,CAAC;UACvB+H,aAAa,CAACvG,qBAAqB,CAACsB,OAAO,CAAC;UAC5CiF,aAAa,CAACtG,qBAAqB,CAACqB,OAAO,CAAC;QAC9C,CAAC,MAAM,IAAIgF,aAAa,GAAG,CAAC,KAAK,CAAC,EAAE;UAClCjF,KAAK,CAAC,sCAAsCiF,aAAa,yDAAyD,CAAC;QACrH;QACA,OAAOA,aAAa;MACtB,CAAC,CAAC;IACJ;EACF,CAAC;EAED,MAAMnF,2BAA2B,GAAGA,CAAA,KAAM;IACxC,MAAMqF,iBAAiB,GAAGjF,MAAM,CAACiF,iBAAiB,IAAIjF,MAAM,CAACkF,uBAAuB;IACpF,IAAI,CAACD,iBAAiB,EAAE;MACtBlG,OAAO,CAACc,KAAK,CAAC,sDAAsD,CAAC;MACrE;IACF;IAEAjC,cAAc,CAACmC,OAAO,GAAG,IAAIkF,iBAAiB,CAAC,CAAC;IAChDrH,cAAc,CAACmC,OAAO,CAACoF,UAAU,GAAG,IAAI;IACxCvH,cAAc,CAACmC,OAAO,CAACqF,cAAc,GAAG,IAAI;IAC5CxH,cAAc,CAACmC,OAAO,CAACsF,IAAI,GAAG,OAAO;IACrCzH,cAAc,CAACmC,OAAO,CAACuF,eAAe,GAAG,CAAC;IAE1C1H,cAAc,CAACmC,OAAO,CAACwF,QAAQ,GAAIC,KAAK,IAAK;MAC3C,IAAIC,eAAe,GAAG,EAAE;MACxB,IAAIC,iBAAiB,GAAG,EAAE;MAE1B,KAAK,IAAIrC,CAAC,GAAGmC,KAAK,CAACG,WAAW,EAAEtC,CAAC,GAAGmC,KAAK,CAACI,OAAO,CAACtC,MAAM,EAAED,CAAC,EAAE,EAAE;QAC7D,MAAM7F,UAAU,GAAGgI,KAAK,CAACI,OAAO,CAACvC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC7F,UAAU;QACjD,IAAIgI,KAAK,CAACI,OAAO,CAACvC,CAAC,CAAC,CAACwC,OAAO,EAAE;UAC5BJ,eAAe,IAAIjI,UAAU,GAAG,GAAG;QACrC,CAAC,MAAM;UACLkI,iBAAiB,IAAIlI,UAAU;QACjC;MACF;MAEAC,aAAa,CAACgI,eAAe,IAAIC,iBAAiB,CAAC;;MAEnD;MACA,IAAID,eAAe,CAACK,QAAQ,CAAC,KAAK,CAAC,IAAIL,eAAe,CAACK,QAAQ,CAAC,MAAM,CAAC,EAAE;QACvEnI,aAAa,CAAEkD,IAAI,IAAKA,IAAI,GAAG,GAAG,CAAC,CAAC,CAAC;MACvC;IACF,CAAC;IAEDjD,cAAc,CAACmC,OAAO,CAACgG,OAAO,GAAIP,KAAK,IAAK;MAC1CzG,OAAO,CAACc,KAAK,CAAC,0BAA0B,EAAE2F,KAAK,CAAC3F,KAAK,CAAC;IACxD,CAAC;IAEDjC,cAAc,CAACmC,OAAO,CAACiG,KAAK,CAAC,CAAC;IAC9BpI,cAAc,CAACmC,OAAO,CAACkG,KAAK,GAAG,MAAM;MACnCrI,cAAc,CAACmC,OAAO,CAACiG,KAAK,CAAC,CAAC;IAChC,CAAC;EACH,CAAC;EAED,MAAME,UAAU,GAAG,MAAAA,CAAA,KAAY;IAC7B,IAAIzJ,SAAS,CAACsD,OAAO,IAAItD,SAAS,CAACsD,OAAO,CAACT,KAAK,CAAC6G,UAAU,KAAK,CAAC,EAAE;MACjE,MAAM7G,KAAK,GAAG7C,SAAS,CAACsD,OAAO,CAACT,KAAK;MACrC,MAAM8G,UAAU,GAAG,MAAMjK,OAAO,CAACkK,cAAc,CAAC/G,KAAK,EAAE,IAAInD,OAAO,CAACmK,uBAAuB,CAAC,CAAC,CAAC;MAC7F,MAAMC,aAAa,GAAGH,UAAU,CAAC9C,MAAM,GAAG,CAAC;MAC3C3G,eAAe,CAAC4J,aAAa,CAAC;MAC9BhJ,iBAAiB,CAAEsD,IAAI,IAAM0F,aAAa,GAAG,CAAC,GAAG1F,IAAI,GAAG,CAAE,CAAC;IAC7D;EACF,CAAC;EAED7E,SAAS,CAAC,MAAM;IACd,OAAO,MAAM;MACX,IAAI4B,cAAc,CAACmC,OAAO,EAAE;QAC1BnC,cAAc,CAACmC,OAAO,CAACyG,IAAI,CAAC,CAAC;MAC/B;MACA,IAAI/H,qBAAqB,CAACsB,OAAO,EAAE;QACjCiF,aAAa,CAACvG,qBAAqB,CAACsB,OAAO,CAAC;MAC9C;MACA,IAAIrB,qBAAqB,CAACqB,OAAO,EAAE;QACjCiF,aAAa,CAACtG,qBAAqB,CAACqB,OAAO,CAAC;MAC9C;MACA,IAAIxB,eAAe,CAACwB,OAAO,EAAE;QAC3BxB,eAAe,CAACwB,OAAO,CAAC0G,KAAK,CAAC,CAAC;MACjC;IACF,CAAC;EACH,CAAC,EAAE,EAAE,CAAC;EAENzK,SAAS,CAAC,MAAM;IACd,IAAIc,kBAAkB,EAAE;MACtB,MAAM4J,QAAQ,GAAGpE,WAAW,CAAC4D,UAAU,EAAE,IAAI,CAAC;MAC9C,OAAO,MAAMlB,aAAa,CAAC0B,QAAQ,CAAC;IACtC;EACF,CAAC,EAAE,CAAC5J,kBAAkB,CAAC,CAAC;EAExBd,SAAS,CAAC,MAAM;IACd,IAAIsB,cAAc,IAAI,EAAE,EAAE;MACxBwC,KAAK,CAAC,oFAAoF,CAAC;MAC3FvC,iBAAiB,CAAC,CAAC,CAAC;IACtB;EACF,CAAC,EAAE,CAACD,cAAc,CAAC,CAAC;;EAEpB;EACA,MAAMqE,yBAAyB,GAAIV,aAAa,IAAK;IACnD,IAAImC,GAAG,GAAG,CAAC;IACX,IAAIuD,cAAc,GAAG,CAAC;IACtB,KAAK,IAAItD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGpC,aAAa,CAACqC,MAAM,EAAED,CAAC,EAAE,EAAE;MAC7C,MAAMuD,SAAS,GAAGrD,IAAI,CAACI,GAAG,CAAC,EAAE,EAAE1C,aAAa,CAACoC,CAAC,CAAC,GAAG,EAAE,CAAC;MACrDD,GAAG,IAAIC,CAAC,GAAGuD,SAAS;MACpBD,cAAc,IAAIC,SAAS;IAC7B;IACA,OAAOD,cAAc,GAAG,CAAC,GAAGvD,GAAG,GAAGuD,cAAc,GAAG,CAAC;EACtD,CAAC;EAED,MAAM9E,yBAAyB,GAAIZ,aAAa,IAAK;IACnD,IAAI4F,OAAO,GAAG,CAAC;IACf,IAAIzD,GAAG,GAAG,CAAC;IACX,MAAMK,KAAK,GAAGxC,aAAa,CAACqC,MAAM;IAClC,KAAK,IAAID,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGI,KAAK,EAAEJ,CAAC,EAAE,EAAE;MAC9B,MAAMyD,KAAK,GAAGvD,IAAI,CAACI,GAAG,CAAC,EAAE,EAAE1C,aAAa,CAACoC,CAAC,CAAC,GAAG,EAAE,CAAC;MACjDwD,OAAO,IAAIC,KAAK;MAChB1D,GAAG,IAAI0D,KAAK;IACd;IACA,OAAO1D,GAAG,GAAG,CAAC,GAAGyD,OAAO,GAAGtD,IAAI,CAACI,GAAG,CAACP,GAAG,GAAGK,KAAK,EAAEA,KAAK,CAAC,GAAG,CAAC;EAC7D,CAAC;EAED,MAAM1B,eAAe,GAAIZ,cAAc,IAAK;IAC1C,IAAIiC,GAAG,GAAG,CAAC;IACX,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGlC,cAAc,CAACmC,MAAM,EAAED,CAAC,EAAE,EAAE;MAC9CD,GAAG,IAAIG,IAAI,CAACI,GAAG,CAACxC,cAAc,CAACkC,CAAC,CAAC,EAAE,CAAC,CAAC;IACvC;IACA,OAAOE,IAAI,CAACwD,IAAI,CAAC3D,GAAG,GAAGjC,cAAc,CAACmC,MAAM,CAAC;EAC/C,CAAC;EAED,MAAMrB,yBAAyB,GAAId,cAAc,IAAK;IACpD,IAAI6F,SAAS,GAAG,CAAC;IACjB,KAAK,IAAI3D,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGlC,cAAc,CAACmC,MAAM,EAAED,CAAC,EAAE,EAAE;MAC9C,IAAIlC,cAAc,CAACkC,CAAC,CAAC,GAAGlC,cAAc,CAACkC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE;QACjD2D,SAAS,EAAE;MACb;IACF;IACA,OAAOA,SAAS,GAAG7F,cAAc,CAACmC,MAAM;EAC1C,CAAC;EAED,MAAMnB,aAAa,GAAIhB,cAAc,IAAK;IACxC,MAAM8F,MAAM,GAAG1D,IAAI,CAAC2D,KAAK,CAAC3I,eAAe,CAACwB,OAAO,CAACK,UAAU,GAAG,EAAE,CAAC,CAAC,CAAC;IACpE,MAAM+G,MAAM,GAAG5D,IAAI,CAAC2D,KAAK,CAAC3I,eAAe,CAACwB,OAAO,CAACK,UAAU,GAAG,GAAG,CAAC,CAAC,CAAC;IACrE,IAAIgH,OAAO,GAAG,CAAC;IACf,IAAIC,eAAe,GAAG,CAAC,CAAC;IAExB,KAAK,IAAIC,GAAG,GAAGH,MAAM,EAAEG,GAAG,IAAIL,MAAM,EAAEK,GAAG,EAAE,EAAE;MAC3C,IAAIC,WAAW,GAAG,CAAC;MACnB,KAAK,IAAIlE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGlC,cAAc,CAACmC,MAAM,GAAGgE,GAAG,EAAEjE,CAAC,EAAE,EAAE;QACpDkE,WAAW,IAAIpG,cAAc,CAACkC,CAAC,CAAC,GAAGlC,cAAc,CAACkC,CAAC,GAAGiE,GAAG,CAAC;MAC5D;MACA,IAAIC,WAAW,GAAGF,eAAe,EAAE;QACjCA,eAAe,GAAGE,WAAW;QAC7BH,OAAO,GAAGE,GAAG;MACf;IACF;IAEA,OAAOF,OAAO,GAAG,CAAC,GAAG7I,eAAe,CAACwB,OAAO,CAACK,UAAU,GAAGgH,OAAO,GAAG,CAAC;EACvE,CAAC;EAED,MAAM/E,gBAAgB,GAAIpB,aAAa,IAAK;IAC1C,MAAMmB,QAAQ,GAAG,EAAE;IACnB,MAAMoF,OAAO,GAAGjJ,eAAe,CAACwB,OAAO,CAACK,UAAU,GAAGa,aAAa,CAACqC,MAAM;IAEzE,KAAK,IAAID,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGpC,aAAa,CAACqC,MAAM,GAAG,CAAC,EAAED,CAAC,EAAE,EAAE;MACjD,MAAMxC,IAAI,GAAGI,aAAa,CAACoC,CAAC,GAAG,CAAC,CAAC;MACjC,MAAMoE,IAAI,GAAGxG,aAAa,CAACoC,CAAC,CAAC;MAC7B,MAAMqE,IAAI,GAAGzG,aAAa,CAACoC,CAAC,GAAG,CAAC,CAAC;MAEjC,IAAIoE,IAAI,GAAG5G,IAAI,IAAI4G,IAAI,GAAGC,IAAI,IAAID,IAAI,GAAG,CAAC,EAAE,EAAE;QAC5CrF,QAAQ,CAACuF,IAAI,CAACtE,CAAC,GAAGmE,OAAO,CAAC;QAC1B,IAAIpF,QAAQ,CAACkB,MAAM,IAAI,CAAC,EAAE,MAAM,CAAC;MACnC;IACF;IAEA,OAAOlB,QAAQ;EACjB,CAAC;EAED,MAAM+B,mBAAmB,GAAGA,CAAClD,aAAa,EAAE2G,OAAO,EAAEC,QAAQ,KAAK;IAChE,MAAML,OAAO,GAAGjJ,eAAe,CAACwB,OAAO,CAACK,UAAU,GAAGa,aAAa,CAACqC,MAAM;IACzE,MAAMwE,QAAQ,GAAGvE,IAAI,CAAC2D,KAAK,CAACU,OAAO,GAAGJ,OAAO,CAAC;IAC9C,MAAMO,MAAM,GAAGxE,IAAI,CAACyE,IAAI,CAACH,QAAQ,GAAGL,OAAO,CAAC;IAC5C,IAAI1F,MAAM,GAAG,CAAC;IAEd,KAAK,IAAIuB,CAAC,GAAGyE,QAAQ,EAAEzE,CAAC,IAAI0E,MAAM,EAAE1E,CAAC,EAAE,EAAE;MACvCvB,MAAM,IAAIyB,IAAI,CAACI,GAAG,CAAC,EAAE,EAAE1C,aAAa,CAACoC,CAAC,CAAC,GAAG,EAAE,CAAC;IAC/C;IAEA,OAAOvB,MAAM,IAAIiG,MAAM,GAAGD,QAAQ,GAAG,CAAC,CAAC;EACzC,CAAC;EAED,MAAMhF,oBAAoB,GAAI3B,cAAc,IAAK;IAC/C,IAAI8G,YAAY,GAAG,CAAC;IACpB,MAAM7D,SAAS,GAAG,IAAI;IAEtB,KAAK,IAAIf,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGlC,cAAc,CAACmC,MAAM,EAAED,CAAC,EAAE,EAAE;MAC9C,IAAIE,IAAI,CAACC,GAAG,CAACrC,cAAc,CAACkC,CAAC,CAAC,CAAC,GAAGe,SAAS,EAAE;QAC3C6D,YAAY,EAAE;MAChB;IACF;IAEA,OAAQA,YAAY,GAAG9G,cAAc,CAACmC,MAAM,GAAI,GAAG;EACrD,CAAC;EAED,MAAMN,sBAAsB,GAAI7B,cAAc,IAAK;IACjD,MAAM+G,aAAa,GAAG3E,IAAI,CAAC2D,KAAK,CAAC3I,eAAe,CAACwB,OAAO,CAACK,UAAU,GAAG,GAAG,CAAC,CAAC,CAAC;IAC5E,MAAM+H,OAAO,GAAG,EAAE;IAElB,KAAK,IAAI9E,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGlC,cAAc,CAACmC,MAAM,GAAG4E,aAAa,EAAE7E,CAAC,IAAI6E,aAAa,EAAE;MAC7E,MAAME,OAAO,GAAGjH,cAAc,CAACkH,KAAK,CAAChF,CAAC,EAAEA,CAAC,GAAG6E,aAAa,CAAC;MAC1D,MAAMhG,KAAK,GAAGC,aAAa,CAACiG,OAAO,CAAC;MACpC,IAAIlG,KAAK,GAAG,CAAC,EAAEiG,OAAO,CAACR,IAAI,CAACzF,KAAK,CAAC;IACpC;IAEA,IAAIiG,OAAO,CAAC7E,MAAM,GAAG,CAAC,EAAE,OAAO,CAAC;IAEhC,IAAIgF,SAAS,GAAG,CAAC;IACjB,KAAK,IAAIjF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG8E,OAAO,CAAC7E,MAAM,EAAED,CAAC,EAAE,EAAE;MACvCiF,SAAS,IAAI/E,IAAI,CAACC,GAAG,CAAC2E,OAAO,CAAC9E,CAAC,CAAC,GAAG8E,OAAO,CAAC9E,CAAC,GAAG,CAAC,CAAC,CAAC;IACpD;IAEA,OAAOiF,SAAS,IAAIH,OAAO,CAAC7E,MAAM,GAAG,CAAC,CAAC;EACzC,CAAC;EAED,oBACEhH,OAAA;IAAKiM,SAAS,EAAC,2BAA2B;IAAAC,QAAA,gBACxClM,OAAA;MAAAkM,QAAA,EAAI;IAA+B;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,EACvCxL,qBAAqB,iBACpBd,OAAA;MAAKiM,SAAS,EAAC,oBAAoB;MAAAC,QAAA,gBACjClM,OAAA;QAAAkM,QAAA,EAAI;MAAqB;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eAC9BtM,OAAA;QAAAkM,QAAA,EAAG;MAAwE;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAC/EtM,OAAA;QAAKiM,SAAS,EAAC,yBAAyB;QAAAC,QAAA,gBACtClM,OAAA;UAAAkM,QAAA,EAAG;QAAgC;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAG,CAAC,eACvCtM,OAAA;UAAAkM,QAAA,EAAG;QAAiD;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAG,CAAC,eACxDtM,OAAA;UAAAkM,QAAA,EAAG;QAA+B;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAG,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACnC,CAAC,eACNtM,OAAA;QAAQiM,SAAS,EAAC,mBAAmB;QAACM,OAAO,EAAE5J,cAAe;QAAAuJ,QAAA,EAAC;MAE/D;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACN,CACN,EACA9L,kBAAkB,IAAI,CAACE,cAAc,iBACpCV,OAAA;MAAKiM,SAAS,EAAC,sBAAsB;MAAAC,QAAA,gBACnClM,OAAA;QAAKiM,SAAS,EAAC,eAAe;QAAAC,QAAA,gBAC5BlM,OAAA,CAACF,MAAM;UACLmD,KAAK,EAAE,IAAK;UACZuJ,GAAG,EAAErM,SAAU;UACfsM,gBAAgB,EAAC,YAAY;UAC7BR,SAAS,EAAC,QAAQ;UAClBS,gBAAgB,EAAE;YAChBC,UAAU,EAAE,MAAM;YAClBC,KAAK,EAAE,GAAG;YACVC,MAAM,EAAE;UACV;QAAE;UAAAV,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACH,CAAC,eACFtM,OAAA;UAAKiM,SAAS,EAAC,mBAAmB;UAAAC,QAAA,gBAChClM,OAAA;YAAKiM,SAAS,EAAE,oBAAoB7L,YAAY,GAAG,QAAQ,GAAG,EAAE,EAAG;YAAA8L,QAAA,EAChE9L,YAAY,GAAG,eAAe,GAAG;UAAkB;YAAA+L,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACjD,CAAC,eACNtM,OAAA;YAAKiM,SAAS,EAAE,oBAAoB1K,aAAa,CAACE,WAAW,GAAG,GAAG,GAAG,QAAQ,GAAG,EAAE,EAAG;YAAAyK,QAAA,EACnF3K,aAAa,CAACE,WAAW,GAAG,GAAG,GAAG,cAAc,GAAG;UAAc;YAAA0K,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAC/D,CAAC,eACNtM,OAAA;YAAKiM,SAAS,EAAC,kBAAkB;YAAAC,QAAA,GAAC,qBACb,EAACjF,IAAI,CAAC6F,KAAK,CAACvL,aAAa,CAACG,gBAAgB,CAAC,EAAC,GACjE;UAAA;YAAAyK,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAK,CAAC;QAAA;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACH,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACH,CAAC,eACNtM,OAAA;QAAKiM,SAAS,EAAC,wBAAwB;QAAAC,QAAA,gBACrClM,OAAA;UAAAkM,QAAA,EAAI;QAAyB;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eAClCtM,OAAA;UAAKiM,SAAS,EAAC,eAAe;UAAAC,QAAA,gBAC5BlM,OAAA;YAAKiM,SAAS,EAAC,QAAQ;YAAAC,QAAA,gBACrBlM,OAAA;cAAMiM,SAAS,EAAC,cAAc;cAAAC,QAAA,EAAC;YAAa;cAAAC,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAM,CAAC,eACnDtM,OAAA;cAAKiM,SAAS,EAAC,sBAAsB;cAAAC,QAAA,eACnClM,OAAA;gBACEiM,SAAS,EAAC,YAAY;gBACtBc,KAAK,EAAE;kBAAEH,KAAK,EAAE,GAAG3F,IAAI,CAACmB,GAAG,CAAC,GAAG,EAAE7G,aAAa,CAACE,WAAW,GAAG,GAAG,CAAC;gBAAI;cAAE;gBAAA0K,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OACnE;YAAC;cAAAH,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OACJ,CAAC;UAAA;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACH,CAAC,eACNtM,OAAA;YAAKiM,SAAS,EAAC,QAAQ;YAAAC,QAAA,gBACrBlM,OAAA;cAAMiM,SAAS,EAAC,cAAc;cAAAC,QAAA,EAAC;YAAiB;cAAAC,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAM,CAAC,eACvDtM,OAAA;cAAKiM,SAAS,EAAC,sBAAsB;cAAAC,QAAA,eACnClM,OAAA;gBACEiM,SAAS,EAAC,kBAAkB;gBAC5Bc,KAAK,EAAE;kBAAEH,KAAK,EAAE,GAAG3F,IAAI,CAACmB,GAAG,CAAC,GAAG,EAAE7G,aAAa,CAACI,oBAAoB,GAAG,GAAG,CAAC;gBAAI;cAAE;gBAAAwK,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAC5E;YAAC;cAAAH,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OACJ,CAAC;UAAA;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACH,CAAC,eACNtM,OAAA;YAAKiM,SAAS,EAAC,QAAQ;YAAAC,QAAA,gBACrBlM,OAAA;cAAMiM,SAAS,EAAC,cAAc;cAAAC,QAAA,EAAC;YAAkB;cAAAC,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAM,CAAC,eACxDtM,OAAA;cAAKiM,SAAS,EAAC,sBAAsB;cAAAC,QAAA,eACnClM,OAAA;gBACEiM,SAAS,EAAC,wBAAwB;gBAClCc,KAAK,EAAE;kBAAEH,KAAK,EAAE,GAAGrL,aAAa,CAACG,gBAAgB;gBAAI;cAAE;gBAAAyK,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OACnD;YAAC;cAAAH,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OACJ,CAAC;UAAA;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACH,CAAC,eACNtM,OAAA;YAAKiM,SAAS,EAAC,QAAQ;YAAAC,QAAA,gBACrBlM,OAAA;cAAMiM,SAAS,EAAC,cAAc;cAAAC,QAAA,EAAC;YAAgB;cAAAC,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAM,CAAC,eACtDtM,OAAA;cAAMiM,SAAS,EAAC,cAAc;cAAAC,QAAA,EAAE3K,aAAa,CAACK;YAAc;cAAAuK,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAO,CAAC;UAAA;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACjE,CAAC;QAAA;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACH,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACH,CAAC,eACNtM,OAAA;QAAKiM,SAAS,EAAC,oBAAoB;QAAAC,QAAA,eACjClM,OAAA;UAAKiM,SAAS,EAAC,gBAAgB;UAAAC,QAAA,gBAC7BlM,OAAA;YAAKiM,SAAS,EAAC,mBAAmB;YAAAC,QAAA,gBAChClM,OAAA;cAAAkM,QAAA,EAAM;YAAwB;cAAAC,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAM,CAAC,eACrCtM,OAAA;cAAMiM,SAAS,EAAC,mBAAmB;cAAAC,QAAA,GAAC,cAAY,EAACjF,IAAI,CAAC2D,KAAK,CAACxJ,UAAU,CAAC,EAAC,IAAE;YAAA;cAAA+K,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAM,CAAC;UAAA;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAC9E,CAAC,eACNtM,OAAA;YAAKiM,SAAS,EAAC,oBAAoB;YAACe,GAAG,EAAC,KAAK;YAAAd,QAAA,EAC1ChL,UAAU,IAAI;UAA4B;YAAAiL,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACxC,CAAC,eACNtM,OAAA;YAAKiM,SAAS,EAAC,gBAAgB;YAAAC,QAAA,GAC5B3K,aAAa,CAACG,gBAAgB,GAAG,EAAE,iBAClC1B,OAAA;cAAKiM,SAAS,EAAC,iBAAiB;cAAAC,QAAA,EAAC;YAEjC;cAAAC,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAK,CACN,EACA/K,aAAa,CAACI,oBAAoB,GAAG,GAAG,iBACvC3B,OAAA;cAAKiM,SAAS,EAAC,iBAAiB;cAAAC,QAAA,EAAC;YAEjC;cAAAC,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAK,CACN;UAAA;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACE,CAAC;QAAA;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACH;MAAC;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACH,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACH,CACN,EACA5L,cAAc,iBACbV,OAAA;MAAKiM,SAAS,EAAC,qBAAqB;MAAAC,QAAA,gBAClClM,OAAA;QAAAkM,QAAA,EAAI;MAAiB;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eAC1BtM,OAAA;QAAAkM,QAAA,EAAG;MAA0E;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eACjFtM,OAAA;QAAKiM,SAAS,EAAC,mBAAmB;QAAAC,QAAA,gBAChClM,OAAA;UAAAkM,QAAA,GAAG,oBAAkB,EAAC9K,UAAU;QAAA;UAAA+K,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eACrCtM,OAAA;UAAAkM,QAAA,GAAG,2BAAyB,EAACjF,IAAI,CAAC6F,KAAK,CAACvL,aAAa,CAACG,gBAAgB,CAAC,EAAC,GAAC;QAAA;UAAAyK,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAG,CAAC,eAC7EtM,OAAA;UAAAkM,QAAA,GAAG,4BAA0B,EAAC3K,aAAa,CAACK,cAAc;QAAA;UAAAuK,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAC5D,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACH,CACN;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV,CAAC;AAACpM,EAAA,CAjkBID,cAAc;AAAAgN,EAAA,GAAdhN,cAAc;AAmkBpB,eAAeA,cAAc;AAAC,IAAAgN,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}