{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\HP\\\\Desktop\\\\continous-authentication1\\\\continous-authentication1\\\\continous-authentication\\\\continous-authentication\\\\src\\\\ContinuousAuth.js\",\n  _s = $RefreshSig$();\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\n// import * as faceapi from \"face-api.js\";\n// import Webcam from \"react-webcam\";\n// import axios from \"axios\";\n// import \"./ContinuousAuth.css\";\n\n// const ContinuousAuth = () => {\n//   const webcamRef = useRef(null);\n//   const [faceDetected, setFaceDetected] = useState(false);\n//   const [soundDetected, setSoundDetected] = useState(false);\n//   const [currentImage, setCurrentImage] = useState(null);\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\n//   const [examTerminated, setExamTerminated] = useState(false);\n//   const [mediaStream, setMediaStream] = useState(null);\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\n\n//   useEffect(() => {\n//     const loadModels = async () => {\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\n//       console.log(\"Face Detection Model Loaded\");\n//     };\n//     loadModels();\n//   }, []);\n\n//   const getPermissions = async () => {\n//     try {\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\n//       setMediaStream(stream);\n//       setPermissionsGranted(true);\n//       setShowPermissionMessage(false);\n//       fetchIpAddress(); // Call to fetch IP address when permissions are granted\n//     } catch (error) {\n//       alert(\"Please allow access to camera and microphone.\");\n//       setShowPermissionMessage(true);\n//     }\n//   };\n\n//   const fetchIpAddress = async () => {\n//     try {\n//       const response = await fetch(\"https://api.ipify.org?format=json\");\n//       const data = await response.json();\n//       alert(`Your IP Address: ${data.ip}`);\n//     } catch (error) {\n//       console.error(\"Error fetching IP address:\", error);\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (mediaStream) {\n//       const tracks = mediaStream.getTracks();\n//       tracks.forEach((track) => {\n//         track.enabled = true;\n//       });\n//     }\n//   }, [mediaStream]);\n\n//   const detectFace = async () => {\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\n//       const video = webcamRef.current.video;\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n//       const isFacePresent = detections.length > 0;\n//       setFaceDetected(isFacePresent);\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       const interval = setInterval(detectFace, 1000);\n//       return () => clearInterval(interval);\n//     }\n//   }, [permissionsGranted]);\n\n//   useEffect(() => {\n//     if (noFaceDuration >= 15) {\n//       alert(\"‚ö†Ô∏è Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\n//       setNoFaceDuration(0);\n//     }\n//   }, [noFaceDuration]);\n\n//   const detectSound = useCallback(() => {\n//     if (!mediaStream) return;\n\n//     const audioContext = new AudioContext();\n//     const analyser = audioContext.createAnalyser();\n//     const source = audioContext.createMediaStreamSource(mediaStream);\n//     source.connect(analyser);\n//     analyser.fftSize = 256;\n//     const bufferLength = analyser.frequencyBinCount;\n//     const dataArray = new Uint8Array(bufferLength);\n\n//     const checkSound = () => {\n//       analyser.getByteFrequencyData(dataArray);\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\n//       setSoundDetected(volume > 10);\n//       requestAnimationFrame(checkSound);\n//     };\n//     checkSound();\n//   }, [mediaStream]);\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       detectSound();\n//     }\n//   }, [permissionsGranted, detectSound]);\n\n//   return (\n//     <div className=\"continuous-auth-container\">\n//       <h2>Continuous Authentication</h2>\n\n//       {showPermissionMessage && (\n//         <div className=\"permission-message\">\n//           <p>Please allow access to your camera and microphone to start the exam.</p>\n//           <button onClick={getPermissions}>Allow Camera and Microphone</button>\n//         </div>\n//       )}\n\n//       {permissionsGranted ? (\n//         <>\n//           <Webcam\n//             audio={true}\n//             ref={webcamRef}\n//             screenshotFormat=\"image/jpeg\"\n//             className=\"webcam\"\n//             videoConstraints={{\n//               facingMode: \"user\",\n//               width: 720,\n//               height: 400,\n//             }}\n//           />\n//           <p>Camera and microphone are active for proctoring.</p>\n\n//           <div className=\"status-buttons-container\">\n//             <div className=\"status-buttons\">\n//               <button className={faceDetected ? \"detected-btn\" : \"not-detected-btn\"}>\n//                 {faceDetected ? \"Face Detected ‚úÖ\" : \"No Face Detected ‚ùå\"}\n//               </button>\n//               <button className={soundDetected ? \"detected-btn\" : \"not-detected-btn\"}>\n//                 {soundDetected ? \"Sound Detected üîä\" : \"No Sound Detected üîá\"}\n//               </button>\n//             </div>\n\n//             <div className=\"captured-images\">\n//               {currentImage && <img src={currentImage} alt=\"Captured\" className=\"small-image\" />}\n//             </div>\n//           </div>\n//         </>\n//       ) : (\n//         <p>Waiting for camera and microphone access...</p>\n//       )}\n\n//       {examTerminated && <p className=\"mismatch-count\">Exam Terminated due to 3 mismatches.</p>}\n//     </div>\n//   );\n// };\n\n// export default ContinuousAuth;\n\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\n// import * as faceapi from \"face-api.js\";\n// import Webcam from \"react-webcam\";\n// import \"./ContinuousAuth.css\";\n\n// const ContinuousAuth = () => {\n//   const webcamRef = useRef(null);\n//   const [faceDetected, setFaceDetected] = useState(false);\n//   const [soundDetected, setSoundDetected] = useState(false);\n//   const [currentImage, setCurrentImage] = useState(null);\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\n//   const [examTerminated, setExamTerminated] = useState(false);\n//   const [mediaStream, setMediaStream] = useState(null);\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\n//   const [transcript, setTranscript] = useState(\"\");\n//   const [violations, setViolations] = useState(0);\n//   const recognitionRef = useRef(null);\n\n//   // ŸÜÿ∏ÿßŸÖ ŸÉÿ¥ŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\n//   const [multipleVoicesDetected, setMultipleVoicesDetected] = useState(false);\n//   const audioContextRef = useRef(null);\n//   const analyserRef = useRef(null);\n//   const voiceProfileRef = useRef({\n//     baseline: null,\n//     lastAlert: 0,\n//     active: false\n//   });\n\n//   useEffect(() => {\n//     const loadModels = async () => {\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\n//       console.log(\"Face Detection Model Loaded\");\n//     };\n//     loadModels();\n//   }, []);\n\n//   const getPermissions = async () => {\n//     try {\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\n//       setMediaStream(stream);\n//       setPermissionsGranted(true);\n//       setShowPermissionMessage(false);\n//       initializeSpeechRecognition();\n//       setupVoiceAnalysis(stream);\n//     } catch (error) {\n//       alert(\"Please allow access to camera and microphone.\");\n//       setShowPermissionMessage(true);\n//     }\n//   };\n\n//   // ŸÜÿ∏ÿßŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\n//   const setupVoiceAnalysis = (stream) => {\n//     try {\n//       audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n//       analyserRef.current = audioContextRef.current.createAnalyser();\n//       analyserRef.current.fftSize = 4096;\n\n//       const source = audioContextRef.current.createMediaStreamSource(stream);\n//       source.connect(analyserRef.current);\n\n//       // ÿ•ŸÜÿ¥ÿßÿ° ÿ®ÿµŸÖÿ© ÿµŸàÿ™Ÿäÿ© ÿ£ŸàŸÑŸäÿ© ÿ®ÿπÿØ 3 ÿ´ŸàÿßŸÜŸä\n//       setTimeout(() => {\n//         voiceProfileRef.current.baseline = createVoiceProfile();\n//         voiceProfileRef.current.active = true;\n//       }, 3000);\n\n//       const analyzeVoice = () => {\n//         if (!voiceProfileRef.current.active) {\n//           requestAnimationFrame(analyzeVoice);\n//           return;\n//         }\n\n//         const currentProfile = createVoiceProfile();\n//         const isMultiple = compareVoiceProfiles(voiceProfileRef.current.baseline, currentProfile);\n\n//         if (isMultiple && Date.now() - voiceProfileRef.current.lastAlert > 5000) {\n//           setMultipleVoicesDetected(true);\n//           voiceProfileRef.current.lastAlert = Date.now();\n//         } else {\n//           setMultipleVoicesDetected(false);\n//         }\n\n//         requestAnimationFrame(analyzeVoice);\n//       };\n\n//       analyzeVoice();\n//     } catch (error) {\n//       console.error(\"Voice analysis error:\", error);\n//     }\n//   };\n\n//   const createVoiceProfile = () => {\n//     const bufferLength = analyserRef.current.frequencyBinCount;\n//     const dataArray = new Float32Array(bufferLength);\n//     analyserRef.current.getFloatFrequencyData(dataArray);\n\n//     const profile = {\n//       lowRange: 0,    // 85-300Hz\n//       midRange: 0,    // 300-1000Hz\n//       highRange: 0,   // 1000-4000Hz\n//       peakCount: 0,\n//       totalEnergy: 0\n//     };\n\n//     for (let i = 0; i < bufferLength; i++) {\n//       const freq = i * audioContextRef.current.sampleRate / analyserRef.current.fftSize;\n//       const value = Math.pow(10, dataArray[i]/20); // Convert dB to linear\n\n//       if (freq >= 85 && freq < 300) {\n//         profile.lowRange += value;\n//       } else if (freq >= 300 && freq < 1000) {\n//         profile.midRange += value;\n//       } else if (freq >= 1000 && freq < 4000) {\n//         profile.highRange += value;\n//       }\n\n//       if (dataArray[i] > -40) profile.peakCount++;\n//       profile.totalEnergy += value;\n//     }\n\n//     return profile;\n//   };\n\n//   const compareVoiceProfiles = (baseline, current) => {\n//     // ÿ≠ÿ≥ÿßÿ® ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ™ÿ∫Ÿäÿ± ŸÑŸÉŸÑ ŸÜÿ∑ÿßŸÇ ÿ™ÿ±ÿØÿØŸä\n//     const lowDiff = Math.abs(current.lowRange - baseline.lowRange) / baseline.lowRange;\n//     const midDiff = Math.abs(current.midRange - baseline.midRange) / baseline.midRange;\n//     const highDiff = Math.abs(current.highRange - baseline.highRange) / baseline.highRange;\n//     const energyDiff = Math.abs(current.totalEnergy - baseline.totalEnergy) / baseline.totalEnergy;\n//     const peakDiff = Math.abs(current.peakCount - baseline.peakCount);\n\n//     // ÿ¥ÿ±Ÿàÿ∑ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ©\n//     return (\n//       (lowDiff > 0.6 || midDiff > 0.6 || highDiff > 0.6) &&\n//       energyDiff > 0.4 &&\n//       peakDiff > 15\n//     );\n//   };\n\n//   const initializeSpeechRecognition = () => {\n//     const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n//     if (!SpeechRecognition) {\n//       console.error(\"Speech Recognition API not supported in this browser\");\n//       return;\n//     }\n\n//     recognitionRef.current = new SpeechRecognition();\n//     recognitionRef.current.continuous = true;\n//     recognitionRef.current.interimResults = false;\n//     recognitionRef.current.lang = \"ar-SA\";\n\n//     recognitionRef.current.onresult = (event) => {\n//       const last = event.results.length - 1;\n//       const text = event.results[last][0].transcript;\n//       setTranscript(text);\n//     };\n\n//     recognitionRef.current.onerror = (event) => {\n//       console.error(\"Speech recognition error\", event.error);\n//     };\n\n//     recognitionRef.current.start();\n//     recognitionRef.current.onend = () => {\n//       recognitionRef.current.start();\n//     };\n//   };\n\n//   useEffect(() => {\n//     if (mediaStream) {\n//       const tracks = mediaStream.getTracks();\n//       tracks.forEach((track) => {\n//         track.enabled = true;\n//       });\n//     }\n\n//     return () => {\n//       if (recognitionRef.current) {\n//         recognitionRef.current.stop();\n//       }\n//       if (audioContextRef.current) {\n//         audioContextRef.current.close();\n//       }\n//     };\n//   }, [mediaStream]);\n\n//   const detectFace = async () => {\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\n//       const video = webcamRef.current.video;\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n//       const isFacePresent = detections.length > 0;\n//       setFaceDetected(isFacePresent);\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       const interval = setInterval(detectFace, 1000);\n//       return () => clearInterval(interval);\n//     }\n//   }, [permissionsGranted]);\n\n//   useEffect(() => {\n//     if (noFaceDuration >= 15) {\n//       alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\n//       setNoFaceDuration(0);\n//     }\n//   }, [noFaceDuration]);\n\n//   const detectSound = useCallback(() => {\n//     if (!mediaStream) return;\n\n//     const audioContext = new AudioContext();\n//     const analyser = audioContext.createAnalyser();\n//     const source = audioContext.createMediaStreamSource(mediaStream);\n//     source.connect(analyser);\n//     analyser.fftSize = 256;\n//     const bufferLength = analyser.frequencyBinCount;\n//     const dataArray = new Uint8Array(bufferLength);\n\n//     const checkSound = () => {\n//       analyser.getByteFrequencyData(dataArray);\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\n//       setSoundDetected(volume > 10);\n//       requestAnimationFrame(checkSound);\n//     };\n//     checkSound();\n//   }, [mediaStream]);\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       detectSound();\n//     }\n//   }, [permissionsGranted, detectSound]);\n\n//   useEffect(() => {\n//     if (multipleVoicesDetected) {\n//       const newViolations = violations + 1;\n//       setViolations(newViolations);\n\n//       alert(`üö® MULTIPLE VOICES DETECTED! (Violation ${newViolations}/3)`);\n\n//       if (newViolations >= 3) {\n//         setExamTerminated(true);\n//       }\n//     }\n//   }, [multipleVoicesDetected]);\n\n//   return (\n//     <div className=\"continuous-auth-container\">\n//       <h2>Exam Proctoring System</h2>\n\n//       {showPermissionMessage && (\n//         <div className=\"permission-message\">\n//           <h3>Exam Proctoring Setup</h3>\n//           <p>This exam requires camera and microphone access for proctoring purposes.</p>\n//           <div className=\"permission-requirements\">\n//             <p>‚úì Face detection must be enabled</p>\n//             <p>‚úì Microphone must be active</p>\n//           </div>\n//           <button className=\"permission-button\" onClick={getPermissions}>\n//             Enable Camera & Microphone\n//           </button>\n//         </div>\n//       )}\n\n//       {permissionsGranted && !examTerminated && (\n//         <div className=\"monitoring-container\">\n//           <div className=\"video-section\">\n//             <Webcam\n//               audio={true}\n//               ref={webcamRef}\n//               screenshotFormat=\"image/jpeg\"\n//               className=\"webcam\"\n//               videoConstraints={{\n//                 facingMode: \"user\",\n//                 width: 480,\n//                 height: 360,\n//               }}\n//             />\n//             <div className=\"status-indicators\">\n//               <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\n//                 {faceDetected ? \"Face Detected\" : \"No Face Detected\"}\n//               </div>\n//               <div className={`status-indicator ${soundDetected ? \"active\" : \"\"}`}>\n//                 {soundDetected ? \"Sound Detected\" : \"No Sound Detected\"}\n//               </div>\n//               {multipleVoicesDetected && (\n//                 <div className=\"status-indicator warning\">\n//                   Multiple Voices Detected!\n//                 </div>\n//               )}\n//             </div>\n//           </div>\n\n//           <div className=\"transcript-section\">\n//             <div className=\"transcript-box\">\n//               <div className=\"transcript-header\">\n//                 <span>Arabic Speech Transcript</span>\n//                 <span className=\"violation-counter\">Violations: {violations}/3</span>\n//               </div>\n//               <div className=\"transcript-content\" dir=\"rtl\">\n//                 {transcript || \"Waiting for audio input...\"}\n//               </div>\n//               <div className={`voice-detection-status ${multipleVoicesDetected ? \"multiple\" : \"\"}`}>\n//                 {multipleVoicesDetected \n//                   ? \"Multiple voices detected!\" \n//                   : \"Voice analysis active\"}\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//       )}\n\n//       {examTerminated && (\n//         <div className=\"termination-message\">\n//           <h3>‚úñ Exam Terminated</h3>\n//           <p>Due to multiple violations detected. Please contact your instructor.</p>\n//           <p>Total violations: {violations}</p>\n//         </div>\n//       )}\n//     </div>\n//   );\n// };\n\n// export default ContinuousAuth;\n\n//////////////////////////////////////////////////////////////////////////////////// \n\nimport React, { useState, useEffect, useRef } from \"react\";\nimport * as faceapi from \"face-api.js\";\nimport Webcam from \"react-webcam\";\nimport \"./ContinuousAuth.css\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst ContinuousAuth = () => {\n  _s();\n  const webcamRef = useRef(null);\n  const [faceDetected, setFaceDetected] = useState(false);\n  const [soundDetected, setSoundDetected] = useState(false);\n  const [permissionsGranted, setPermissionsGranted] = useState(false);\n  const [examTerminated, setExamTerminated] = useState(false);\n  const [mediaStream, setMediaStream] = useState(null);\n  const [showPermissionMessage, setShowPermissionMessage] = useState(true);\n  const [noFaceDuration, setNoFaceDuration] = useState(0);\n  const [transcript, setTranscript] = useState(\"\");\n  const [violations, setViolations] = useState(0);\n  const recognitionRef = useRef(null);\n\n  // ÿ™ŸáŸäÿ¶ÿ© ŸÜŸÖÿßÿ∞ÿ¨ ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑŸàÿ¨Ÿá\n  useEffect(() => {\n    const loadModels = async () => {\n      await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\n    };\n    loadModels();\n  }, []);\n\n  // ÿ∑ŸÑÿ® ÿßŸÑÿ£ÿ∞ŸàŸÜÿßÿ™\n  const getPermissions = async () => {\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({\n        video: true,\n        audio: true\n      });\n      setMediaStream(stream);\n      setPermissionsGranted(true);\n      setShowPermissionMessage(false);\n      initializeSpeechRecognition();\n    } catch (error) {\n      alert(\"Ÿäÿ¨ÿ® ÿßŸÑÿ≥ŸÖÿßÿ≠ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÉÿßŸÖŸäÿ±ÿß ŸàÿßŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ\");\n      setShowPermissionMessage(true);\n    }\n  };\n\n  // ŸÜÿ∏ÿßŸÖ ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑŸÉŸÑÿßŸÖ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\n  const initializeSpeechRecognition = () => {\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!SpeechRecognition) {\n      alert(\"ŸÖÿ™ÿµŸÅÿ≠ŸÉ ŸÑÿß ŸäÿØÿπŸÖ ŸÖŸäÿ≤ÿ© ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑÿµŸàÿ™\");\n      return;\n    }\n    recognitionRef.current = new SpeechRecognition();\n    recognitionRef.current.continuous = true;\n    recognitionRef.current.interimResults = true;\n    recognitionRef.current.lang = \"ar-SA\";\n    recognitionRef.current.maxAlternatives = 1;\n    recognitionRef.current.onresult = event => {\n      let interim = \"\";\n      let final = \"\";\n      for (let i = event.resultIndex; i < event.results.length; i++) {\n        const transcript = event.results[i][0].transcript;\n        if (event.results[i].isFinal) {\n          final += transcript;\n        } else {\n          interim += transcript;\n        }\n      }\n\n      // ÿ™ÿ≠ÿØŸäÿ´ ÿßŸÑŸÜÿµ ŸÖÿπ ÿßŸÑÿ≠ŸÅÿßÿ∏ ÿπŸÑŸâ ÿ¢ÿÆÿ± 10 ÿ¨ŸÖŸÑ ŸÅŸÇÿ∑\n      setTranscript(prev => {\n        const updated = prev + final;\n        const sentences = updated.split(/[.!ÿü]\\s+/);\n        return sentences.slice(-10).join(\". \") + (interim ? ` (${interim})` : \"\");\n      });\n    };\n    recognitionRef.current.onerror = event => {\n      if (event.error === \"no-speech\") {\n        console.log(\"ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿ£Ÿä ŸÉŸÑÿßŸÖ\");\n      } else {\n        console.error(\"ÿÆÿ∑ÿ£ ŸÅŸä ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑÿµŸàÿ™:\", event.error);\n      }\n    };\n    recognitionRef.current.start();\n    recognitionRef.current.onend = () => {\n      recognitionRef.current.start();\n    };\n  };\n\n  // ŸÉÿ¥ŸÅ ÿßŸÑŸàÿ¨Ÿá\n  const detectFace = async () => {\n    var _webcamRef$current, _webcamRef$current$vi;\n    if (((_webcamRef$current = webcamRef.current) === null || _webcamRef$current === void 0 ? void 0 : (_webcamRef$current$vi = _webcamRef$current.video) === null || _webcamRef$current$vi === void 0 ? void 0 : _webcamRef$current$vi.readyState) === 4) {\n      const detections = await faceapi.detectAllFaces(webcamRef.current.video, new faceapi.TinyFaceDetectorOptions());\n      setFaceDetected(detections.length > 0);\n      setNoFaceDuration(prev => detections.length > 0 ? 0 : prev + 1);\n    }\n  };\n\n  // ÿßŸÑÿ™ÿ£ÿ´Ÿäÿ±ÿßÿ™ ÿßŸÑÿ¨ÿßŸÜÿ®Ÿäÿ©\n  useEffect(() => {\n    if (permissionsGranted) {\n      const faceInterval = setInterval(detectFace, 1000);\n      return () => clearInterval(faceInterval);\n    }\n  }, [permissionsGranted]);\n  useEffect(() => {\n    if (noFaceDuration >= 15) {\n      alert(\"‚ö† ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑŸàÿ¨Ÿá ŸÑŸÖÿØÿ© 15 ÿ´ÿßŸÜŸäÿ©\");\n      setNoFaceDuration(0);\n    }\n  }, [noFaceDuration]);\n\n  // ÿßŸÑÿ™ŸÜÿ∏ŸäŸÅ\n  useEffect(() => {\n    return () => {\n      if (recognitionRef.current) {\n        recognitionRef.current.stop();\n      }\n      if (mediaStream) {\n        mediaStream.getTracks().forEach(track => track.stop());\n      }\n    };\n  }, [mediaStream]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"continuous-auth-container\",\n    children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n      children: \"\\u0646\\u0638\\u0627\\u0645 \\u0645\\u0631\\u0627\\u0642\\u0628\\u0629 \\u0627\\u0644\\u0627\\u062E\\u062A\\u0628\\u0627\\u0631\\u0627\\u062A\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 647,\n      columnNumber: 7\n    }, this), showPermissionMessage && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"permission-message\",\n      children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n        children: \"\\u0625\\u0639\\u062F\\u0627\\u062F\\u0627\\u062A \\u0645\\u0631\\u0627\\u0642\\u0628\\u0629 \\u0627\\u0644\\u0627\\u062E\\u062A\\u0628\\u0627\\u0631\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 651,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n        className: \"permission-button\",\n        onClick: getPermissions,\n        children: \"\\u062A\\u0641\\u0639\\u064A\\u0644 \\u0627\\u0644\\u0643\\u0627\\u0645\\u064A\\u0631\\u0627 \\u0648\\u0627\\u0644\\u0645\\u064A\\u0643\\u0631\\u0648\\u0641\\u0648\\u0646\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 652,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 650,\n      columnNumber: 9\n    }, this), permissionsGranted && !examTerminated && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"monitoring-container\",\n      children: [/*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"video-section\",\n        children: [/*#__PURE__*/_jsxDEV(Webcam, {\n          ref: webcamRef,\n          className: \"webcam\",\n          videoConstraints: {\n            facingMode: \"user\"\n          }\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 661,\n          columnNumber: 13\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"status-indicators\",\n          children: /*#__PURE__*/_jsxDEV(\"div\", {\n            className: `status-indicator ${faceDetected ? \"active\" : \"\"}`,\n            children: faceDetected ? \"ÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑŸàÿ¨Ÿá\" : \"ŸÑÿß ŸäŸàÿ¨ÿØ Ÿàÿ¨Ÿá\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 667,\n            columnNumber: 15\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 666,\n          columnNumber: 13\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 660,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"transcript-section\",\n        children: /*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"transcript-box\",\n          children: [/*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"transcript-header\",\n            children: /*#__PURE__*/_jsxDEV(\"span\", {\n              children: \"\\u0646\\u0635 \\u0627\\u0644\\u062A\\u0639\\u0631\\u0641 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0643\\u0644\\u0627\\u0645\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 676,\n              columnNumber: 17\n            }, this)\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 675,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"transcript-content\",\n            dir: \"rtl\",\n            children: transcript || \"ŸÅŸä ÿßŸÜÿ™ÿ∏ÿßÿ± ÿßŸÑŸÖÿØÿÆŸÑÿßÿ™ ÿßŸÑÿµŸàÿ™Ÿäÿ©...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 678,\n            columnNumber: 15\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 674,\n          columnNumber: 13\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 673,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 659,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 646,\n    columnNumber: 5\n  }, this);\n};\n_s(ContinuousAuth, \"TE8+ZyGnCkRkUwPcrtDfSOsi0V0=\");\n_c = ContinuousAuth;\nexport default ContinuousAuth;\n\n///////////////////////////////////////////////////////////////////////////////////////////////// \n\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\n// import * as faceapi from \"face-api.js\";\n// import Webcam from \"react-webcam\";\n// import \"./ContinuousAuth.css\";\n\n// const ContinuousAuth = () => {\n//   const webcamRef = useRef(null);\n//   const [faceDetected, setFaceDetected] = useState(false);\n//   const [soundDetected, setSoundDetected] = useState(false);\n//   const [currentImage, setCurrentImage] = useState(null);\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\n//   const [examTerminated, setExamTerminated] = useState(false);\n//   const [mediaStream, setMediaStream] = useState(null);\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\n//   const [transcript, setTranscript] = useState(\"\");\n//   const [violations, setViolations] = useState(0);\n\n//   // ŸÇÿßÿ¶ŸÖÿ© ÿ®ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿ≠ÿ∏Ÿàÿ±ÿ©\n//   const forbiddenWords = [\n//     \"ÿ∫ÿ¥\", \"ŸÜÿ≥ÿÆ\",\"ŸÖÿ≥ÿßÿπÿØÿ©\",     \n//     \"ÿßŸÑÿ≥ÿ§ÿßŸÑ\", \"ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ©\", \"ÿ≠ŸÑ\",\"ÿÆÿ∑Ÿàÿ©\",        \n//     \"ŸÜÿµŸäÿ≠ÿ©\",\"ŸÖÿ¥ÿßÿ±ŸÉÿ©\",\"ÿ±ÿ≥ÿßŸÑÿ©\",    \n//     \"ÿ•ÿ¥ÿßÿ±ÿ©\",\"ÿßÿ≥ÿ™ŸÅŸáÿßŸÖ\",\"ÿÆÿ∑ÿ£\",         \n//     \"ÿµÿ≠Ÿäÿ≠\",\"ŸÖÿπÿßŸÉ\",\"ÿßÿ±ÿ≥ŸÑ\",       \n//     \"ÿßÿ≥ÿ™ŸÑŸÖ\",\"ÿßÿ¨ÿßŸàÿ®ŸÉ\",\"ÿ®ÿ≥ÿ±ÿπÿ©\",       \n//     \"ÿ¥Ÿà\",\"ŸÉŸäŸÅ\",         \n//   ];\n//   const [forbiddenCount, setForbiddenCount] = useState(0); // ÿπÿØÿßÿØ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿ≠ÿ∏Ÿàÿ±ÿ©\n//   const detectedForbiddenWords = useRef(new Set()); // ŸÖÿ¨ŸÖŸàÿπÿ© ÿ™ÿÆÿ≤ŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿ≠ÿ∏Ÿàÿ±ÿ© ÿßŸÑŸÖŸÉÿ™ÿ¥ŸÅÿ©\n\n//   const recognitionRef = useRef(null);\n\n//   useEffect(() => {\n//     const loadModels = async () => {\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\n//       console.log(\"Face Detection Model Loaded\");\n//     };\n//     loadModels();\n//   }, []);\n\n//   const getPermissions = async () => {\n//     try {\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\n//       setMediaStream(stream);\n//       setPermissionsGranted(true);\n//       setShowPermissionMessage(false);\n//       initializeSpeechRecognition();\n//     } catch (error) {\n//       alert(\"Please allow access to camera and microphone.\");\n//       setShowPermissionMessage(true);\n//     }\n//   };\n\n//   const initializeSpeechRecognition = () => {\n//     const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n//     if (!SpeechRecognition) {\n//       console.error(\"Speech Recognition API not supported in this browser\");\n//       return;\n//     }\n//     recognitionRef.current = new SpeechRecognition();\n//     recognitionRef.current.continuous = true;\n//     recognitionRef.current.interimResults = false;\n//     recognitionRef.current.lang = \"ar-SA\";\n\n//     recognitionRef.current.onresult = (event) => {\n//       const last = event.results.length - 1;\n//       const text = event.results[last][0].transcript;\n//       console.log(\"Recognized Text:\", text); // ŸÑŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿßŸÑŸÜÿµŸàÿµ ÿßŸÑŸÖÿØÿÆŸÑÿ©\n//       setTranscript(text);\n\n//       // ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿ≠ÿ∏Ÿàÿ±ÿ©\n//       checkForbiddenWords(text);\n//     };\n\n//     recognitionRef.current.onerror = (event) => {\n//       console.error(\"Speech recognition error\", event.error);\n//     };\n\n//     recognitionRef.current.start();\n//     recognitionRef.current.onend = () => {\n//       recognitionRef.current.start();\n//     };\n//   };\n\n//   // ÿØÿßŸÑÿ© ŸÑŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿ≠ÿ∏Ÿàÿ±ÿ©\n//   const checkForbiddenWords = (text) => {\n//     forbiddenWords.forEach((word) => {\n//       if (text.includes(word)) {\n//         // ÿ•ÿ∞ÿß ŸÑŸÖ ÿ™ŸÉŸÜ ÿßŸÑŸÉŸÑŸÖÿ© ŸÇÿØ ÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅŸáÿß ŸÖŸÜ ŸÇÿ®ŸÑ\n//         if (!detectedForbiddenWords.current.has(word)) {\n//           detectedForbiddenWords.current.add(word); // ÿ•ÿ∂ÿßŸÅÿ© ÿßŸÑŸÉŸÑŸÖÿ© ÿ•ŸÑŸâ ÿßŸÑŸÖÿ¨ŸÖŸàÿπÿ©\n//           const newCount = detectedForbiddenWords.current.size; // ÿ≠ÿ≥ÿßÿ® ÿßŸÑÿπÿØÿØ ÿßŸÑÿ¨ÿØŸäÿØ\n//           setForbiddenCount(newCount); // ÿ™ÿ≠ÿØŸäÿ´ ÿßŸÑÿπÿØÿßÿØ\n//           console.log(`New forbidden word detected: ${word} (Total: ${newCount})`); // ŸÑŸÑÿ™ÿ≠ŸÇŸÇ\n\n//           // ÿ•ÿ∞ÿß ŸàÿµŸÑ ÿßŸÑÿπÿØÿßÿØ ÿ•ŸÑŸâ 3\n//           if (newCount >= 3) {\n//             alert(\"‚ö†Ô∏è ÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ 3 ŸÉŸÑŸÖÿßÿ™ ŸÖÿ≠ÿ∏Ÿàÿ±ÿ© ŸÖÿÆÿ™ŸÑŸÅÿ©! ÿ≥Ÿäÿ™ŸÖ ÿ•ŸÜŸáÿßÿ° ÿßŸÑÿßŸÖÿ™ÿ≠ÿßŸÜ.\");\n//             terminateExam();\n//           }\n//         }\n//       }\n//     });\n//   };\n\n//   // ÿØÿßŸÑÿ© ŸÑÿ•ŸÜŸáÿßÿ° ÿßŸÑÿßŸÖÿ™ÿ≠ÿßŸÜ Ÿàÿ•ÿ∫ŸÑÿßŸÇ ÿßŸÑÿµŸÅÿ≠ÿ©\n//   const terminateExam = () => {\n//     setExamTerminated(true);\n//     alert(\"‚úñ ÿßŸÑÿßŸÖÿ™ÿ≠ÿßŸÜ ÿ™ŸàŸÇŸÅ ÿ®ÿ≥ÿ®ÿ® ÿßŸÜÿ™ŸáÿßŸÉÿßÿ™ ŸÖÿ™ÿπÿØÿØÿ©!\");\n//     window.close(); // ÿ•ÿ∫ŸÑÿßŸÇ ÿßŸÑÿµŸÅÿ≠ÿ©\n//   };\n\n//   const detectFace = async () => {\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\n//       const video = webcamRef.current.video;\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n//       const isFacePresent = detections.length > 0;\n//       setFaceDetected(isFacePresent);\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       const interval = setInterval(detectFace, 1000);\n//       return () => clearInterval(interval);\n//     }\n//   }, [permissionsGranted]);\n\n//   useEffect(() => {\n//     if (noFaceDuration >= 15) {\n//       alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\n//       setNoFaceDuration(0);\n//     }\n//   }, [noFaceDuration]);\n\n//   const detectSound = useCallback(() => {\n//     if (!mediaStream) return;\n//     const audioContext = new AudioContext();\n//     const analyser = audioContext.createAnalyser();\n//     const source = audioContext.createMediaStreamSource(mediaStream);\n//     source.connect(analyser);\n//     analyser.fftSize = 256;\n//     const bufferLength = analyser.frequencyBinCount;\n//     const dataArray = new Uint8Array(bufferLength);\n//     const checkSound = () => {\n//       analyser.getByteFrequencyData(dataArray);\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\n//       setSoundDetected(volume > 10);\n//       requestAnimationFrame(checkSound);\n//     };\n//     checkSound();\n//   }, [mediaStream]);\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       detectSound();\n//     }\n//   }, [permissionsGranted, detectSound]);\n\n//   return (\n//     <div className=\"continuous-auth-container\">\n//       <h2>Exam Proctoring System</h2>\n//       {showPermissionMessage && (\n//         <div className=\"permission-message\">\n//           <h3>Exam Proctoring Setup</h3>\n//           <p>This exam requires camera and microphone access for proctoring purposes.</p>\n//           <div className=\"permission-requirements\">\n//             <p>‚úì Face detection must be enabled</p>\n//             <p>‚úì Microphone must be active</p>\n//           </div>\n//           <button className=\"permission-button\" onClick={getPermissions}>\n//             Enable Camera & Microphone\n//           </button>\n//         </div>\n//       )}\n//       {permissionsGranted && !examTerminated && (\n//         <div className=\"monitoring-container\">\n//           <div className=\"video-section\">\n//             <Webcam\n//               audio={true}\n//               ref={webcamRef}\n//               screenshotFormat=\"image/jpeg\"\n//               className=\"webcam\"\n//               videoConstraints={{\n//                 facingMode: \"user\",\n//                 width: 480,\n//                 height: 360,\n//               }}\n//             />\n//             <div className=\"status-indicators\">\n//               <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\n//                 {faceDetected ? \"Face Detected\" : \"No Face Detected\"}\n//               </div>\n//               <div className={`status-indicator ${soundDetected ? \"active\" : \"\"}`}>\n//                 {soundDetected ? \"Sound Detected\" : \"No Sound Detected\"}\n//               </div>\n//             </div>\n//           </div>\n//           <div className=\"transcript-section\">\n//             <div className=\"transcript-box\">\n//               <div className=\"transcript-header\">\n//                 <span>Arabic Speech Transcript</span>\n//                 <span className=\"violation-counter\">Total Forbidden Words: {forbiddenCount}/3</span>\n//               </div>\n//               <div className=\"transcript-content\" dir=\"rtl\">\n//                 {transcript || \"Waiting for audio input...\"}\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//       )}\n//       {examTerminated && (\n//         <div className=\"termination-message\">\n//           <h3>‚úñ Exam Terminated</h3>\n//           <p>Due to multiple violations detected. Please contact your instructor.</p>\n//         </div>\n//       )}\n//     </div>\n//   );\n// };\n\n// export default ContinuousAuth;\nvar _c;\n$RefreshReg$(_c, \"ContinuousAuth\");","map":{"version":3,"names":["React","useState","useEffect","useRef","faceapi","Webcam","jsxDEV","_jsxDEV","ContinuousAuth","_s","webcamRef","faceDetected","setFaceDetected","soundDetected","setSoundDetected","permissionsGranted","setPermissionsGranted","examTerminated","setExamTerminated","mediaStream","setMediaStream","showPermissionMessage","setShowPermissionMessage","noFaceDuration","setNoFaceDuration","transcript","setTranscript","violations","setViolations","recognitionRef","loadModels","nets","tinyFaceDetector","loadFromUri","getPermissions","stream","navigator","mediaDevices","getUserMedia","video","audio","initializeSpeechRecognition","error","alert","SpeechRecognition","window","webkitSpeechRecognition","current","continuous","interimResults","lang","maxAlternatives","onresult","event","interim","final","i","resultIndex","results","length","isFinal","prev","updated","sentences","split","slice","join","onerror","console","log","start","onend","detectFace","_webcamRef$current","_webcamRef$current$vi","readyState","detections","detectAllFaces","TinyFaceDetectorOptions","faceInterval","setInterval","clearInterval","stop","getTracks","forEach","track","className","children","fileName","_jsxFileName","lineNumber","columnNumber","onClick","ref","videoConstraints","facingMode","dir","_c","$RefreshReg$"],"sources":["C:/Users/HP/Desktop/continous-authentication1/continous-authentication1/continous-authentication/continous-authentication/src/ContinuousAuth.js"],"sourcesContent":["// import React, { useState, useEffect, useRef, useCallback } from \"react\";\r\n// import * as faceapi from \"face-api.js\";\r\n// import Webcam from \"react-webcam\";\r\n// import axios from \"axios\";\r\n// import \"./ContinuousAuth.css\";\r\n\r\n// const ContinuousAuth = () => {\r\n//   const webcamRef = useRef(null);\r\n//   const [faceDetected, setFaceDetected] = useState(false);\r\n//   const [soundDetected, setSoundDetected] = useState(false);\r\n//   const [currentImage, setCurrentImage] = useState(null);\r\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\r\n//   const [examTerminated, setExamTerminated] = useState(false);\r\n//   const [mediaStream, setMediaStream] = useState(null);\r\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\r\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\r\n\r\n//   useEffect(() => {\r\n//     const loadModels = async () => {\r\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\r\n//       console.log(\"Face Detection Model Loaded\");\r\n//     };\r\n//     loadModels();\r\n//   }, []);\r\n\r\n//   const getPermissions = async () => {\r\n//     try {\r\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\r\n//       setMediaStream(stream);\r\n//       setPermissionsGranted(true);\r\n//       setShowPermissionMessage(false);\r\n//       fetchIpAddress(); // Call to fetch IP address when permissions are granted\r\n//     } catch (error) {\r\n//       alert(\"Please allow access to camera and microphone.\");\r\n//       setShowPermissionMessage(true);\r\n//     }\r\n//   };\r\n\r\n//   const fetchIpAddress = async () => {\r\n//     try {\r\n//       const response = await fetch(\"https://api.ipify.org?format=json\");\r\n//       const data = await response.json();\r\n//       alert(`Your IP Address: ${data.ip}`);\r\n//     } catch (error) {\r\n//       console.error(\"Error fetching IP address:\", error);\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (mediaStream) {\r\n//       const tracks = mediaStream.getTracks();\r\n//       tracks.forEach((track) => {\r\n//         track.enabled = true;\r\n//       });\r\n//     }\r\n//   }, [mediaStream]);\r\n\r\n//   const detectFace = async () => {\r\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\r\n//       const video = webcamRef.current.video;\r\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\r\n//       const isFacePresent = detections.length > 0;\r\n//       setFaceDetected(isFacePresent);\r\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       const interval = setInterval(detectFace, 1000);\r\n//       return () => clearInterval(interval);\r\n//     }\r\n//   }, [permissionsGranted]);\r\n\r\n//   useEffect(() => {\r\n//     if (noFaceDuration >= 15) {\r\n//       alert(\"‚ö†Ô∏è Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\r\n//       setNoFaceDuration(0);\r\n//     }\r\n//   }, [noFaceDuration]);\r\n\r\n//   const detectSound = useCallback(() => {\r\n//     if (!mediaStream) return;\r\n\r\n//     const audioContext = new AudioContext();\r\n//     const analyser = audioContext.createAnalyser();\r\n//     const source = audioContext.createMediaStreamSource(mediaStream);\r\n//     source.connect(analyser);\r\n//     analyser.fftSize = 256;\r\n//     const bufferLength = analyser.frequencyBinCount;\r\n//     const dataArray = new Uint8Array(bufferLength);\r\n\r\n//     const checkSound = () => {\r\n//       analyser.getByteFrequencyData(dataArray);\r\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\r\n//       setSoundDetected(volume > 10);\r\n//       requestAnimationFrame(checkSound);\r\n//     };\r\n//     checkSound();\r\n//   }, [mediaStream]);\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       detectSound();\r\n//     }\r\n//   }, [permissionsGranted, detectSound]);\r\n\r\n//   return (\r\n//     <div className=\"continuous-auth-container\">\r\n//       <h2>Continuous Authentication</h2>\r\n\r\n//       {showPermissionMessage && (\r\n//         <div className=\"permission-message\">\r\n//           <p>Please allow access to your camera and microphone to start the exam.</p>\r\n//           <button onClick={getPermissions}>Allow Camera and Microphone</button>\r\n//         </div>\r\n//       )}\r\n\r\n//       {permissionsGranted ? (\r\n//         <>\r\n//           <Webcam\r\n//             audio={true}\r\n//             ref={webcamRef}\r\n//             screenshotFormat=\"image/jpeg\"\r\n//             className=\"webcam\"\r\n//             videoConstraints={{\r\n//               facingMode: \"user\",\r\n//               width: 720,\r\n//               height: 400,\r\n//             }}\r\n//           />\r\n//           <p>Camera and microphone are active for proctoring.</p>\r\n\r\n//           <div className=\"status-buttons-container\">\r\n//             <div className=\"status-buttons\">\r\n//               <button className={faceDetected ? \"detected-btn\" : \"not-detected-btn\"}>\r\n//                 {faceDetected ? \"Face Detected ‚úÖ\" : \"No Face Detected ‚ùå\"}\r\n//               </button>\r\n//               <button className={soundDetected ? \"detected-btn\" : \"not-detected-btn\"}>\r\n//                 {soundDetected ? \"Sound Detected üîä\" : \"No Sound Detected üîá\"}\r\n//               </button>\r\n//             </div>\r\n\r\n//             <div className=\"captured-images\">\r\n//               {currentImage && <img src={currentImage} alt=\"Captured\" className=\"small-image\" />}\r\n//             </div>\r\n//           </div>\r\n//         </>\r\n//       ) : (\r\n//         <p>Waiting for camera and microphone access...</p>\r\n//       )}\r\n\r\n//       {examTerminated && <p className=\"mismatch-count\">Exam Terminated due to 3 mismatches.</p>}\r\n//     </div>\r\n//   );\r\n// };\r\n\r\n// export default ContinuousAuth;\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\r\n// import * as faceapi from \"face-api.js\";\r\n// import Webcam from \"react-webcam\";\r\n// import \"./ContinuousAuth.css\";\r\n\r\n// const ContinuousAuth = () => {\r\n//   const webcamRef = useRef(null);\r\n//   const [faceDetected, setFaceDetected] = useState(false);\r\n//   const [soundDetected, setSoundDetected] = useState(false);\r\n//   const [currentImage, setCurrentImage] = useState(null);\r\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\r\n//   const [examTerminated, setExamTerminated] = useState(false);\r\n//   const [mediaStream, setMediaStream] = useState(null);\r\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\r\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\r\n//   const [transcript, setTranscript] = useState(\"\");\r\n//   const [violations, setViolations] = useState(0);\r\n//   const recognitionRef = useRef(null);\r\n\r\n//   // ŸÜÿ∏ÿßŸÖ ŸÉÿ¥ŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\r\n//   const [multipleVoicesDetected, setMultipleVoicesDetected] = useState(false);\r\n//   const audioContextRef = useRef(null);\r\n//   const analyserRef = useRef(null);\r\n//   const voiceProfileRef = useRef({\r\n//     baseline: null,\r\n//     lastAlert: 0,\r\n//     active: false\r\n//   });\r\n\r\n//   useEffect(() => {\r\n//     const loadModels = async () => {\r\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\r\n//       console.log(\"Face Detection Model Loaded\");\r\n//     };\r\n//     loadModels();\r\n//   }, []);\r\n\r\n//   const getPermissions = async () => {\r\n//     try {\r\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\r\n//       setMediaStream(stream);\r\n//       setPermissionsGranted(true);\r\n//       setShowPermissionMessage(false);\r\n//       initializeSpeechRecognition();\r\n//       setupVoiceAnalysis(stream);\r\n//     } catch (error) {\r\n//       alert(\"Please allow access to camera and microphone.\");\r\n//       setShowPermissionMessage(true);\r\n//     }\r\n//   };\r\n\r\n//   // ŸÜÿ∏ÿßŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\r\n//   const setupVoiceAnalysis = (stream) => {\r\n//     try {\r\n//       audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\r\n//       analyserRef.current = audioContextRef.current.createAnalyser();\r\n//       analyserRef.current.fftSize = 4096;\r\n      \r\n//       const source = audioContextRef.current.createMediaStreamSource(stream);\r\n//       source.connect(analyserRef.current);\r\n\r\n//       // ÿ•ŸÜÿ¥ÿßÿ° ÿ®ÿµŸÖÿ© ÿµŸàÿ™Ÿäÿ© ÿ£ŸàŸÑŸäÿ© ÿ®ÿπÿØ 3 ÿ´ŸàÿßŸÜŸä\r\n//       setTimeout(() => {\r\n//         voiceProfileRef.current.baseline = createVoiceProfile();\r\n//         voiceProfileRef.current.active = true;\r\n//       }, 3000);\r\n\r\n//       const analyzeVoice = () => {\r\n//         if (!voiceProfileRef.current.active) {\r\n//           requestAnimationFrame(analyzeVoice);\r\n//           return;\r\n//         }\r\n\r\n//         const currentProfile = createVoiceProfile();\r\n//         const isMultiple = compareVoiceProfiles(voiceProfileRef.current.baseline, currentProfile);\r\n        \r\n//         if (isMultiple && Date.now() - voiceProfileRef.current.lastAlert > 5000) {\r\n//           setMultipleVoicesDetected(true);\r\n//           voiceProfileRef.current.lastAlert = Date.now();\r\n//         } else {\r\n//           setMultipleVoicesDetected(false);\r\n//         }\r\n\r\n//         requestAnimationFrame(analyzeVoice);\r\n//       };\r\n\r\n//       analyzeVoice();\r\n//     } catch (error) {\r\n//       console.error(\"Voice analysis error:\", error);\r\n//     }\r\n//   };\r\n\r\n//   const createVoiceProfile = () => {\r\n//     const bufferLength = analyserRef.current.frequencyBinCount;\r\n//     const dataArray = new Float32Array(bufferLength);\r\n//     analyserRef.current.getFloatFrequencyData(dataArray);\r\n\r\n//     const profile = {\r\n//       lowRange: 0,    // 85-300Hz\r\n//       midRange: 0,    // 300-1000Hz\r\n//       highRange: 0,   // 1000-4000Hz\r\n//       peakCount: 0,\r\n//       totalEnergy: 0\r\n//     };\r\n\r\n//     for (let i = 0; i < bufferLength; i++) {\r\n//       const freq = i * audioContextRef.current.sampleRate / analyserRef.current.fftSize;\r\n//       const value = Math.pow(10, dataArray[i]/20); // Convert dB to linear\r\n\r\n//       if (freq >= 85 && freq < 300) {\r\n//         profile.lowRange += value;\r\n//       } else if (freq >= 300 && freq < 1000) {\r\n//         profile.midRange += value;\r\n//       } else if (freq >= 1000 && freq < 4000) {\r\n//         profile.highRange += value;\r\n//       }\r\n\r\n//       if (dataArray[i] > -40) profile.peakCount++;\r\n//       profile.totalEnergy += value;\r\n//     }\r\n\r\n//     return profile;\r\n//   };\r\n\r\n//   const compareVoiceProfiles = (baseline, current) => {\r\n//     // ÿ≠ÿ≥ÿßÿ® ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ™ÿ∫Ÿäÿ± ŸÑŸÉŸÑ ŸÜÿ∑ÿßŸÇ ÿ™ÿ±ÿØÿØŸä\r\n//     const lowDiff = Math.abs(current.lowRange - baseline.lowRange) / baseline.lowRange;\r\n//     const midDiff = Math.abs(current.midRange - baseline.midRange) / baseline.midRange;\r\n//     const highDiff = Math.abs(current.highRange - baseline.highRange) / baseline.highRange;\r\n//     const energyDiff = Math.abs(current.totalEnergy - baseline.totalEnergy) / baseline.totalEnergy;\r\n//     const peakDiff = Math.abs(current.peakCount - baseline.peakCount);\r\n\r\n//     // ÿ¥ÿ±Ÿàÿ∑ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ©\r\n//     return (\r\n//       (lowDiff > 0.6 || midDiff > 0.6 || highDiff > 0.6) &&\r\n//       energyDiff > 0.4 &&\r\n//       peakDiff > 15\r\n//     );\r\n//   };\r\n\r\n//   const initializeSpeechRecognition = () => {\r\n//     const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n//     if (!SpeechRecognition) {\r\n//       console.error(\"Speech Recognition API not supported in this browser\");\r\n//       return;\r\n//     }\r\n\r\n//     recognitionRef.current = new SpeechRecognition();\r\n//     recognitionRef.current.continuous = true;\r\n//     recognitionRef.current.interimResults = false;\r\n//     recognitionRef.current.lang = \"ar-SA\";\r\n\r\n//     recognitionRef.current.onresult = (event) => {\r\n//       const last = event.results.length - 1;\r\n//       const text = event.results[last][0].transcript;\r\n//       setTranscript(text);\r\n//     };\r\n\r\n//     recognitionRef.current.onerror = (event) => {\r\n//       console.error(\"Speech recognition error\", event.error);\r\n//     };\r\n\r\n//     recognitionRef.current.start();\r\n//     recognitionRef.current.onend = () => {\r\n//       recognitionRef.current.start();\r\n//     };\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (mediaStream) {\r\n//       const tracks = mediaStream.getTracks();\r\n//       tracks.forEach((track) => {\r\n//         track.enabled = true;\r\n//       });\r\n//     }\r\n\r\n//     return () => {\r\n//       if (recognitionRef.current) {\r\n//         recognitionRef.current.stop();\r\n//       }\r\n//       if (audioContextRef.current) {\r\n//         audioContextRef.current.close();\r\n//       }\r\n//     };\r\n//   }, [mediaStream]);\r\n\r\n//   const detectFace = async () => {\r\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\r\n//       const video = webcamRef.current.video;\r\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\r\n//       const isFacePresent = detections.length > 0;\r\n//       setFaceDetected(isFacePresent);\r\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       const interval = setInterval(detectFace, 1000);\r\n//       return () => clearInterval(interval);\r\n//     }\r\n//   }, [permissionsGranted]);\r\n\r\n//   useEffect(() => {\r\n//     if (noFaceDuration >= 15) {\r\n//       alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\r\n//       setNoFaceDuration(0);\r\n//     }\r\n//   }, [noFaceDuration]);\r\n\r\n//   const detectSound = useCallback(() => {\r\n//     if (!mediaStream) return;\r\n\r\n//     const audioContext = new AudioContext();\r\n//     const analyser = audioContext.createAnalyser();\r\n//     const source = audioContext.createMediaStreamSource(mediaStream);\r\n//     source.connect(analyser);\r\n//     analyser.fftSize = 256;\r\n//     const bufferLength = analyser.frequencyBinCount;\r\n//     const dataArray = new Uint8Array(bufferLength);\r\n\r\n//     const checkSound = () => {\r\n//       analyser.getByteFrequencyData(dataArray);\r\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\r\n//       setSoundDetected(volume > 10);\r\n//       requestAnimationFrame(checkSound);\r\n//     };\r\n//     checkSound();\r\n//   }, [mediaStream]);\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       detectSound();\r\n//     }\r\n//   }, [permissionsGranted, detectSound]);\r\n\r\n//   useEffect(() => {\r\n//     if (multipleVoicesDetected) {\r\n//       const newViolations = violations + 1;\r\n//       setViolations(newViolations);\r\n      \r\n//       alert(`üö® MULTIPLE VOICES DETECTED! (Violation ${newViolations}/3)`);\r\n      \r\n//       if (newViolations >= 3) {\r\n//         setExamTerminated(true);\r\n//       }\r\n//     }\r\n//   }, [multipleVoicesDetected]);\r\n\r\n//   return (\r\n//     <div className=\"continuous-auth-container\">\r\n//       <h2>Exam Proctoring System</h2>\r\n\r\n//       {showPermissionMessage && (\r\n//         <div className=\"permission-message\">\r\n//           <h3>Exam Proctoring Setup</h3>\r\n//           <p>This exam requires camera and microphone access for proctoring purposes.</p>\r\n//           <div className=\"permission-requirements\">\r\n//             <p>‚úì Face detection must be enabled</p>\r\n//             <p>‚úì Microphone must be active</p>\r\n//           </div>\r\n//           <button className=\"permission-button\" onClick={getPermissions}>\r\n//             Enable Camera & Microphone\r\n//           </button>\r\n//         </div>\r\n//       )}\r\n\r\n//       {permissionsGranted && !examTerminated && (\r\n//         <div className=\"monitoring-container\">\r\n//           <div className=\"video-section\">\r\n//             <Webcam\r\n//               audio={true}\r\n//               ref={webcamRef}\r\n//               screenshotFormat=\"image/jpeg\"\r\n//               className=\"webcam\"\r\n//               videoConstraints={{\r\n//                 facingMode: \"user\",\r\n//                 width: 480,\r\n//                 height: 360,\r\n//               }}\r\n//             />\r\n//             <div className=\"status-indicators\">\r\n//               <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\r\n//                 {faceDetected ? \"Face Detected\" : \"No Face Detected\"}\r\n//               </div>\r\n//               <div className={`status-indicator ${soundDetected ? \"active\" : \"\"}`}>\r\n//                 {soundDetected ? \"Sound Detected\" : \"No Sound Detected\"}\r\n//               </div>\r\n//               {multipleVoicesDetected && (\r\n//                 <div className=\"status-indicator warning\">\r\n//                   Multiple Voices Detected!\r\n//                 </div>\r\n//               )}\r\n//             </div>\r\n//           </div>\r\n\r\n//           <div className=\"transcript-section\">\r\n//             <div className=\"transcript-box\">\r\n//               <div className=\"transcript-header\">\r\n//                 <span>Arabic Speech Transcript</span>\r\n//                 <span className=\"violation-counter\">Violations: {violations}/3</span>\r\n//               </div>\r\n//               <div className=\"transcript-content\" dir=\"rtl\">\r\n//                 {transcript || \"Waiting for audio input...\"}\r\n//               </div>\r\n//               <div className={`voice-detection-status ${multipleVoicesDetected ? \"multiple\" : \"\"}`}>\r\n//                 {multipleVoicesDetected \r\n//                   ? \"Multiple voices detected!\" \r\n//                   : \"Voice analysis active\"}\r\n//               </div>\r\n//             </div>\r\n//           </div>\r\n//         </div>\r\n//       )}\r\n\r\n//       {examTerminated && (\r\n//         <div className=\"termination-message\">\r\n//           <h3>‚úñ Exam Terminated</h3>\r\n//           <p>Due to multiple violations detected. Please contact your instructor.</p>\r\n//           <p>Total violations: {violations}</p>\r\n//         </div>\r\n//       )}\r\n//     </div>\r\n//   );\r\n// };\r\n\r\n// export default ContinuousAuth;\r\n\r\n\r\n\r\n\r\n//////////////////////////////////////////////////////////////////////////////////// \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nimport React, { useState, useEffect, useRef } from \"react\";\r\nimport * as faceapi from \"face-api.js\";\r\nimport Webcam from \"react-webcam\";\r\nimport \"./ContinuousAuth.css\";\r\n\r\nconst ContinuousAuth = () => {\r\n  const webcamRef = useRef(null);\r\n  const [faceDetected, setFaceDetected] = useState(false);\r\n  const [soundDetected, setSoundDetected] = useState(false);\r\n  const [permissionsGranted, setPermissionsGranted] = useState(false);\r\n  const [examTerminated, setExamTerminated] = useState(false);\r\n  const [mediaStream, setMediaStream] = useState(null);\r\n  const [showPermissionMessage, setShowPermissionMessage] = useState(true);\r\n  const [noFaceDuration, setNoFaceDuration] = useState(0);\r\n  const [transcript, setTranscript] = useState(\"\");\r\n  const [violations, setViolations] = useState(0);\r\n  const recognitionRef = useRef(null);\r\n\r\n  // ÿ™ŸáŸäÿ¶ÿ© ŸÜŸÖÿßÿ∞ÿ¨ ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑŸàÿ¨Ÿá\r\n  useEffect(() => {\r\n    const loadModels = async () => {\r\n      await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\r\n    };\r\n    loadModels();\r\n  }, []);\r\n\r\n  // ÿ∑ŸÑÿ® ÿßŸÑÿ£ÿ∞ŸàŸÜÿßÿ™\r\n  const getPermissions = async () => {\r\n    try {\r\n      const stream = await navigator.mediaDevices.getUserMedia({ \r\n        video: true, \r\n        audio: true \r\n      });\r\n      setMediaStream(stream);\r\n      setPermissionsGranted(true);\r\n      setShowPermissionMessage(false);\r\n      initializeSpeechRecognition();\r\n    } catch (error) {\r\n      alert(\"Ÿäÿ¨ÿ® ÿßŸÑÿ≥ŸÖÿßÿ≠ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÉÿßŸÖŸäÿ±ÿß ŸàÿßŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ\");\r\n      setShowPermissionMessage(true);\r\n    }\r\n  };\r\n\r\n  // ŸÜÿ∏ÿßŸÖ ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑŸÉŸÑÿßŸÖ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\r\n  const initializeSpeechRecognition = () => {\r\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n    if (!SpeechRecognition) {\r\n      alert(\"ŸÖÿ™ÿµŸÅÿ≠ŸÉ ŸÑÿß ŸäÿØÿπŸÖ ŸÖŸäÿ≤ÿ© ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑÿµŸàÿ™\");\r\n      return;\r\n    }\r\n\r\n    recognitionRef.current = new SpeechRecognition();\r\n    recognitionRef.current.continuous = true;\r\n    recognitionRef.current.interimResults = true;\r\n    recognitionRef.current.lang = \"ar-SA\";\r\n    recognitionRef.current.maxAlternatives = 1;\r\n\r\n    recognitionRef.current.onresult = (event) => {\r\n      let interim = \"\";\r\n      let final = \"\";\r\n\r\n      for (let i = event.resultIndex; i < event.results.length; i++) {\r\n        const transcript = event.results[i][0].transcript;\r\n        if (event.results[i].isFinal) {\r\n          final += transcript;\r\n        } else {\r\n          interim += transcript;\r\n        }\r\n      }\r\n\r\n      // ÿ™ÿ≠ÿØŸäÿ´ ÿßŸÑŸÜÿµ ŸÖÿπ ÿßŸÑÿ≠ŸÅÿßÿ∏ ÿπŸÑŸâ ÿ¢ÿÆÿ± 10 ÿ¨ŸÖŸÑ ŸÅŸÇÿ∑\r\n      setTranscript(prev => {\r\n        const updated = prev + final;\r\n        const sentences = updated.split(/[.!ÿü]\\s+/);\r\n        return sentences.slice(-10).join(\". \") + (interim ? ` (${interim})` : \"\");\r\n      });\r\n    };\r\n\r\n    recognitionRef.current.onerror = (event) => {\r\n      if (event.error === \"no-speech\") {\r\n        console.log(\"ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿ£Ÿä ŸÉŸÑÿßŸÖ\");\r\n      } else {\r\n        console.error(\"ÿÆÿ∑ÿ£ ŸÅŸä ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑÿµŸàÿ™:\", event.error);\r\n      }\r\n    };\r\n\r\n    recognitionRef.current.start();\r\n    recognitionRef.current.onend = () => {\r\n      recognitionRef.current.start();\r\n    };\r\n  };\r\n\r\n  // ŸÉÿ¥ŸÅ ÿßŸÑŸàÿ¨Ÿá\r\n  const detectFace = async () => {\r\n    if (webcamRef.current?.video?.readyState === 4) {\r\n      const detections = await faceapi.detectAllFaces(\r\n        webcamRef.current.video, \r\n        new faceapi.TinyFaceDetectorOptions()\r\n      );\r\n      setFaceDetected(detections.length > 0);\r\n      setNoFaceDuration(prev => detections.length > 0 ? 0 : prev + 1);\r\n    }\r\n  };\r\n\r\n  // ÿßŸÑÿ™ÿ£ÿ´Ÿäÿ±ÿßÿ™ ÿßŸÑÿ¨ÿßŸÜÿ®Ÿäÿ©\r\n  useEffect(() => {\r\n    if (permissionsGranted) {\r\n      const faceInterval = setInterval(detectFace, 1000);\r\n      return () => clearInterval(faceInterval);\r\n    }\r\n  }, [permissionsGranted]);\r\n\r\n  useEffect(() => {\r\n    if (noFaceDuration >= 15) {\r\n      alert(\"‚ö† ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑŸàÿ¨Ÿá ŸÑŸÖÿØÿ© 15 ÿ´ÿßŸÜŸäÿ©\");\r\n      setNoFaceDuration(0);\r\n    }\r\n  }, [noFaceDuration]);\r\n\r\n  // ÿßŸÑÿ™ŸÜÿ∏ŸäŸÅ\r\n  useEffect(() => {\r\n    return () => {\r\n      if (recognitionRef.current) {\r\n        recognitionRef.current.stop();\r\n      }\r\n      if (mediaStream) {\r\n        mediaStream.getTracks().forEach(track => track.stop());\r\n      }\r\n    };\r\n  }, [mediaStream]);\r\n\r\n  return (\r\n    <div className=\"continuous-auth-container\">\r\n      <h2>ŸÜÿ∏ÿßŸÖ ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±ÿßÿ™</h2>\r\n\r\n      {showPermissionMessage && (\r\n        <div className=\"permission-message\">\r\n          <h3>ÿ•ÿπÿØÿßÿØÿßÿ™ ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±</h3>\r\n          <button className=\"permission-button\" onClick={getPermissions}>\r\n            ÿ™ŸÅÿπŸäŸÑ ÿßŸÑŸÉÿßŸÖŸäÿ±ÿß ŸàÿßŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ\r\n          </button>\r\n        </div>\r\n      )}\r\n\r\n      {permissionsGranted && !examTerminated && (\r\n        <div className=\"monitoring-container\">\r\n          <div className=\"video-section\">\r\n            <Webcam\r\n              ref={webcamRef}\r\n              className=\"webcam\"\r\n              videoConstraints={{ facingMode: \"user\" }}\r\n            />\r\n            <div className=\"status-indicators\">\r\n              <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\r\n                {faceDetected ? \"ÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑŸàÿ¨Ÿá\" : \"ŸÑÿß ŸäŸàÿ¨ÿØ Ÿàÿ¨Ÿá\"}\r\n              </div>\r\n            </div>\r\n          </div>\r\n\r\n          <div className=\"transcript-section\">\r\n            <div className=\"transcript-box\">\r\n              <div className=\"transcript-header\">\r\n                <span>ŸÜÿµ ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑŸÉŸÑÿßŸÖ</span>\r\n              </div>\r\n              <div className=\"transcript-content\" dir=\"rtl\">\r\n                {transcript || \"ŸÅŸä ÿßŸÜÿ™ÿ∏ÿßÿ± ÿßŸÑŸÖÿØÿÆŸÑÿßÿ™ ÿßŸÑÿµŸàÿ™Ÿäÿ©...\"}\r\n              </div>\r\n            </div>\r\n          </div>\r\n        </div>\r\n      )}\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default ContinuousAuth;\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n///////////////////////////////////////////////////////////////////////////////////////////////// \r\n\r\n\r\n\r\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\r\n// import * as faceapi from \"face-api.js\";\r\n// import Webcam from \"react-webcam\";\r\n// import \"./ContinuousAuth.css\";\r\n\r\n// const ContinuousAuth = () => {\r\n//   const webcamRef = useRef(null);\r\n//   const [faceDetected, setFaceDetected] = useState(false);\r\n//   const [soundDetected, setSoundDetected] = useState(false);\r\n//   const [currentImage, setCurrentImage] = useState(null);\r\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\r\n//   const [examTerminated, setExamTerminated] = useState(false);\r\n//   const [mediaStream, setMediaStream] = useState(null);\r\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\r\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\r\n//   const [transcript, setTranscript] = useState(\"\");\r\n//   const [violations, setViolations] = useState(0);\r\n\r\n//   // ŸÇÿßÿ¶ŸÖÿ© ÿ®ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿ≠ÿ∏Ÿàÿ±ÿ©\r\n//   const forbiddenWords = [\r\n//     \"ÿ∫ÿ¥\", \"ŸÜÿ≥ÿÆ\",\"ŸÖÿ≥ÿßÿπÿØÿ©\",     \r\n//     \"ÿßŸÑÿ≥ÿ§ÿßŸÑ\", \"ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ©\", \"ÿ≠ŸÑ\",\"ÿÆÿ∑Ÿàÿ©\",        \r\n//     \"ŸÜÿµŸäÿ≠ÿ©\",\"ŸÖÿ¥ÿßÿ±ŸÉÿ©\",\"ÿ±ÿ≥ÿßŸÑÿ©\",    \r\n//     \"ÿ•ÿ¥ÿßÿ±ÿ©\",\"ÿßÿ≥ÿ™ŸÅŸáÿßŸÖ\",\"ÿÆÿ∑ÿ£\",         \r\n//     \"ÿµÿ≠Ÿäÿ≠\",\"ŸÖÿπÿßŸÉ\",\"ÿßÿ±ÿ≥ŸÑ\",       \r\n//     \"ÿßÿ≥ÿ™ŸÑŸÖ\",\"ÿßÿ¨ÿßŸàÿ®ŸÉ\",\"ÿ®ÿ≥ÿ±ÿπÿ©\",       \r\n//     \"ÿ¥Ÿà\",\"ŸÉŸäŸÅ\",         \r\n//   ];\r\n//   const [forbiddenCount, setForbiddenCount] = useState(0); // ÿπÿØÿßÿØ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿ≠ÿ∏Ÿàÿ±ÿ©\r\n//   const detectedForbiddenWords = useRef(new Set()); // ŸÖÿ¨ŸÖŸàÿπÿ© ÿ™ÿÆÿ≤ŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿ≠ÿ∏Ÿàÿ±ÿ© ÿßŸÑŸÖŸÉÿ™ÿ¥ŸÅÿ©\r\n\r\n//   const recognitionRef = useRef(null);\r\n\r\n//   useEffect(() => {\r\n//     const loadModels = async () => {\r\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\r\n//       console.log(\"Face Detection Model Loaded\");\r\n//     };\r\n//     loadModels();\r\n//   }, []);\r\n\r\n//   const getPermissions = async () => {\r\n//     try {\r\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\r\n//       setMediaStream(stream);\r\n//       setPermissionsGranted(true);\r\n//       setShowPermissionMessage(false);\r\n//       initializeSpeechRecognition();\r\n//     } catch (error) {\r\n//       alert(\"Please allow access to camera and microphone.\");\r\n//       setShowPermissionMessage(true);\r\n//     }\r\n//   };\r\n\r\n//   const initializeSpeechRecognition = () => {\r\n//     const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n//     if (!SpeechRecognition) {\r\n//       console.error(\"Speech Recognition API not supported in this browser\");\r\n//       return;\r\n//     }\r\n//     recognitionRef.current = new SpeechRecognition();\r\n//     recognitionRef.current.continuous = true;\r\n//     recognitionRef.current.interimResults = false;\r\n//     recognitionRef.current.lang = \"ar-SA\";\r\n\r\n//     recognitionRef.current.onresult = (event) => {\r\n//       const last = event.results.length - 1;\r\n//       const text = event.results[last][0].transcript;\r\n//       console.log(\"Recognized Text:\", text); // ŸÑŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿßŸÑŸÜÿµŸàÿµ ÿßŸÑŸÖÿØÿÆŸÑÿ©\r\n//       setTranscript(text);\r\n\r\n//       // ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿ≠ÿ∏Ÿàÿ±ÿ©\r\n//       checkForbiddenWords(text);\r\n//     };\r\n\r\n//     recognitionRef.current.onerror = (event) => {\r\n//       console.error(\"Speech recognition error\", event.error);\r\n//     };\r\n\r\n//     recognitionRef.current.start();\r\n//     recognitionRef.current.onend = () => {\r\n//       recognitionRef.current.start();\r\n//     };\r\n//   };\r\n\r\n//   // ÿØÿßŸÑÿ© ŸÑŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿ≠ÿ∏Ÿàÿ±ÿ©\r\n//   const checkForbiddenWords = (text) => {\r\n//     forbiddenWords.forEach((word) => {\r\n//       if (text.includes(word)) {\r\n//         // ÿ•ÿ∞ÿß ŸÑŸÖ ÿ™ŸÉŸÜ ÿßŸÑŸÉŸÑŸÖÿ© ŸÇÿØ ÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅŸáÿß ŸÖŸÜ ŸÇÿ®ŸÑ\r\n//         if (!detectedForbiddenWords.current.has(word)) {\r\n//           detectedForbiddenWords.current.add(word); // ÿ•ÿ∂ÿßŸÅÿ© ÿßŸÑŸÉŸÑŸÖÿ© ÿ•ŸÑŸâ ÿßŸÑŸÖÿ¨ŸÖŸàÿπÿ©\r\n//           const newCount = detectedForbiddenWords.current.size; // ÿ≠ÿ≥ÿßÿ® ÿßŸÑÿπÿØÿØ ÿßŸÑÿ¨ÿØŸäÿØ\r\n//           setForbiddenCount(newCount); // ÿ™ÿ≠ÿØŸäÿ´ ÿßŸÑÿπÿØÿßÿØ\r\n//           console.log(`New forbidden word detected: ${word} (Total: ${newCount})`); // ŸÑŸÑÿ™ÿ≠ŸÇŸÇ\r\n\r\n//           // ÿ•ÿ∞ÿß ŸàÿµŸÑ ÿßŸÑÿπÿØÿßÿØ ÿ•ŸÑŸâ 3\r\n//           if (newCount >= 3) {\r\n//             alert(\"‚ö†Ô∏è ÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ 3 ŸÉŸÑŸÖÿßÿ™ ŸÖÿ≠ÿ∏Ÿàÿ±ÿ© ŸÖÿÆÿ™ŸÑŸÅÿ©! ÿ≥Ÿäÿ™ŸÖ ÿ•ŸÜŸáÿßÿ° ÿßŸÑÿßŸÖÿ™ÿ≠ÿßŸÜ.\");\r\n//             terminateExam();\r\n//           }\r\n//         }\r\n//       }\r\n//     });\r\n//   };\r\n\r\n//   // ÿØÿßŸÑÿ© ŸÑÿ•ŸÜŸáÿßÿ° ÿßŸÑÿßŸÖÿ™ÿ≠ÿßŸÜ Ÿàÿ•ÿ∫ŸÑÿßŸÇ ÿßŸÑÿµŸÅÿ≠ÿ©\r\n//   const terminateExam = () => {\r\n//     setExamTerminated(true);\r\n//     alert(\"‚úñ ÿßŸÑÿßŸÖÿ™ÿ≠ÿßŸÜ ÿ™ŸàŸÇŸÅ ÿ®ÿ≥ÿ®ÿ® ÿßŸÜÿ™ŸáÿßŸÉÿßÿ™ ŸÖÿ™ÿπÿØÿØÿ©!\");\r\n//     window.close(); // ÿ•ÿ∫ŸÑÿßŸÇ ÿßŸÑÿµŸÅÿ≠ÿ©\r\n//   };\r\n\r\n//   const detectFace = async () => {\r\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\r\n//       const video = webcamRef.current.video;\r\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\r\n//       const isFacePresent = detections.length > 0;\r\n//       setFaceDetected(isFacePresent);\r\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       const interval = setInterval(detectFace, 1000);\r\n//       return () => clearInterval(interval);\r\n//     }\r\n//   }, [permissionsGranted]);\r\n\r\n//   useEffect(() => {\r\n//     if (noFaceDuration >= 15) {\r\n//       alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\r\n//       setNoFaceDuration(0);\r\n//     }\r\n//   }, [noFaceDuration]);\r\n\r\n//   const detectSound = useCallback(() => {\r\n//     if (!mediaStream) return;\r\n//     const audioContext = new AudioContext();\r\n//     const analyser = audioContext.createAnalyser();\r\n//     const source = audioContext.createMediaStreamSource(mediaStream);\r\n//     source.connect(analyser);\r\n//     analyser.fftSize = 256;\r\n//     const bufferLength = analyser.frequencyBinCount;\r\n//     const dataArray = new Uint8Array(bufferLength);\r\n//     const checkSound = () => {\r\n//       analyser.getByteFrequencyData(dataArray);\r\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\r\n//       setSoundDetected(volume > 10);\r\n//       requestAnimationFrame(checkSound);\r\n//     };\r\n//     checkSound();\r\n//   }, [mediaStream]);\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       detectSound();\r\n//     }\r\n//   }, [permissionsGranted, detectSound]);\r\n\r\n//   return (\r\n//     <div className=\"continuous-auth-container\">\r\n//       <h2>Exam Proctoring System</h2>\r\n//       {showPermissionMessage && (\r\n//         <div className=\"permission-message\">\r\n//           <h3>Exam Proctoring Setup</h3>\r\n//           <p>This exam requires camera and microphone access for proctoring purposes.</p>\r\n//           <div className=\"permission-requirements\">\r\n//             <p>‚úì Face detection must be enabled</p>\r\n//             <p>‚úì Microphone must be active</p>\r\n//           </div>\r\n//           <button className=\"permission-button\" onClick={getPermissions}>\r\n//             Enable Camera & Microphone\r\n//           </button>\r\n//         </div>\r\n//       )}\r\n//       {permissionsGranted && !examTerminated && (\r\n//         <div className=\"monitoring-container\">\r\n//           <div className=\"video-section\">\r\n//             <Webcam\r\n//               audio={true}\r\n//               ref={webcamRef}\r\n//               screenshotFormat=\"image/jpeg\"\r\n//               className=\"webcam\"\r\n//               videoConstraints={{\r\n//                 facingMode: \"user\",\r\n//                 width: 480,\r\n//                 height: 360,\r\n//               }}\r\n//             />\r\n//             <div className=\"status-indicators\">\r\n//               <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\r\n//                 {faceDetected ? \"Face Detected\" : \"No Face Detected\"}\r\n//               </div>\r\n//               <div className={`status-indicator ${soundDetected ? \"active\" : \"\"}`}>\r\n//                 {soundDetected ? \"Sound Detected\" : \"No Sound Detected\"}\r\n//               </div>\r\n//             </div>\r\n//           </div>\r\n//           <div className=\"transcript-section\">\r\n//             <div className=\"transcript-box\">\r\n//               <div className=\"transcript-header\">\r\n//                 <span>Arabic Speech Transcript</span>\r\n//                 <span className=\"violation-counter\">Total Forbidden Words: {forbiddenCount}/3</span>\r\n//               </div>\r\n//               <div className=\"transcript-content\" dir=\"rtl\">\r\n//                 {transcript || \"Waiting for audio input...\"}\r\n//               </div>\r\n//             </div>\r\n//           </div>\r\n//         </div>\r\n//       )}\r\n//       {examTerminated && (\r\n//         <div className=\"termination-message\">\r\n//           <h3>‚úñ Exam Terminated</h3>\r\n//           <p>Due to multiple violations detected. Please contact your instructor.</p>\r\n//         </div>\r\n//       )}\r\n//     </div>\r\n//   );\r\n// };\r\n\r\n// export default ContinuousAuth;"],"mappings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aA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,MAAM,QAAQ,OAAO;AAC1D,OAAO,KAAKC,OAAO,MAAM,aAAa;AACtC,OAAOC,MAAM,MAAM,cAAc;AACjC,OAAO,sBAAsB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE9B,MAAMC,cAAc,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC3B,MAAMC,SAAS,GAAGP,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAM,CAACQ,YAAY,EAAEC,eAAe,CAAC,GAAGX,QAAQ,CAAC,KAAK,CAAC;EACvD,MAAM,CAACY,aAAa,EAAEC,gBAAgB,CAAC,GAAGb,QAAQ,CAAC,KAAK,CAAC;EACzD,MAAM,CAACc,kBAAkB,EAAEC,qBAAqB,CAAC,GAAGf,QAAQ,CAAC,KAAK,CAAC;EACnE,MAAM,CAACgB,cAAc,EAAEC,iBAAiB,CAAC,GAAGjB,QAAQ,CAAC,KAAK,CAAC;EAC3D,MAAM,CAACkB,WAAW,EAAEC,cAAc,CAAC,GAAGnB,QAAQ,CAAC,IAAI,CAAC;EACpD,MAAM,CAACoB,qBAAqB,EAAEC,wBAAwB,CAAC,GAAGrB,QAAQ,CAAC,IAAI,CAAC;EACxE,MAAM,CAACsB,cAAc,EAAEC,iBAAiB,CAAC,GAAGvB,QAAQ,CAAC,CAAC,CAAC;EACvD,MAAM,CAACwB,UAAU,EAAEC,aAAa,CAAC,GAAGzB,QAAQ,CAAC,EAAE,CAAC;EAChD,MAAM,CAAC0B,UAAU,EAAEC,aAAa,CAAC,GAAG3B,QAAQ,CAAC,CAAC,CAAC;EAC/C,MAAM4B,cAAc,GAAG1B,MAAM,CAAC,IAAI,CAAC;;EAEnC;EACAD,SAAS,CAAC,MAAM;IACd,MAAM4B,UAAU,GAAG,MAAAA,CAAA,KAAY;MAC7B,MAAM1B,OAAO,CAAC2B,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAAC,SAAS,CAAC;IAC5D,CAAC;IACDH,UAAU,CAAC,CAAC;EACd,CAAC,EAAE,EAAE,CAAC;;EAEN;EACA,MAAMI,cAAc,GAAG,MAAAA,CAAA,KAAY;IACjC,IAAI;MACF,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QACvDC,KAAK,EAAE,IAAI;QACXC,KAAK,EAAE;MACT,CAAC,CAAC;MACFpB,cAAc,CAACe,MAAM,CAAC;MACtBnB,qBAAqB,CAAC,IAAI,CAAC;MAC3BM,wBAAwB,CAAC,KAAK,CAAC;MAC/BmB,2BAA2B,CAAC,CAAC;IAC/B,CAAC,CAAC,OAAOC,KAAK,EAAE;MACdC,KAAK,CAAC,0CAA0C,CAAC;MACjDrB,wBAAwB,CAAC,IAAI,CAAC;IAChC;EACF,CAAC;;EAED;EACA,MAAMmB,2BAA2B,GAAGA,CAAA,KAAM;IACxC,MAAMG,iBAAiB,GAAGC,MAAM,CAACD,iBAAiB,IAAIC,MAAM,CAACC,uBAAuB;IACpF,IAAI,CAACF,iBAAiB,EAAE;MACtBD,KAAK,CAAC,sCAAsC,CAAC;MAC7C;IACF;IAEAd,cAAc,CAACkB,OAAO,GAAG,IAAIH,iBAAiB,CAAC,CAAC;IAChDf,cAAc,CAACkB,OAAO,CAACC,UAAU,GAAG,IAAI;IACxCnB,cAAc,CAACkB,OAAO,CAACE,cAAc,GAAG,IAAI;IAC5CpB,cAAc,CAACkB,OAAO,CAACG,IAAI,GAAG,OAAO;IACrCrB,cAAc,CAACkB,OAAO,CAACI,eAAe,GAAG,CAAC;IAE1CtB,cAAc,CAACkB,OAAO,CAACK,QAAQ,GAAIC,KAAK,IAAK;MAC3C,IAAIC,OAAO,GAAG,EAAE;MAChB,IAAIC,KAAK,GAAG,EAAE;MAEd,KAAK,IAAIC,CAAC,GAAGH,KAAK,CAACI,WAAW,EAAED,CAAC,GAAGH,KAAK,CAACK,OAAO,CAACC,MAAM,EAAEH,CAAC,EAAE,EAAE;QAC7D,MAAM/B,UAAU,GAAG4B,KAAK,CAACK,OAAO,CAACF,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC/B,UAAU;QACjD,IAAI4B,KAAK,CAACK,OAAO,CAACF,CAAC,CAAC,CAACI,OAAO,EAAE;UAC5BL,KAAK,IAAI9B,UAAU;QACrB,CAAC,MAAM;UACL6B,OAAO,IAAI7B,UAAU;QACvB;MACF;;MAEA;MACAC,aAAa,CAACmC,IAAI,IAAI;QACpB,MAAMC,OAAO,GAAGD,IAAI,GAAGN,KAAK;QAC5B,MAAMQ,SAAS,GAAGD,OAAO,CAACE,KAAK,CAAC,UAAU,CAAC;QAC3C,OAAOD,SAAS,CAACE,KAAK,CAAC,CAAC,EAAE,CAAC,CAACC,IAAI,CAAC,IAAI,CAAC,IAAIZ,OAAO,GAAG,KAAKA,OAAO,GAAG,GAAG,EAAE,CAAC;MAC3E,CAAC,CAAC;IACJ,CAAC;IAEDzB,cAAc,CAACkB,OAAO,CAACoB,OAAO,GAAId,KAAK,IAAK;MAC1C,IAAIA,KAAK,CAACX,KAAK,KAAK,WAAW,EAAE;QAC/B0B,OAAO,CAACC,GAAG,CAAC,uBAAuB,CAAC;MACtC,CAAC,MAAM;QACLD,OAAO,CAAC1B,KAAK,CAAC,0BAA0B,EAAEW,KAAK,CAACX,KAAK,CAAC;MACxD;IACF,CAAC;IAEDb,cAAc,CAACkB,OAAO,CAACuB,KAAK,CAAC,CAAC;IAC9BzC,cAAc,CAACkB,OAAO,CAACwB,KAAK,GAAG,MAAM;MACnC1C,cAAc,CAACkB,OAAO,CAACuB,KAAK,CAAC,CAAC;IAChC,CAAC;EACH,CAAC;;EAED;EACA,MAAME,UAAU,GAAG,MAAAA,CAAA,KAAY;IAAA,IAAAC,kBAAA,EAAAC,qBAAA;IAC7B,IAAI,EAAAD,kBAAA,GAAA/D,SAAS,CAACqC,OAAO,cAAA0B,kBAAA,wBAAAC,qBAAA,GAAjBD,kBAAA,CAAmBlC,KAAK,cAAAmC,qBAAA,uBAAxBA,qBAAA,CAA0BC,UAAU,MAAK,CAAC,EAAE;MAC9C,MAAMC,UAAU,GAAG,MAAMxE,OAAO,CAACyE,cAAc,CAC7CnE,SAAS,CAACqC,OAAO,CAACR,KAAK,EACvB,IAAInC,OAAO,CAAC0E,uBAAuB,CAAC,CACtC,CAAC;MACDlE,eAAe,CAACgE,UAAU,CAACjB,MAAM,GAAG,CAAC,CAAC;MACtCnC,iBAAiB,CAACqC,IAAI,IAAIe,UAAU,CAACjB,MAAM,GAAG,CAAC,GAAG,CAAC,GAAGE,IAAI,GAAG,CAAC,CAAC;IACjE;EACF,CAAC;;EAED;EACA3D,SAAS,CAAC,MAAM;IACd,IAAIa,kBAAkB,EAAE;MACtB,MAAMgE,YAAY,GAAGC,WAAW,CAACR,UAAU,EAAE,IAAI,CAAC;MAClD,OAAO,MAAMS,aAAa,CAACF,YAAY,CAAC;IAC1C;EACF,CAAC,EAAE,CAAChE,kBAAkB,CAAC,CAAC;EAExBb,SAAS,CAAC,MAAM;IACd,IAAIqB,cAAc,IAAI,EAAE,EAAE;MACxBoB,KAAK,CAAC,qCAAqC,CAAC;MAC5CnB,iBAAiB,CAAC,CAAC,CAAC;IACtB;EACF,CAAC,EAAE,CAACD,cAAc,CAAC,CAAC;;EAEpB;EACArB,SAAS,CAAC,MAAM;IACd,OAAO,MAAM;MACX,IAAI2B,cAAc,CAACkB,OAAO,EAAE;QAC1BlB,cAAc,CAACkB,OAAO,CAACmC,IAAI,CAAC,CAAC;MAC/B;MACA,IAAI/D,WAAW,EAAE;QACfA,WAAW,CAACgE,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACH,IAAI,CAAC,CAAC,CAAC;MACxD;IACF,CAAC;EACH,CAAC,EAAE,CAAC/D,WAAW,CAAC,CAAC;EAEjB,oBACEZ,OAAA;IAAK+E,SAAS,EAAC,2BAA2B;IAAAC,QAAA,gBACxChF,OAAA;MAAAgF,QAAA,EAAI;IAAsB;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,EAE9BtE,qBAAqB,iBACpBd,OAAA;MAAK+E,SAAS,EAAC,oBAAoB;MAAAC,QAAA,gBACjChF,OAAA;QAAAgF,QAAA,EAAI;MAAuB;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eAChCpF,OAAA;QAAQ+E,SAAS,EAAC,mBAAmB;QAACM,OAAO,EAAE1D,cAAe;QAAAqD,QAAA,EAAC;MAE/D;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACN,CACN,EAEA5E,kBAAkB,IAAI,CAACE,cAAc,iBACpCV,OAAA;MAAK+E,SAAS,EAAC,sBAAsB;MAAAC,QAAA,gBACnChF,OAAA;QAAK+E,SAAS,EAAC,eAAe;QAAAC,QAAA,gBAC5BhF,OAAA,CAACF,MAAM;UACLwF,GAAG,EAAEnF,SAAU;UACf4E,SAAS,EAAC,QAAQ;UAClBQ,gBAAgB,EAAE;YAAEC,UAAU,EAAE;UAAO;QAAE;UAAAP,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAC1C,CAAC,eACFpF,OAAA;UAAK+E,SAAS,EAAC,mBAAmB;UAAAC,QAAA,eAChChF,OAAA;YAAK+E,SAAS,EAAE,oBAAoB3E,YAAY,GAAG,QAAQ,GAAG,EAAE,EAAG;YAAA4E,QAAA,EAChE5E,YAAY,GAAG,iBAAiB,GAAG;UAAa;YAAA6E,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAC9C;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACH,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACH,CAAC,eAENpF,OAAA;QAAK+E,SAAS,EAAC,oBAAoB;QAAAC,QAAA,eACjChF,OAAA;UAAK+E,SAAS,EAAC,gBAAgB;UAAAC,QAAA,gBAC7BhF,OAAA;YAAK+E,SAAS,EAAC,mBAAmB;YAAAC,QAAA,eAChChF,OAAA;cAAAgF,QAAA,EAAM;YAAoB;cAAAC,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAM;UAAC;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAC9B,CAAC,eACNpF,OAAA;YAAK+E,SAAS,EAAC,oBAAoB;YAACU,GAAG,EAAC,KAAK;YAAAT,QAAA,EAC1C9D,UAAU,IAAI;UAA+B;YAAA+D,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAC3C,CAAC;QAAA;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACH;MAAC;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACH,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACH,CACN;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV,CAAC;AAAClF,EAAA,CAxKID,cAAc;AAAAyF,EAAA,GAAdzF,cAAc;AA0KpB,eAAeA,cAAc;;AAW7B;;AAIA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAAA,IAAAyF,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}