{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\HP\\\\Desktop\\\\continous-authentication1\\\\continous-authentication1\\\\continous-authentication\\\\continous-authentication\\\\src\\\\ContinuousAuth.js\",\n  _s = $RefreshSig$();\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\n// import * as faceapi from \"face-api.js\";\n// import Webcam from \"react-webcam\";\n// import axios from \"axios\";\n// import \"./ContinuousAuth.css\";\n\n// const ContinuousAuth = () => {\n//   const webcamRef = useRef(null);\n//   const [faceDetected, setFaceDetected] = useState(false);\n//   const [soundDetected, setSoundDetected] = useState(false);\n//   const [currentImage, setCurrentImage] = useState(null);\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\n//   const [examTerminated, setExamTerminated] = useState(false);\n//   const [mediaStream, setMediaStream] = useState(null);\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\n\n//   useEffect(() => {\n//     const loadModels = async () => {\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\n//       console.log(\"Face Detection Model Loaded\");\n//     };\n//     loadModels();\n//   }, []);\n\n//   const getPermissions = async () => {\n//     try {\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\n//       setMediaStream(stream);\n//       setPermissionsGranted(true);\n//       setShowPermissionMessage(false);\n//       fetchIpAddress(); // Call to fetch IP address when permissions are granted\n//     } catch (error) {\n//       alert(\"Please allow access to camera and microphone.\");\n//       setShowPermissionMessage(true);\n//     }\n//   };\n\n//   const fetchIpAddress = async () => {\n//     try {\n//       const response = await fetch(\"https://api.ipify.org?format=json\");\n//       const data = await response.json();\n//       alert(`Your IP Address: ${data.ip}`);\n//     } catch (error) {\n//       console.error(\"Error fetching IP address:\", error);\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (mediaStream) {\n//       const tracks = mediaStream.getTracks();\n//       tracks.forEach((track) => {\n//         track.enabled = true;\n//       });\n//     }\n//   }, [mediaStream]);\n\n//   const detectFace = async () => {\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\n//       const video = webcamRef.current.video;\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n//       const isFacePresent = detections.length > 0;\n//       setFaceDetected(isFacePresent);\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       const interval = setInterval(detectFace, 1000);\n//       return () => clearInterval(interval);\n//     }\n//   }, [permissionsGranted]);\n\n//   useEffect(() => {\n//     if (noFaceDuration >= 15) {\n//       alert(\"‚ö†Ô∏è Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\n//       setNoFaceDuration(0);\n//     }\n//   }, [noFaceDuration]);\n\n//   const detectSound = useCallback(() => {\n//     if (!mediaStream) return;\n\n//     const audioContext = new AudioContext();\n//     const analyser = audioContext.createAnalyser();\n//     const source = audioContext.createMediaStreamSource(mediaStream);\n//     source.connect(analyser);\n//     analyser.fftSize = 256;\n//     const bufferLength = analyser.frequencyBinCount;\n//     const dataArray = new Uint8Array(bufferLength);\n\n//     const checkSound = () => {\n//       analyser.getByteFrequencyData(dataArray);\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\n//       setSoundDetected(volume > 10);\n//       requestAnimationFrame(checkSound);\n//     };\n//     checkSound();\n//   }, [mediaStream]);\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       detectSound();\n//     }\n//   }, [permissionsGranted, detectSound]);\n\n//   return (\n//     <div className=\"continuous-auth-container\">\n//       <h2>Continuous Authentication</h2>\n\n//       {showPermissionMessage && (\n//         <div className=\"permission-message\">\n//           <p>Please allow access to your camera and microphone to start the exam.</p>\n//           <button onClick={getPermissions}>Allow Camera and Microphone</button>\n//         </div>\n//       )}\n\n//       {permissionsGranted ? (\n//         <>\n//           <Webcam\n//             audio={true}\n//             ref={webcamRef}\n//             screenshotFormat=\"image/jpeg\"\n//             className=\"webcam\"\n//             videoConstraints={{\n//               facingMode: \"user\",\n//               width: 720,\n//               height: 400,\n//             }}\n//           />\n//           <p>Camera and microphone are active for proctoring.</p>\n\n//           <div className=\"status-buttons-container\">\n//             <div className=\"status-buttons\">\n//               <button className={faceDetected ? \"detected-btn\" : \"not-detected-btn\"}>\n//                 {faceDetected ? \"Face Detected ‚úÖ\" : \"No Face Detected ‚ùå\"}\n//               </button>\n//               <button className={soundDetected ? \"detected-btn\" : \"not-detected-btn\"}>\n//                 {soundDetected ? \"Sound Detected üîä\" : \"No Sound Detected üîá\"}\n//               </button>\n//             </div>\n\n//             <div className=\"captured-images\">\n//               {currentImage && <img src={currentImage} alt=\"Captured\" className=\"small-image\" />}\n//             </div>\n//           </div>\n//         </>\n//       ) : (\n//         <p>Waiting for camera and microphone access...</p>\n//       )}\n\n//       {examTerminated && <p className=\"mismatch-count\">Exam Terminated due to 3 mismatches.</p>}\n//     </div>\n//   );\n// };\n\n// export default ContinuousAuth;\n\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\n// import * as faceapi from \"face-api.js\";\n// import Webcam from \"react-webcam\";\n// import \"./ContinuousAuth.css\";\n\n// const ContinuousAuth = () => {\n//   const webcamRef = useRef(null);\n//   const [faceDetected, setFaceDetected] = useState(false);\n//   const [soundDetected, setSoundDetected] = useState(false);\n//   const [currentImage, setCurrentImage] = useState(null);\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\n//   const [examTerminated, setExamTerminated] = useState(false);\n//   const [mediaStream, setMediaStream] = useState(null);\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\n//   const [transcript, setTranscript] = useState(\"\");\n//   const [violations, setViolations] = useState(0);\n//   const recognitionRef = useRef(null);\n\n//   // ŸÜÿ∏ÿßŸÖ ŸÉÿ¥ŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\n//   const [multipleVoicesDetected, setMultipleVoicesDetected] = useState(false);\n//   const audioContextRef = useRef(null);\n//   const analyserRef = useRef(null);\n//   const voiceProfileRef = useRef({\n//     baseline: null,\n//     lastAlert: 0,\n//     active: false\n//   });\n\n//   useEffect(() => {\n//     const loadModels = async () => {\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\n//       console.log(\"Face Detection Model Loaded\");\n//     };\n//     loadModels();\n//   }, []);\n\n//   const getPermissions = async () => {\n//     try {\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\n//       setMediaStream(stream);\n//       setPermissionsGranted(true);\n//       setShowPermissionMessage(false);\n//       initializeSpeechRecognition();\n//       setupVoiceAnalysis(stream);\n//     } catch (error) {\n//       alert(\"Please allow access to camera and microphone.\");\n//       setShowPermissionMessage(true);\n//     }\n//   };\n\n//   // ŸÜÿ∏ÿßŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\n//   const setupVoiceAnalysis = (stream) => {\n//     try {\n//       audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n//       analyserRef.current = audioContextRef.current.createAnalyser();\n//       analyserRef.current.fftSize = 4096;\n\n//       const source = audioContextRef.current.createMediaStreamSource(stream);\n//       source.connect(analyserRef.current);\n\n//       // ÿ•ŸÜÿ¥ÿßÿ° ÿ®ÿµŸÖÿ© ÿµŸàÿ™Ÿäÿ© ÿ£ŸàŸÑŸäÿ© ÿ®ÿπÿØ 3 ÿ´ŸàÿßŸÜŸä\n//       setTimeout(() => {\n//         voiceProfileRef.current.baseline = createVoiceProfile();\n//         voiceProfileRef.current.active = true;\n//       }, 3000);\n\n//       const analyzeVoice = () => {\n//         if (!voiceProfileRef.current.active) {\n//           requestAnimationFrame(analyzeVoice);\n//           return;\n//         }\n\n//         const currentProfile = createVoiceProfile();\n//         const isMultiple = compareVoiceProfiles(voiceProfileRef.current.baseline, currentProfile);\n\n//         if (isMultiple && Date.now() - voiceProfileRef.current.lastAlert > 5000) {\n//           setMultipleVoicesDetected(true);\n//           voiceProfileRef.current.lastAlert = Date.now();\n//         } else {\n//           setMultipleVoicesDetected(false);\n//         }\n\n//         requestAnimationFrame(analyzeVoice);\n//       };\n\n//       analyzeVoice();\n//     } catch (error) {\n//       console.error(\"Voice analysis error:\", error);\n//     }\n//   };\n\n//   const createVoiceProfile = () => {\n//     const bufferLength = analyserRef.current.frequencyBinCount;\n//     const dataArray = new Float32Array(bufferLength);\n//     analyserRef.current.getFloatFrequencyData(dataArray);\n\n//     const profile = {\n//       lowRange: 0,    // 85-300Hz\n//       midRange: 0,    // 300-1000Hz\n//       highRange: 0,   // 1000-4000Hz\n//       peakCount: 0,\n//       totalEnergy: 0\n//     };\n\n//     for (let i = 0; i < bufferLength; i++) {\n//       const freq = i * audioContextRef.current.sampleRate / analyserRef.current.fftSize;\n//       const value = Math.pow(10, dataArray[i]/20); // Convert dB to linear\n\n//       if (freq >= 85 && freq < 300) {\n//         profile.lowRange += value;\n//       } else if (freq >= 300 && freq < 1000) {\n//         profile.midRange += value;\n//       } else if (freq >= 1000 && freq < 4000) {\n//         profile.highRange += value;\n//       }\n\n//       if (dataArray[i] > -40) profile.peakCount++;\n//       profile.totalEnergy += value;\n//     }\n\n//     return profile;\n//   };\n\n//   const compareVoiceProfiles = (baseline, current) => {\n//     // ÿ≠ÿ≥ÿßÿ® ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ™ÿ∫Ÿäÿ± ŸÑŸÉŸÑ ŸÜÿ∑ÿßŸÇ ÿ™ÿ±ÿØÿØŸä\n//     const lowDiff = Math.abs(current.lowRange - baseline.lowRange) / baseline.lowRange;\n//     const midDiff = Math.abs(current.midRange - baseline.midRange) / baseline.midRange;\n//     const highDiff = Math.abs(current.highRange - baseline.highRange) / baseline.highRange;\n//     const energyDiff = Math.abs(current.totalEnergy - baseline.totalEnergy) / baseline.totalEnergy;\n//     const peakDiff = Math.abs(current.peakCount - baseline.peakCount);\n\n//     // ÿ¥ÿ±Ÿàÿ∑ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ©\n//     return (\n//       (lowDiff > 0.6 || midDiff > 0.6 || highDiff > 0.6) &&\n//       energyDiff > 0.4 &&\n//       peakDiff > 15\n//     );\n//   };\n\n//   const initializeSpeechRecognition = () => {\n//     const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n//     if (!SpeechRecognition) {\n//       console.error(\"Speech Recognition API not supported in this browser\");\n//       return;\n//     }\n\n//     recognitionRef.current = new SpeechRecognition();\n//     recognitionRef.current.continuous = true;\n//     recognitionRef.current.interimResults = false;\n//     recognitionRef.current.lang = \"ar-SA\";\n\n//     recognitionRef.current.onresult = (event) => {\n//       const last = event.results.length - 1;\n//       const text = event.results[last][0].transcript;\n//       setTranscript(text);\n//     };\n\n//     recognitionRef.current.onerror = (event) => {\n//       console.error(\"Speech recognition error\", event.error);\n//     };\n\n//     recognitionRef.current.start();\n//     recognitionRef.current.onend = () => {\n//       recognitionRef.current.start();\n//     };\n//   };\n\n//   useEffect(() => {\n//     if (mediaStream) {\n//       const tracks = mediaStream.getTracks();\n//       tracks.forEach((track) => {\n//         track.enabled = true;\n//       });\n//     }\n\n//     return () => {\n//       if (recognitionRef.current) {\n//         recognitionRef.current.stop();\n//       }\n//       if (audioContextRef.current) {\n//         audioContextRef.current.close();\n//       }\n//     };\n//   }, [mediaStream]);\n\n//   const detectFace = async () => {\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\n//       const video = webcamRef.current.video;\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n//       const isFacePresent = detections.length > 0;\n//       setFaceDetected(isFacePresent);\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       const interval = setInterval(detectFace, 1000);\n//       return () => clearInterval(interval);\n//     }\n//   }, [permissionsGranted]);\n\n//   useEffect(() => {\n//     if (noFaceDuration >= 15) {\n//       alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\n//       setNoFaceDuration(0);\n//     }\n//   }, [noFaceDuration]);\n\n//   const detectSound = useCallback(() => {\n//     if (!mediaStream) return;\n\n//     const audioContext = new AudioContext();\n//     const analyser = audioContext.createAnalyser();\n//     const source = audioContext.createMediaStreamSource(mediaStream);\n//     source.connect(analyser);\n//     analyser.fftSize = 256;\n//     const bufferLength = analyser.frequencyBinCount;\n//     const dataArray = new Uint8Array(bufferLength);\n\n//     const checkSound = () => {\n//       analyser.getByteFrequencyData(dataArray);\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\n//       setSoundDetected(volume > 10);\n//       requestAnimationFrame(checkSound);\n//     };\n//     checkSound();\n//   }, [mediaStream]);\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       detectSound();\n//     }\n//   }, [permissionsGranted, detectSound]);\n\n//   useEffect(() => {\n//     if (multipleVoicesDetected) {\n//       const newViolations = violations + 1;\n//       setViolations(newViolations);\n\n//       alert(`üö® MULTIPLE VOICES DETECTED! (Violation ${newViolations}/3)`);\n\n//       if (newViolations >= 3) {\n//         setExamTerminated(true);\n//       }\n//     }\n//   }, [multipleVoicesDetected]);\n\n//   return (\n//     <div className=\"continuous-auth-container\">\n//       <h2>Exam Proctoring System</h2>\n\n//       {showPermissionMessage && (\n//         <div className=\"permission-message\">\n//           <h3>Exam Proctoring Setup</h3>\n//           <p>This exam requires camera and microphone access for proctoring purposes.</p>\n//           <div className=\"permission-requirements\">\n//             <p>‚úì Face detection must be enabled</p>\n//             <p>‚úì Microphone must be active</p>\n//           </div>\n//           <button className=\"permission-button\" onClick={getPermissions}>\n//             Enable Camera & Microphone\n//           </button>\n//         </div>\n//       )}\n\n//       {permissionsGranted && !examTerminated && (\n//         <div className=\"monitoring-container\">\n//           <div className=\"video-section\">\n//             <Webcam\n//               audio={true}\n//               ref={webcamRef}\n//               screenshotFormat=\"image/jpeg\"\n//               className=\"webcam\"\n//               videoConstraints={{\n//                 facingMode: \"user\",\n//                 width: 480,\n//                 height: 360,\n//               }}\n//             />\n//             <div className=\"status-indicators\">\n//               <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\n//                 {faceDetected ? \"Face Detected\" : \"No Face Detected\"}\n//               </div>\n//               <div className={`status-indicator ${soundDetected ? \"active\" : \"\"}`}>\n//                 {soundDetected ? \"Sound Detected\" : \"No Sound Detected\"}\n//               </div>\n//               {multipleVoicesDetected && (\n//                 <div className=\"status-indicator warning\">\n//                   Multiple Voices Detected!\n//                 </div>\n//               )}\n//             </div>\n//           </div>\n\n//           <div className=\"transcript-section\">\n//             <div className=\"transcript-box\">\n//               <div className=\"transcript-header\">\n//                 <span>Arabic Speech Transcript</span>\n//                 <span className=\"violation-counter\">Violations: {violations}/3</span>\n//               </div>\n//               <div className=\"transcript-content\" dir=\"rtl\">\n//                 {transcript || \"Waiting for audio input...\"}\n//               </div>\n//               <div className={`voice-detection-status ${multipleVoicesDetected ? \"multiple\" : \"\"}`}>\n//                 {multipleVoicesDetected \n//                   ? \"Multiple voices detected!\" \n//                   : \"Voice analysis active\"}\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//       )}\n\n//       {examTerminated && (\n//         <div className=\"termination-message\">\n//           <h3>‚úñ Exam Terminated</h3>\n//           <p>Due to multiple violations detected. Please contact your instructor.</p>\n//           <p>Total violations: {violations}</p>\n//         </div>\n//       )}\n//     </div>\n//   );\n// };\n\n// export default ContinuousAuth;\n\n//////////////////////////////////////////////////////////////////////////////////// \n\nimport React, { useState, useEffect, useRef, useCallback } from \"react\";\nimport * as faceapi from \"face-api.js\";\nimport Webcam from \"react-webcam\";\nimport \"./ContinuousAuth.css\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst ContinuousAuth = () => {\n  _s();\n  const webcamRef = useRef(null);\n  const [faceDetected, setFaceDetected] = useState(false);\n  const [soundDetected, setSoundDetected] = useState(false);\n  const [currentImage, setCurrentImage] = useState(null);\n  const [permissionsGranted, setPermissionsGranted] = useState(false);\n  const [examTerminated, setExamTerminated] = useState(false);\n  const [mediaStream, setMediaStream] = useState(null);\n  const [showPermissionMessage, setShowPermissionMessage] = useState(true);\n  const [noFaceDuration, setNoFaceDuration] = useState(0);\n  const [transcript, setTranscript] = useState(\"\");\n  const [violations, setViolations] = useState(0);\n  const recognitionRef = useRef(null);\n\n  // ŸÜÿ∏ÿßŸÖ ŸÉÿ¥ŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\n  const [multipleVoicesDetected, setMultipleVoicesDetected] = useState(false);\n  const audioContextRef = useRef(null);\n  const analyserRef = useRef(null);\n  const voiceProfileRef = useRef({\n    baseline: null,\n    lastAlert: 0,\n    active: false\n  });\n\n  // ŸÇÿßÿ¶ŸÖÿ© ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿ≠ÿ∏Ÿàÿ±ÿ© ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\n  const forbiddenWords = [\"ÿßŸÑÿßÿ¨ÿßÿ®ÿ©\", \"ÿ¨ÿßŸàÿ®\", \"ÿ≥ÿßÿπÿØŸÜŸä\", \"ÿßŸÑÿ∫ÿ¥\", \"ÿ∫ÿ¥\", \"ÿßÿ≥ÿ¶ŸÑÿ©\", \"ÿßŸÖÿ™ÿ≠ÿßŸÜ\", \"ÿßŸÑÿßŸÖÿ™ÿ≠ÿßŸÜ\", \"ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ©\", \"ÿ≠ŸÑ\", \"ÿßŸÑÿ≠ŸÑ\", \"ÿßŸÑŸÉÿ™ÿßÿ®\", \"ŸÉÿ™ÿßÿ®\", \"ÿßŸÑŸÜÿ™\", \"ŸÜÿ™\", \"ÿßŸÑÿßŸÜÿ™ÿ±ŸÜÿ™\", \"ÿßŸÜÿ™ÿ±ŸÜÿ™\", \"ÿ¨Ÿàÿ¨ŸÑ\", \"google\", \"ÿ®ÿ≠ÿ´\", \"ÿßŸÑÿ®ÿ≠ÿ´\", \"ÿ≥ÿ§ÿßŸÑ\", \"ÿßŸÑÿ≥ÿ§ÿßŸÑ\", \"ÿßŸÑŸàÿßÿ≠ÿØ\", \"ÿßÿ™ŸÜŸäŸÜ\", \"ÿ™ŸÑÿßÿ™ÿ©\", \"ÿ£ÿ±ÿ®ÿπÿ©\", \"ÿÆŸÖÿ≥ÿ©\", \"ÿ≥ÿ™ÿ©\", \"ÿ≥ÿ®ÿπÿ©\", \"ÿ™ŸÖŸÜŸäÿ©\", \"ÿ™ÿ≥ÿπÿ©\", \"ÿπÿ¥ÿ±ÿ©\", \"ÿ£\", \"ÿ®\", \"ÿ¨\", \"ÿØ\", \"ÿµÿ≠\", \"ÿ∫ŸÑÿ∑\", \"ÿµÿ≠Ÿäÿ≠\", \"ÿÆÿ∑ÿ£\", \"ÿßŸÑÿßÿÆÿ™Ÿäÿßÿ±\", \"ÿßÿÆÿ™Ÿäÿßÿ±\", \"ŸÖÿ™ÿπÿØÿØ\", \"ÿßŸÑÿßÿÆÿ™Ÿäÿßÿ±ÿßÿ™\", \"ÿßÿÆÿ™Ÿäÿßÿ±ÿßÿ™\", \"ÿßŸÑÿÆŸäÿßÿ±\", \"ÿÆŸäÿßÿ±\", \"ÿßŸÑŸÖÿ±ÿßÿ¨ÿπÿ©\", \"ŸÖÿ±ÿßÿ¨ÿπÿ©\", \"ÿßŸÑŸÖŸÑÿÆÿµ\", \"ŸÖŸÑÿÆÿµ\", \"ÿßŸÑÿØÿ±ÿ≥\", \"ÿØÿ±ÿ≥\", \"ÿßŸÑŸÖÿßÿØÿ©\", \"ŸÖÿßÿØÿ©\", \"ÿßŸÑÿ≥ŸÉÿ±ŸäŸÜ\", \"ÿ≥ŸÉÿ±ŸäŸÜ\", \"ÿ¥Ÿäÿ±\", \"ÿ¥ÿßÿ±ŸÉ\", \"ÿßŸÑŸàŸäŸÉŸä\", \"ŸàŸäŸÉŸä\", \"ŸàŸäŸÉŸäÿ®ŸäÿØŸäÿß\", \"ŸàŸäŸÉŸäÿ®ŸäÿØŸäÿß\", \"ÿµŸÅÿ≠ÿ©\", \"ÿßŸÑÿµŸÅÿ≠ÿ©\", \"ÿßŸÑŸÖŸàŸÇÿπ\", \"ŸÖŸàŸÇÿπ\", \"ÿßŸÑŸÖŸàÿßŸÇÿπ\", \"ŸÖŸàÿßŸÇÿπ\", \"ÿßŸÑÿ±ÿßÿ®ÿ∑\", \"ÿ±ÿßÿ®ÿ∑\", \"ÿßŸÑŸÑŸäŸÜŸÉ\", \"ŸÑŸäŸÜŸÉ\", \"ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ\", \"ÿ™ÿ∑ÿ®ŸäŸÇ\", \"ÿßŸÑÿ™ŸÑŸäÿ¨ÿ±ÿßŸÖ\", \"ÿ™ŸÑŸäÿ¨ÿ±ÿßŸÖ\", \"ÿßŸÑŸàÿßÿ™ÿ≥\", \"Ÿàÿßÿ™ÿ≥\", \"ÿßŸÑŸÅŸäÿ≥ÿ®ŸàŸÉ\", \"ŸÅŸäÿ≥ÿ®ŸàŸÉ\", \"ÿßŸÑŸÖÿ≥ŸÜÿ¨ÿ±\", \"ŸÖÿ≥ŸÜÿ¨ÿ±\", \"ÿßŸÑÿ™ŸàŸäÿ™ÿ±\", \"ÿ™ŸàŸäÿ™ÿ±\", \"ÿßŸÑÿßŸÜÿ≥ÿ™ÿ¨ÿ±ÿßŸÖ\", \"ÿßŸÜÿ≥ÿ™ÿ¨ÿ±ÿßŸÖ\", \"ÿßŸÑÿ™ŸäŸÉ ÿ™ŸàŸÉ\", \"ÿ™ŸäŸÉ ÿ™ŸàŸÉ\", \"ÿßŸÑŸäŸàÿ™ŸäŸàÿ®\", \"ŸäŸàÿ™ŸäŸàÿ®\", \"ÿßŸÑÿ™ŸÑŸÅŸàŸÜ\", \"ÿ™ŸÑŸÅŸàŸÜ\", \"ÿßŸÑŸÖŸàÿ®ÿßŸäŸÑ\", \"ŸÖŸàÿ®ÿßŸäŸÑ\", \"ÿßŸÑÿ¨ŸàÿßŸÑ\", \"ÿ¨ŸàÿßŸÑ\", \"ÿßŸÑŸÉŸÖÿ®ŸäŸàÿ™ÿ±\", \"ŸÉŸÖÿ®ŸäŸàÿ™ÿ±\", \"ÿßŸÑŸÑÿßÿ®\", \"ŸÑÿßÿ®\", \"ÿßŸÑÿ™ÿßÿ®\", \"ÿ™ÿßÿ®\", \"ÿßŸÑÿßŸäÿ®ÿßÿØ\", \"ÿßŸäÿ®ÿßÿØ\", \"ÿßŸÑÿßŸäŸÅŸàŸÜ\", \"ÿßŸäŸÅŸàŸÜ\", \"ÿßŸÑÿßŸÜÿØÿ±ŸàŸäÿØ\", \"ÿßŸÜÿØÿ±ŸàŸäÿØ\", \"ÿßŸÑŸàŸäŸÜÿØŸàÿ≤\", \"ŸàŸäŸÜÿØŸàÿ≤\", \"ÿßŸÑŸÖÿßŸÉ\", \"ŸÖÿßŸÉ\", \"ÿßŸÑŸÑÿßÿ®ÿ™Ÿàÿ®\", \"ŸÑÿßÿ®ÿ™Ÿàÿ®\", \"ÿßŸÑÿØŸäÿ≥ŸÉÿ™Ÿàÿ®\", \"ÿØŸäÿ≥ŸÉÿ™Ÿàÿ®\", \"ÿßŸÑÿ™ÿßÿ®ŸÑÿ™\", \"ÿ™ÿßÿ®ŸÑÿ™\", \"ÿßŸÑÿ≥ŸÖÿßÿ±ÿ™\", \"ÿ≥ŸÖÿßÿ±ÿ™\", \"ÿßŸÑŸÅŸàŸÜ\", \"ŸÅŸàŸÜ\", \"ÿßŸÑÿ™ÿßÿ®\", \"ÿ™ÿßÿ®\", \"ÿßŸÑŸÑÿßÿ®\", \"ŸÑÿßÿ®\", \"ÿßŸÑÿ™ÿßÿ®\", \"ÿßŸÑŸÑÿßÿ®\", \"ÿßŸÑÿ™ÿßÿ®\", \"ÿßŸÑŸÑÿßÿ®\", \"ÿßŸÑÿ™ÿßÿ®\", \"ÿßŸÑŸÑÿßÿ®\", \"ÿßŸÑÿ™ÿßÿ®\", \"ÿßŸÑŸÑÿßÿ®\", \"ÿßŸÑÿ™ÿßÿ®\"];\n  useEffect(() => {\n    const loadModels = async () => {\n      await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\n      console.log(\"Face Detection Model Loaded\");\n    };\n    loadModels();\n  }, []);\n  const getPermissions = async () => {\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({\n        video: true,\n        audio: true\n      });\n      setMediaStream(stream);\n      setPermissionsGranted(true);\n      setShowPermissionMessage(false);\n      initializeSpeechRecognition();\n      setupVoiceAnalysis(stream);\n    } catch (error) {\n      alert(\"Please allow access to camera and microphone.\");\n      setShowPermissionMessage(true);\n    }\n  };\n\n  // ŸÜÿ∏ÿßŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\n  const setupVoiceAnalysis = stream => {\n    try {\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n      analyserRef.current = audioContextRef.current.createAnalyser();\n      analyserRef.current.fftSize = 4096;\n      const source = audioContextRef.current.createMediaStreamSource(stream);\n      source.connect(analyserRef.current);\n\n      // ÿ•ŸÜÿ¥ÿßÿ° ÿ®ÿµŸÖÿ© ÿµŸàÿ™Ÿäÿ© ÿ£ŸàŸÑŸäÿ© ÿ®ÿπÿØ 3 ÿ´ŸàÿßŸÜŸä\n      setTimeout(() => {\n        voiceProfileRef.current.baseline = createVoiceProfile();\n        voiceProfileRef.current.active = true;\n      }, 3000);\n      const analyzeVoice = () => {\n        if (!voiceProfileRef.current.active) {\n          requestAnimationFrame(analyzeVoice);\n          return;\n        }\n        const currentProfile = createVoiceProfile();\n        const isMultiple = compareVoiceProfiles(voiceProfileRef.current.baseline, currentProfile);\n        if (isMultiple && Date.now() - voiceProfileRef.current.lastAlert > 5000) {\n          setMultipleVoicesDetected(true);\n          voiceProfileRef.current.lastAlert = Date.now();\n        } else {\n          setMultipleVoicesDetected(false);\n        }\n        requestAnimationFrame(analyzeVoice);\n      };\n      analyzeVoice();\n    } catch (error) {\n      console.error(\"Voice analysis error:\", error);\n    }\n  };\n  const createVoiceProfile = () => {\n    const bufferLength = analyserRef.current.frequencyBinCount;\n    const dataArray = new Float32Array(bufferLength);\n    analyserRef.current.getFloatFrequencyData(dataArray);\n    const profile = {\n      lowRange: 0,\n      // 85-300Hz\n      midRange: 0,\n      // 300-1000Hz\n      highRange: 0,\n      // 1000-4000Hz\n      peakCount: 0,\n      totalEnergy: 0\n    };\n    for (let i = 0; i < bufferLength; i++) {\n      const freq = i * audioContextRef.current.sampleRate / analyserRef.current.fftSize;\n      const value = Math.pow(10, dataArray[i] / 20); // Convert dB to linear\n\n      if (freq >= 85 && freq < 300) {\n        profile.lowRange += value;\n      } else if (freq >= 300 && freq < 1000) {\n        profile.midRange += value;\n      } else if (freq >= 1000 && freq < 4000) {\n        profile.highRange += value;\n      }\n      if (dataArray[i] > -40) profile.peakCount++;\n      profile.totalEnergy += value;\n    }\n    return profile;\n  };\n  const compareVoiceProfiles = (baseline, current) => {\n    // ÿ≠ÿ≥ÿßÿ® ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ™ÿ∫Ÿäÿ± ŸÑŸÉŸÑ ŸÜÿ∑ÿßŸÇ ÿ™ÿ±ÿØÿØŸä\n    const lowDiff = Math.abs(current.lowRange - baseline.lowRange) / baseline.lowRange;\n    const midDiff = Math.abs(current.midRange - baseline.midRange) / baseline.midRange;\n    const highDiff = Math.abs(current.highRange - baseline.highRange) / baseline.highRange;\n    const energyDiff = Math.abs(current.totalEnergy - baseline.totalEnergy) / baseline.totalEnergy;\n    const peakDiff = Math.abs(current.peakCount - baseline.peakCount);\n\n    // ÿ¥ÿ±Ÿàÿ∑ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ©\n    return (lowDiff > 0.6 || midDiff > 0.6 || highDiff > 0.6) && energyDiff > 0.4 && peakDiff > 15;\n  };\n  const checkForForbiddenWords = text => {\n    const words = text.split(/\\s+/);\n    let foundWords = [];\n    words.forEach(word => {\n      if (forbiddenWords.includes(word.toLowerCase())) {\n        foundWords.push(word);\n      }\n    });\n    if (foundWords.length > 0) {\n      const newViolations = violations + foundWords.length;\n      setViolations(newViolations);\n      alert(`üö® FORBIDDEN WORDS DETECTED: ${foundWords.join(', ')} (Violation ${newViolations}/3)`);\n      if (newViolations >= 3) {\n        setExamTerminated(true);\n      }\n    }\n  };\n  const initializeSpeechRecognition = () => {\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!SpeechRecognition) {\n      console.error(\"Speech Recognition API not supported in this browser\");\n      return;\n    }\n    recognitionRef.current = new SpeechRecognition();\n    recognitionRef.current.continuous = true;\n    recognitionRef.current.interimResults = false;\n    recognitionRef.current.lang = \"ar-SA\";\n    recognitionRef.current.onresult = event => {\n      const last = event.results.length - 1;\n      const text = event.results[last][0].transcript;\n      setTranscript(text);\n      checkForForbiddenWords(text);\n    };\n    recognitionRef.current.onerror = event => {\n      console.error(\"Speech recognition error\", event.error);\n    };\n    recognitionRef.current.start();\n    recognitionRef.current.onend = () => {\n      recognitionRef.current.start();\n    };\n  };\n  useEffect(() => {\n    if (mediaStream) {\n      const tracks = mediaStream.getTracks();\n      tracks.forEach(track => {\n        track.enabled = true;\n      });\n    }\n    return () => {\n      if (recognitionRef.current) {\n        recognitionRef.current.stop();\n      }\n      if (audioContextRef.current) {\n        audioContextRef.current.close();\n      }\n    };\n  }, [mediaStream]);\n  const detectFace = async () => {\n    if (webcamRef.current && webcamRef.current.video.readyState === 4) {\n      const video = webcamRef.current.video;\n      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n      const isFacePresent = detections.length > 0;\n      setFaceDetected(isFacePresent);\n      setNoFaceDuration(prev => isFacePresent ? 0 : prev + 1);\n    }\n  };\n  useEffect(() => {\n    if (permissionsGranted) {\n      const interval = setInterval(detectFace, 1000);\n      return () => clearInterval(interval);\n    }\n  }, [permissionsGranted]);\n  useEffect(() => {\n    if (noFaceDuration >= 15) {\n      alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\n      setNoFaceDuration(0);\n    }\n  }, [noFaceDuration]);\n  const detectSound = useCallback(() => {\n    if (!mediaStream) return;\n    const audioContext = new AudioContext();\n    const analyser = audioContext.createAnalyser();\n    const source = audioContext.createMediaStreamSource(mediaStream);\n    source.connect(analyser);\n    analyser.fftSize = 256;\n    const bufferLength = analyser.frequencyBinCount;\n    const dataArray = new Uint8Array(bufferLength);\n    const checkSound = () => {\n      analyser.getByteFrequencyData(dataArray);\n      const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\n      setSoundDetected(volume > 10);\n      requestAnimationFrame(checkSound);\n    };\n    checkSound();\n  }, [mediaStream]);\n  useEffect(() => {\n    if (permissionsGranted) {\n      detectSound();\n    }\n  }, [permissionsGranted, detectSound]);\n  useEffect(() => {\n    if (multipleVoicesDetected) {\n      const newViolations = violations + 1;\n      setViolations(newViolations);\n      alert(`üö® MULTIPLE VOICES DETECTED! (Violation ${newViolations}/3)`);\n      if (newViolations >= 3) {\n        setExamTerminated(true);\n      }\n    }\n  }, [multipleVoicesDetected]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"continuous-auth-container\",\n    children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n      children: \"Exam Proctoring System\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 806,\n      columnNumber: 7\n    }, this), showPermissionMessage && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"permission-message\",\n      children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n        children: \"Exam Proctoring Setup\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 810,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"This exam requires camera and microphone access for proctoring purposes.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 811,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"permission-requirements\",\n        children: [/*#__PURE__*/_jsxDEV(\"p\", {\n          children: \"\\u2713 Face detection must be enabled\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 813,\n          columnNumber: 13\n        }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n          children: \"\\u2713 Microphone must be active\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 814,\n          columnNumber: 13\n        }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n          children: \"\\u2713 Forbidden words monitoring is active\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 815,\n          columnNumber: 13\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 812,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n        className: \"permission-button\",\n        onClick: getPermissions,\n        children: \"Enable Camera & Microphone\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 817,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 809,\n      columnNumber: 9\n    }, this), permissionsGranted && !examTerminated && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"monitoring-container\",\n      children: [/*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"video-section\",\n        children: [/*#__PURE__*/_jsxDEV(Webcam, {\n          audio: true,\n          ref: webcamRef,\n          screenshotFormat: \"image/jpeg\",\n          className: \"webcam\",\n          videoConstraints: {\n            facingMode: \"user\",\n            width: 480,\n            height: 360\n          }\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 826,\n          columnNumber: 13\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"status-indicators\",\n          children: [/*#__PURE__*/_jsxDEV(\"div\", {\n            className: `status-indicator ${faceDetected ? \"active\" : \"\"}`,\n            children: faceDetected ? \"Face Detected\" : \"No Face Detected\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 838,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: `status-indicator ${soundDetected ? \"active\" : \"\"}`,\n            children: soundDetected ? \"Sound Detected\" : \"No Sound Detected\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 841,\n            columnNumber: 15\n          }, this), multipleVoicesDetected && /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"status-indicator warning\",\n            children: \"Multiple Voices Detected!\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 845,\n            columnNumber: 17\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 837,\n          columnNumber: 13\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 825,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"transcript-section\",\n        children: /*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"transcript-box\",\n          children: [/*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"transcript-header\",\n            children: [/*#__PURE__*/_jsxDEV(\"span\", {\n              children: \"Arabic Speech Transcript\"\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 855,\n              columnNumber: 17\n            }, this), /*#__PURE__*/_jsxDEV(\"span\", {\n              className: \"violation-counter\",\n              children: [\"Violations: \", violations, \"/3\"]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 856,\n              columnNumber: 17\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 854,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"transcript-content\",\n            dir: \"rtl\",\n            children: transcript || \"Waiting for audio input...\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 858,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: `voice-detection-status ${multipleVoicesDetected ? \"multiple\" : \"\"}`,\n            children: multipleVoicesDetected ? \"Multiple voices detected!\" : \"Voice analysis active\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 861,\n            columnNumber: 15\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 853,\n          columnNumber: 13\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 852,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 824,\n      columnNumber: 9\n    }, this), examTerminated && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"termination-message\",\n      children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n        children: \"\\u2716 Exam Terminated\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 873,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"Due to multiple violations detected. Please contact your instructor.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 874,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: [\"Total violations: \", violations]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 875,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: [\"Termination reason: \", multipleVoicesDetected ? \"Multiple voices detected\" : \"Forbidden words detected\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 876,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 872,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 805,\n    columnNumber: 5\n  }, this);\n};\n_s(ContinuousAuth, \"Mrpqo08g+jRfCEOTMJbJsAww2l0=\");\n_c = ContinuousAuth;\nexport default ContinuousAuth;\nvar _c;\n$RefreshReg$(_c, \"ContinuousAuth\");","map":{"version":3,"names":["React","useState","useEffect","useRef","useCallback","faceapi","Webcam","jsxDEV","_jsxDEV","ContinuousAuth","_s","webcamRef","faceDetected","setFaceDetected","soundDetected","setSoundDetected","currentImage","setCurrentImage","permissionsGranted","setPermissionsGranted","examTerminated","setExamTerminated","mediaStream","setMediaStream","showPermissionMessage","setShowPermissionMessage","noFaceDuration","setNoFaceDuration","transcript","setTranscript","violations","setViolations","recognitionRef","multipleVoicesDetected","setMultipleVoicesDetected","audioContextRef","analyserRef","voiceProfileRef","baseline","lastAlert","active","forbiddenWords","loadModels","nets","tinyFaceDetector","loadFromUri","console","log","getPermissions","stream","navigator","mediaDevices","getUserMedia","video","audio","initializeSpeechRecognition","setupVoiceAnalysis","error","alert","current","window","AudioContext","webkitAudioContext","createAnalyser","fftSize","source","createMediaStreamSource","connect","setTimeout","createVoiceProfile","analyzeVoice","requestAnimationFrame","currentProfile","isMultiple","compareVoiceProfiles","Date","now","bufferLength","frequencyBinCount","dataArray","Float32Array","getFloatFrequencyData","profile","lowRange","midRange","highRange","peakCount","totalEnergy","i","freq","sampleRate","value","Math","pow","lowDiff","abs","midDiff","highDiff","energyDiff","peakDiff","checkForForbiddenWords","text","words","split","foundWords","forEach","word","includes","toLowerCase","push","length","newViolations","join","SpeechRecognition","webkitSpeechRecognition","continuous","interimResults","lang","onresult","event","last","results","onerror","start","onend","tracks","getTracks","track","enabled","stop","close","detectFace","readyState","detections","detectAllFaces","TinyFaceDetectorOptions","isFacePresent","prev","interval","setInterval","clearInterval","detectSound","audioContext","analyser","Uint8Array","checkSound","getByteFrequencyData","volume","reduce","sum","className","children","fileName","_jsxFileName","lineNumber","columnNumber","onClick","ref","screenshotFormat","videoConstraints","facingMode","width","height","dir","_c","$RefreshReg$"],"sources":["C:/Users/HP/Desktop/continous-authentication1/continous-authentication1/continous-authentication/continous-authentication/src/ContinuousAuth.js"],"sourcesContent":["// import React, { useState, useEffect, useRef, useCallback } from \"react\";\r\n// import * as faceapi from \"face-api.js\";\r\n// import Webcam from \"react-webcam\";\r\n// import axios from \"axios\";\r\n// import \"./ContinuousAuth.css\";\r\n\r\n// const ContinuousAuth = () => {\r\n//   const webcamRef = useRef(null);\r\n//   const [faceDetected, setFaceDetected] = useState(false);\r\n//   const [soundDetected, setSoundDetected] = useState(false);\r\n//   const [currentImage, setCurrentImage] = useState(null);\r\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\r\n//   const [examTerminated, setExamTerminated] = useState(false);\r\n//   const [mediaStream, setMediaStream] = useState(null);\r\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\r\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\r\n\r\n//   useEffect(() => {\r\n//     const loadModels = async () => {\r\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\r\n//       console.log(\"Face Detection Model Loaded\");\r\n//     };\r\n//     loadModels();\r\n//   }, []);\r\n\r\n//   const getPermissions = async () => {\r\n//     try {\r\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\r\n//       setMediaStream(stream);\r\n//       setPermissionsGranted(true);\r\n//       setShowPermissionMessage(false);\r\n//       fetchIpAddress(); // Call to fetch IP address when permissions are granted\r\n//     } catch (error) {\r\n//       alert(\"Please allow access to camera and microphone.\");\r\n//       setShowPermissionMessage(true);\r\n//     }\r\n//   };\r\n\r\n//   const fetchIpAddress = async () => {\r\n//     try {\r\n//       const response = await fetch(\"https://api.ipify.org?format=json\");\r\n//       const data = await response.json();\r\n//       alert(`Your IP Address: ${data.ip}`);\r\n//     } catch (error) {\r\n//       console.error(\"Error fetching IP address:\", error);\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (mediaStream) {\r\n//       const tracks = mediaStream.getTracks();\r\n//       tracks.forEach((track) => {\r\n//         track.enabled = true;\r\n//       });\r\n//     }\r\n//   }, [mediaStream]);\r\n\r\n//   const detectFace = async () => {\r\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\r\n//       const video = webcamRef.current.video;\r\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\r\n//       const isFacePresent = detections.length > 0;\r\n//       setFaceDetected(isFacePresent);\r\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       const interval = setInterval(detectFace, 1000);\r\n//       return () => clearInterval(interval);\r\n//     }\r\n//   }, [permissionsGranted]);\r\n\r\n//   useEffect(() => {\r\n//     if (noFaceDuration >= 15) {\r\n//       alert(\"‚ö†Ô∏è Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\r\n//       setNoFaceDuration(0);\r\n//     }\r\n//   }, [noFaceDuration]);\r\n\r\n//   const detectSound = useCallback(() => {\r\n//     if (!mediaStream) return;\r\n\r\n//     const audioContext = new AudioContext();\r\n//     const analyser = audioContext.createAnalyser();\r\n//     const source = audioContext.createMediaStreamSource(mediaStream);\r\n//     source.connect(analyser);\r\n//     analyser.fftSize = 256;\r\n//     const bufferLength = analyser.frequencyBinCount;\r\n//     const dataArray = new Uint8Array(bufferLength);\r\n\r\n//     const checkSound = () => {\r\n//       analyser.getByteFrequencyData(dataArray);\r\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\r\n//       setSoundDetected(volume > 10);\r\n//       requestAnimationFrame(checkSound);\r\n//     };\r\n//     checkSound();\r\n//   }, [mediaStream]);\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       detectSound();\r\n//     }\r\n//   }, [permissionsGranted, detectSound]);\r\n\r\n//   return (\r\n//     <div className=\"continuous-auth-container\">\r\n//       <h2>Continuous Authentication</h2>\r\n\r\n//       {showPermissionMessage && (\r\n//         <div className=\"permission-message\">\r\n//           <p>Please allow access to your camera and microphone to start the exam.</p>\r\n//           <button onClick={getPermissions}>Allow Camera and Microphone</button>\r\n//         </div>\r\n//       )}\r\n\r\n//       {permissionsGranted ? (\r\n//         <>\r\n//           <Webcam\r\n//             audio={true}\r\n//             ref={webcamRef}\r\n//             screenshotFormat=\"image/jpeg\"\r\n//             className=\"webcam\"\r\n//             videoConstraints={{\r\n//               facingMode: \"user\",\r\n//               width: 720,\r\n//               height: 400,\r\n//             }}\r\n//           />\r\n//           <p>Camera and microphone are active for proctoring.</p>\r\n\r\n//           <div className=\"status-buttons-container\">\r\n//             <div className=\"status-buttons\">\r\n//               <button className={faceDetected ? \"detected-btn\" : \"not-detected-btn\"}>\r\n//                 {faceDetected ? \"Face Detected ‚úÖ\" : \"No Face Detected ‚ùå\"}\r\n//               </button>\r\n//               <button className={soundDetected ? \"detected-btn\" : \"not-detected-btn\"}>\r\n//                 {soundDetected ? \"Sound Detected üîä\" : \"No Sound Detected üîá\"}\r\n//               </button>\r\n//             </div>\r\n\r\n//             <div className=\"captured-images\">\r\n//               {currentImage && <img src={currentImage} alt=\"Captured\" className=\"small-image\" />}\r\n//             </div>\r\n//           </div>\r\n//         </>\r\n//       ) : (\r\n//         <p>Waiting for camera and microphone access...</p>\r\n//       )}\r\n\r\n//       {examTerminated && <p className=\"mismatch-count\">Exam Terminated due to 3 mismatches.</p>}\r\n//     </div>\r\n//   );\r\n// };\r\n\r\n// export default ContinuousAuth;\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\r\n// import * as faceapi from \"face-api.js\";\r\n// import Webcam from \"react-webcam\";\r\n// import \"./ContinuousAuth.css\";\r\n\r\n// const ContinuousAuth = () => {\r\n//   const webcamRef = useRef(null);\r\n//   const [faceDetected, setFaceDetected] = useState(false);\r\n//   const [soundDetected, setSoundDetected] = useState(false);\r\n//   const [currentImage, setCurrentImage] = useState(null);\r\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\r\n//   const [examTerminated, setExamTerminated] = useState(false);\r\n//   const [mediaStream, setMediaStream] = useState(null);\r\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\r\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\r\n//   const [transcript, setTranscript] = useState(\"\");\r\n//   const [violations, setViolations] = useState(0);\r\n//   const recognitionRef = useRef(null);\r\n\r\n//   // ŸÜÿ∏ÿßŸÖ ŸÉÿ¥ŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\r\n//   const [multipleVoicesDetected, setMultipleVoicesDetected] = useState(false);\r\n//   const audioContextRef = useRef(null);\r\n//   const analyserRef = useRef(null);\r\n//   const voiceProfileRef = useRef({\r\n//     baseline: null,\r\n//     lastAlert: 0,\r\n//     active: false\r\n//   });\r\n\r\n//   useEffect(() => {\r\n//     const loadModels = async () => {\r\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\r\n//       console.log(\"Face Detection Model Loaded\");\r\n//     };\r\n//     loadModels();\r\n//   }, []);\r\n\r\n//   const getPermissions = async () => {\r\n//     try {\r\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\r\n//       setMediaStream(stream);\r\n//       setPermissionsGranted(true);\r\n//       setShowPermissionMessage(false);\r\n//       initializeSpeechRecognition();\r\n//       setupVoiceAnalysis(stream);\r\n//     } catch (error) {\r\n//       alert(\"Please allow access to camera and microphone.\");\r\n//       setShowPermissionMessage(true);\r\n//     }\r\n//   };\r\n\r\n//   // ŸÜÿ∏ÿßŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\r\n//   const setupVoiceAnalysis = (stream) => {\r\n//     try {\r\n//       audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\r\n//       analyserRef.current = audioContextRef.current.createAnalyser();\r\n//       analyserRef.current.fftSize = 4096;\r\n      \r\n//       const source = audioContextRef.current.createMediaStreamSource(stream);\r\n//       source.connect(analyserRef.current);\r\n\r\n//       // ÿ•ŸÜÿ¥ÿßÿ° ÿ®ÿµŸÖÿ© ÿµŸàÿ™Ÿäÿ© ÿ£ŸàŸÑŸäÿ© ÿ®ÿπÿØ 3 ÿ´ŸàÿßŸÜŸä\r\n//       setTimeout(() => {\r\n//         voiceProfileRef.current.baseline = createVoiceProfile();\r\n//         voiceProfileRef.current.active = true;\r\n//       }, 3000);\r\n\r\n//       const analyzeVoice = () => {\r\n//         if (!voiceProfileRef.current.active) {\r\n//           requestAnimationFrame(analyzeVoice);\r\n//           return;\r\n//         }\r\n\r\n//         const currentProfile = createVoiceProfile();\r\n//         const isMultiple = compareVoiceProfiles(voiceProfileRef.current.baseline, currentProfile);\r\n        \r\n//         if (isMultiple && Date.now() - voiceProfileRef.current.lastAlert > 5000) {\r\n//           setMultipleVoicesDetected(true);\r\n//           voiceProfileRef.current.lastAlert = Date.now();\r\n//         } else {\r\n//           setMultipleVoicesDetected(false);\r\n//         }\r\n\r\n//         requestAnimationFrame(analyzeVoice);\r\n//       };\r\n\r\n//       analyzeVoice();\r\n//     } catch (error) {\r\n//       console.error(\"Voice analysis error:\", error);\r\n//     }\r\n//   };\r\n\r\n//   const createVoiceProfile = () => {\r\n//     const bufferLength = analyserRef.current.frequencyBinCount;\r\n//     const dataArray = new Float32Array(bufferLength);\r\n//     analyserRef.current.getFloatFrequencyData(dataArray);\r\n\r\n//     const profile = {\r\n//       lowRange: 0,    // 85-300Hz\r\n//       midRange: 0,    // 300-1000Hz\r\n//       highRange: 0,   // 1000-4000Hz\r\n//       peakCount: 0,\r\n//       totalEnergy: 0\r\n//     };\r\n\r\n//     for (let i = 0; i < bufferLength; i++) {\r\n//       const freq = i * audioContextRef.current.sampleRate / analyserRef.current.fftSize;\r\n//       const value = Math.pow(10, dataArray[i]/20); // Convert dB to linear\r\n\r\n//       if (freq >= 85 && freq < 300) {\r\n//         profile.lowRange += value;\r\n//       } else if (freq >= 300 && freq < 1000) {\r\n//         profile.midRange += value;\r\n//       } else if (freq >= 1000 && freq < 4000) {\r\n//         profile.highRange += value;\r\n//       }\r\n\r\n//       if (dataArray[i] > -40) profile.peakCount++;\r\n//       profile.totalEnergy += value;\r\n//     }\r\n\r\n//     return profile;\r\n//   };\r\n\r\n//   const compareVoiceProfiles = (baseline, current) => {\r\n//     // ÿ≠ÿ≥ÿßÿ® ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ™ÿ∫Ÿäÿ± ŸÑŸÉŸÑ ŸÜÿ∑ÿßŸÇ ÿ™ÿ±ÿØÿØŸä\r\n//     const lowDiff = Math.abs(current.lowRange - baseline.lowRange) / baseline.lowRange;\r\n//     const midDiff = Math.abs(current.midRange - baseline.midRange) / baseline.midRange;\r\n//     const highDiff = Math.abs(current.highRange - baseline.highRange) / baseline.highRange;\r\n//     const energyDiff = Math.abs(current.totalEnergy - baseline.totalEnergy) / baseline.totalEnergy;\r\n//     const peakDiff = Math.abs(current.peakCount - baseline.peakCount);\r\n\r\n//     // ÿ¥ÿ±Ÿàÿ∑ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ©\r\n//     return (\r\n//       (lowDiff > 0.6 || midDiff > 0.6 || highDiff > 0.6) &&\r\n//       energyDiff > 0.4 &&\r\n//       peakDiff > 15\r\n//     );\r\n//   };\r\n\r\n//   const initializeSpeechRecognition = () => {\r\n//     const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n//     if (!SpeechRecognition) {\r\n//       console.error(\"Speech Recognition API not supported in this browser\");\r\n//       return;\r\n//     }\r\n\r\n//     recognitionRef.current = new SpeechRecognition();\r\n//     recognitionRef.current.continuous = true;\r\n//     recognitionRef.current.interimResults = false;\r\n//     recognitionRef.current.lang = \"ar-SA\";\r\n\r\n//     recognitionRef.current.onresult = (event) => {\r\n//       const last = event.results.length - 1;\r\n//       const text = event.results[last][0].transcript;\r\n//       setTranscript(text);\r\n//     };\r\n\r\n//     recognitionRef.current.onerror = (event) => {\r\n//       console.error(\"Speech recognition error\", event.error);\r\n//     };\r\n\r\n//     recognitionRef.current.start();\r\n//     recognitionRef.current.onend = () => {\r\n//       recognitionRef.current.start();\r\n//     };\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (mediaStream) {\r\n//       const tracks = mediaStream.getTracks();\r\n//       tracks.forEach((track) => {\r\n//         track.enabled = true;\r\n//       });\r\n//     }\r\n\r\n//     return () => {\r\n//       if (recognitionRef.current) {\r\n//         recognitionRef.current.stop();\r\n//       }\r\n//       if (audioContextRef.current) {\r\n//         audioContextRef.current.close();\r\n//       }\r\n//     };\r\n//   }, [mediaStream]);\r\n\r\n//   const detectFace = async () => {\r\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\r\n//       const video = webcamRef.current.video;\r\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\r\n//       const isFacePresent = detections.length > 0;\r\n//       setFaceDetected(isFacePresent);\r\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       const interval = setInterval(detectFace, 1000);\r\n//       return () => clearInterval(interval);\r\n//     }\r\n//   }, [permissionsGranted]);\r\n\r\n//   useEffect(() => {\r\n//     if (noFaceDuration >= 15) {\r\n//       alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\r\n//       setNoFaceDuration(0);\r\n//     }\r\n//   }, [noFaceDuration]);\r\n\r\n//   const detectSound = useCallback(() => {\r\n//     if (!mediaStream) return;\r\n\r\n//     const audioContext = new AudioContext();\r\n//     const analyser = audioContext.createAnalyser();\r\n//     const source = audioContext.createMediaStreamSource(mediaStream);\r\n//     source.connect(analyser);\r\n//     analyser.fftSize = 256;\r\n//     const bufferLength = analyser.frequencyBinCount;\r\n//     const dataArray = new Uint8Array(bufferLength);\r\n\r\n//     const checkSound = () => {\r\n//       analyser.getByteFrequencyData(dataArray);\r\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\r\n//       setSoundDetected(volume > 10);\r\n//       requestAnimationFrame(checkSound);\r\n//     };\r\n//     checkSound();\r\n//   }, [mediaStream]);\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       detectSound();\r\n//     }\r\n//   }, [permissionsGranted, detectSound]);\r\n\r\n//   useEffect(() => {\r\n//     if (multipleVoicesDetected) {\r\n//       const newViolations = violations + 1;\r\n//       setViolations(newViolations);\r\n      \r\n//       alert(`üö® MULTIPLE VOICES DETECTED! (Violation ${newViolations}/3)`);\r\n      \r\n//       if (newViolations >= 3) {\r\n//         setExamTerminated(true);\r\n//       }\r\n//     }\r\n//   }, [multipleVoicesDetected]);\r\n\r\n//   return (\r\n//     <div className=\"continuous-auth-container\">\r\n//       <h2>Exam Proctoring System</h2>\r\n\r\n//       {showPermissionMessage && (\r\n//         <div className=\"permission-message\">\r\n//           <h3>Exam Proctoring Setup</h3>\r\n//           <p>This exam requires camera and microphone access for proctoring purposes.</p>\r\n//           <div className=\"permission-requirements\">\r\n//             <p>‚úì Face detection must be enabled</p>\r\n//             <p>‚úì Microphone must be active</p>\r\n//           </div>\r\n//           <button className=\"permission-button\" onClick={getPermissions}>\r\n//             Enable Camera & Microphone\r\n//           </button>\r\n//         </div>\r\n//       )}\r\n\r\n//       {permissionsGranted && !examTerminated && (\r\n//         <div className=\"monitoring-container\">\r\n//           <div className=\"video-section\">\r\n//             <Webcam\r\n//               audio={true}\r\n//               ref={webcamRef}\r\n//               screenshotFormat=\"image/jpeg\"\r\n//               className=\"webcam\"\r\n//               videoConstraints={{\r\n//                 facingMode: \"user\",\r\n//                 width: 480,\r\n//                 height: 360,\r\n//               }}\r\n//             />\r\n//             <div className=\"status-indicators\">\r\n//               <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\r\n//                 {faceDetected ? \"Face Detected\" : \"No Face Detected\"}\r\n//               </div>\r\n//               <div className={`status-indicator ${soundDetected ? \"active\" : \"\"}`}>\r\n//                 {soundDetected ? \"Sound Detected\" : \"No Sound Detected\"}\r\n//               </div>\r\n//               {multipleVoicesDetected && (\r\n//                 <div className=\"status-indicator warning\">\r\n//                   Multiple Voices Detected!\r\n//                 </div>\r\n//               )}\r\n//             </div>\r\n//           </div>\r\n\r\n//           <div className=\"transcript-section\">\r\n//             <div className=\"transcript-box\">\r\n//               <div className=\"transcript-header\">\r\n//                 <span>Arabic Speech Transcript</span>\r\n//                 <span className=\"violation-counter\">Violations: {violations}/3</span>\r\n//               </div>\r\n//               <div className=\"transcript-content\" dir=\"rtl\">\r\n//                 {transcript || \"Waiting for audio input...\"}\r\n//               </div>\r\n//               <div className={`voice-detection-status ${multipleVoicesDetected ? \"multiple\" : \"\"}`}>\r\n//                 {multipleVoicesDetected \r\n//                   ? \"Multiple voices detected!\" \r\n//                   : \"Voice analysis active\"}\r\n//               </div>\r\n//             </div>\r\n//           </div>\r\n//         </div>\r\n//       )}\r\n\r\n//       {examTerminated && (\r\n//         <div className=\"termination-message\">\r\n//           <h3>‚úñ Exam Terminated</h3>\r\n//           <p>Due to multiple violations detected. Please contact your instructor.</p>\r\n//           <p>Total violations: {violations}</p>\r\n//         </div>\r\n//       )}\r\n//     </div>\r\n//   );\r\n// };\r\n\r\n// export default ContinuousAuth;\r\n\r\n\r\n\r\n\r\n//////////////////////////////////////////////////////////////////////////////////// \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nimport React, { useState, useEffect, useRef, useCallback } from \"react\";\r\nimport * as faceapi from \"face-api.js\";\r\nimport Webcam from \"react-webcam\";\r\nimport \"./ContinuousAuth.css\";\r\n\r\nconst ContinuousAuth = () => {\r\n  const webcamRef = useRef(null);\r\n  const [faceDetected, setFaceDetected] = useState(false);\r\n  const [soundDetected, setSoundDetected] = useState(false);\r\n  const [currentImage, setCurrentImage] = useState(null);\r\n  const [permissionsGranted, setPermissionsGranted] = useState(false);\r\n  const [examTerminated, setExamTerminated] = useState(false);\r\n  const [mediaStream, setMediaStream] = useState(null);\r\n  const [showPermissionMessage, setShowPermissionMessage] = useState(true);\r\n  const [noFaceDuration, setNoFaceDuration] = useState(0);\r\n  const [transcript, setTranscript] = useState(\"\");\r\n  const [violations, setViolations] = useState(0);\r\n  const recognitionRef = useRef(null);\r\n\r\n  // ŸÜÿ∏ÿßŸÖ ŸÉÿ¥ŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\r\n  const [multipleVoicesDetected, setMultipleVoicesDetected] = useState(false);\r\n  const audioContextRef = useRef(null);\r\n  const analyserRef = useRef(null);\r\n  const voiceProfileRef = useRef({\r\n    baseline: null,\r\n    lastAlert: 0,\r\n    active: false\r\n  });\r\n\r\n  // ŸÇÿßÿ¶ŸÖÿ© ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖÿ≠ÿ∏Ÿàÿ±ÿ© ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\r\n  const forbiddenWords = [\r\n    \"ÿßŸÑÿßÿ¨ÿßÿ®ÿ©\", \"ÿ¨ÿßŸàÿ®\", \"ÿ≥ÿßÿπÿØŸÜŸä\", \"ÿßŸÑÿ∫ÿ¥\", \"ÿ∫ÿ¥\", \"ÿßÿ≥ÿ¶ŸÑÿ©\", \"ÿßŸÖÿ™ÿ≠ÿßŸÜ\", \r\n    \"ÿßŸÑÿßŸÖÿ™ÿ≠ÿßŸÜ\", \"ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ©\", \"ÿ≠ŸÑ\", \"ÿßŸÑÿ≠ŸÑ\", \"ÿßŸÑŸÉÿ™ÿßÿ®\", \"ŸÉÿ™ÿßÿ®\", \"ÿßŸÑŸÜÿ™\", \r\n    \"ŸÜÿ™\", \"ÿßŸÑÿßŸÜÿ™ÿ±ŸÜÿ™\", \"ÿßŸÜÿ™ÿ±ŸÜÿ™\", \"ÿ¨Ÿàÿ¨ŸÑ\", \"google\", \"ÿ®ÿ≠ÿ´\", \"ÿßŸÑÿ®ÿ≠ÿ´\",\r\n    \"ÿ≥ÿ§ÿßŸÑ\", \"ÿßŸÑÿ≥ÿ§ÿßŸÑ\", \"ÿßŸÑŸàÿßÿ≠ÿØ\", \"ÿßÿ™ŸÜŸäŸÜ\", \"ÿ™ŸÑÿßÿ™ÿ©\", \"ÿ£ÿ±ÿ®ÿπÿ©\", \"ÿÆŸÖÿ≥ÿ©\",\r\n    \"ÿ≥ÿ™ÿ©\", \"ÿ≥ÿ®ÿπÿ©\", \"ÿ™ŸÖŸÜŸäÿ©\", \"ÿ™ÿ≥ÿπÿ©\", \"ÿπÿ¥ÿ±ÿ©\", \"ÿ£\", \"ÿ®\", \"ÿ¨\", \"ÿØ\",\r\n    \"ÿµÿ≠\", \"ÿ∫ŸÑÿ∑\", \"ÿµÿ≠Ÿäÿ≠\", \"ÿÆÿ∑ÿ£\", \"ÿßŸÑÿßÿÆÿ™Ÿäÿßÿ±\", \"ÿßÿÆÿ™Ÿäÿßÿ±\", \"ŸÖÿ™ÿπÿØÿØ\",\r\n    \"ÿßŸÑÿßÿÆÿ™Ÿäÿßÿ±ÿßÿ™\", \"ÿßÿÆÿ™Ÿäÿßÿ±ÿßÿ™\", \"ÿßŸÑÿÆŸäÿßÿ±\", \"ÿÆŸäÿßÿ±\", \"ÿßŸÑŸÖÿ±ÿßÿ¨ÿπÿ©\", \"ŸÖÿ±ÿßÿ¨ÿπÿ©\",\r\n    \"ÿßŸÑŸÖŸÑÿÆÿµ\", \"ŸÖŸÑÿÆÿµ\", \"ÿßŸÑÿØÿ±ÿ≥\", \"ÿØÿ±ÿ≥\", \"ÿßŸÑŸÖÿßÿØÿ©\", \"ŸÖÿßÿØÿ©\", \"ÿßŸÑÿ≥ŸÉÿ±ŸäŸÜ\", \r\n    \"ÿ≥ŸÉÿ±ŸäŸÜ\", \"ÿ¥Ÿäÿ±\", \"ÿ¥ÿßÿ±ŸÉ\", \"ÿßŸÑŸàŸäŸÉŸä\", \"ŸàŸäŸÉŸä\", \"ŸàŸäŸÉŸäÿ®ŸäÿØŸäÿß\", \"ŸàŸäŸÉŸäÿ®ŸäÿØŸäÿß\",\r\n    \"ÿµŸÅÿ≠ÿ©\", \"ÿßŸÑÿµŸÅÿ≠ÿ©\", \"ÿßŸÑŸÖŸàŸÇÿπ\", \"ŸÖŸàŸÇÿπ\", \"ÿßŸÑŸÖŸàÿßŸÇÿπ\", \"ŸÖŸàÿßŸÇÿπ\", \"ÿßŸÑÿ±ÿßÿ®ÿ∑\",\r\n    \"ÿ±ÿßÿ®ÿ∑\", \"ÿßŸÑŸÑŸäŸÜŸÉ\", \"ŸÑŸäŸÜŸÉ\", \"ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ\", \"ÿ™ÿ∑ÿ®ŸäŸÇ\", \"ÿßŸÑÿ™ŸÑŸäÿ¨ÿ±ÿßŸÖ\", \"ÿ™ŸÑŸäÿ¨ÿ±ÿßŸÖ\",\r\n    \"ÿßŸÑŸàÿßÿ™ÿ≥\", \"Ÿàÿßÿ™ÿ≥\", \"ÿßŸÑŸÅŸäÿ≥ÿ®ŸàŸÉ\", \"ŸÅŸäÿ≥ÿ®ŸàŸÉ\", \"ÿßŸÑŸÖÿ≥ŸÜÿ¨ÿ±\", \"ŸÖÿ≥ŸÜÿ¨ÿ±\", \"ÿßŸÑÿ™ŸàŸäÿ™ÿ±\",\r\n    \"ÿ™ŸàŸäÿ™ÿ±\", \"ÿßŸÑÿßŸÜÿ≥ÿ™ÿ¨ÿ±ÿßŸÖ\", \"ÿßŸÜÿ≥ÿ™ÿ¨ÿ±ÿßŸÖ\", \"ÿßŸÑÿ™ŸäŸÉ ÿ™ŸàŸÉ\", \"ÿ™ŸäŸÉ ÿ™ŸàŸÉ\", \"ÿßŸÑŸäŸàÿ™ŸäŸàÿ®\",\r\n    \"ŸäŸàÿ™ŸäŸàÿ®\", \"ÿßŸÑÿ™ŸÑŸÅŸàŸÜ\", \"ÿ™ŸÑŸÅŸàŸÜ\", \"ÿßŸÑŸÖŸàÿ®ÿßŸäŸÑ\", \"ŸÖŸàÿ®ÿßŸäŸÑ\", \"ÿßŸÑÿ¨ŸàÿßŸÑ\", \"ÿ¨ŸàÿßŸÑ\",\r\n    \"ÿßŸÑŸÉŸÖÿ®ŸäŸàÿ™ÿ±\", \"ŸÉŸÖÿ®ŸäŸàÿ™ÿ±\", \"ÿßŸÑŸÑÿßÿ®\", \"ŸÑÿßÿ®\", \"ÿßŸÑÿ™ÿßÿ®\", \"ÿ™ÿßÿ®\", \"ÿßŸÑÿßŸäÿ®ÿßÿØ\", \"ÿßŸäÿ®ÿßÿØ\",\r\n    \"ÿßŸÑÿßŸäŸÅŸàŸÜ\", \"ÿßŸäŸÅŸàŸÜ\", \"ÿßŸÑÿßŸÜÿØÿ±ŸàŸäÿØ\", \"ÿßŸÜÿØÿ±ŸàŸäÿØ\", \"ÿßŸÑŸàŸäŸÜÿØŸàÿ≤\", \"ŸàŸäŸÜÿØŸàÿ≤\", \"ÿßŸÑŸÖÿßŸÉ\",\r\n    \"ŸÖÿßŸÉ\", \"ÿßŸÑŸÑÿßÿ®ÿ™Ÿàÿ®\", \"ŸÑÿßÿ®ÿ™Ÿàÿ®\", \"ÿßŸÑÿØŸäÿ≥ŸÉÿ™Ÿàÿ®\", \"ÿØŸäÿ≥ŸÉÿ™Ÿàÿ®\", \"ÿßŸÑÿ™ÿßÿ®ŸÑÿ™\", \"ÿ™ÿßÿ®ŸÑÿ™\",\r\n    \"ÿßŸÑÿ≥ŸÖÿßÿ±ÿ™\", \"ÿ≥ŸÖÿßÿ±ÿ™\", \"ÿßŸÑŸÅŸàŸÜ\", \"ŸÅŸàŸÜ\", \"ÿßŸÑÿ™ÿßÿ®\", \"ÿ™ÿßÿ®\", \"ÿßŸÑŸÑÿßÿ®\", \"ŸÑÿßÿ®\", \"ÿßŸÑÿ™ÿßÿ®\",\r\n    \"ÿßŸÑŸÑÿßÿ®\", \"ÿßŸÑÿ™ÿßÿ®\", \"ÿßŸÑŸÑÿßÿ®\", \"ÿßŸÑÿ™ÿßÿ®\", \"ÿßŸÑŸÑÿßÿ®\", \"ÿßŸÑÿ™ÿßÿ®\", \"ÿßŸÑŸÑÿßÿ®\", \"ÿßŸÑÿ™ÿßÿ®\"\r\n  ];\r\n\r\n  useEffect(() => {\r\n    const loadModels = async () => {\r\n      await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\r\n      console.log(\"Face Detection Model Loaded\");\r\n    };\r\n    loadModels();\r\n  }, []);\r\n\r\n  const getPermissions = async () => {\r\n    try {\r\n      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\r\n      setMediaStream(stream);\r\n      setPermissionsGranted(true);\r\n      setShowPermissionMessage(false);\r\n      initializeSpeechRecognition();\r\n      setupVoiceAnalysis(stream);\r\n    } catch (error) {\r\n      alert(\"Please allow access to camera and microphone.\");\r\n      setShowPermissionMessage(true);\r\n    }\r\n  };\r\n\r\n  // ŸÜÿ∏ÿßŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\r\n  const setupVoiceAnalysis = (stream) => {\r\n    try {\r\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\r\n      analyserRef.current = audioContextRef.current.createAnalyser();\r\n      analyserRef.current.fftSize = 4096;\r\n      \r\n      const source = audioContextRef.current.createMediaStreamSource(stream);\r\n      source.connect(analyserRef.current);\r\n\r\n      // ÿ•ŸÜÿ¥ÿßÿ° ÿ®ÿµŸÖÿ© ÿµŸàÿ™Ÿäÿ© ÿ£ŸàŸÑŸäÿ© ÿ®ÿπÿØ 3 ÿ´ŸàÿßŸÜŸä\r\n      setTimeout(() => {\r\n        voiceProfileRef.current.baseline = createVoiceProfile();\r\n        voiceProfileRef.current.active = true;\r\n      }, 3000);\r\n\r\n      const analyzeVoice = () => {\r\n        if (!voiceProfileRef.current.active) {\r\n          requestAnimationFrame(analyzeVoice);\r\n          return;\r\n        }\r\n\r\n        const currentProfile = createVoiceProfile();\r\n        const isMultiple = compareVoiceProfiles(voiceProfileRef.current.baseline, currentProfile);\r\n        \r\n        if (isMultiple && Date.now() - voiceProfileRef.current.lastAlert > 5000) {\r\n          setMultipleVoicesDetected(true);\r\n          voiceProfileRef.current.lastAlert = Date.now();\r\n        } else {\r\n          setMultipleVoicesDetected(false);\r\n        }\r\n\r\n        requestAnimationFrame(analyzeVoice);\r\n      };\r\n\r\n      analyzeVoice();\r\n    } catch (error) {\r\n      console.error(\"Voice analysis error:\", error);\r\n    }\r\n  };\r\n\r\n  const createVoiceProfile = () => {\r\n    const bufferLength = analyserRef.current.frequencyBinCount;\r\n    const dataArray = new Float32Array(bufferLength);\r\n    analyserRef.current.getFloatFrequencyData(dataArray);\r\n\r\n    const profile = {\r\n      lowRange: 0,    // 85-300Hz\r\n      midRange: 0,    // 300-1000Hz\r\n      highRange: 0,   // 1000-4000Hz\r\n      peakCount: 0,\r\n      totalEnergy: 0\r\n    };\r\n\r\n    for (let i = 0; i < bufferLength; i++) {\r\n      const freq = i * audioContextRef.current.sampleRate / analyserRef.current.fftSize;\r\n      const value = Math.pow(10, dataArray[i]/20); // Convert dB to linear\r\n\r\n      if (freq >= 85 && freq < 300) {\r\n        profile.lowRange += value;\r\n      } else if (freq >= 300 && freq < 1000) {\r\n        profile.midRange += value;\r\n      } else if (freq >= 1000 && freq < 4000) {\r\n        profile.highRange += value;\r\n      }\r\n\r\n      if (dataArray[i] > -40) profile.peakCount++;\r\n      profile.totalEnergy += value;\r\n    }\r\n\r\n    return profile;\r\n  };\r\n\r\n  const compareVoiceProfiles = (baseline, current) => {\r\n    // ÿ≠ÿ≥ÿßÿ® ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ™ÿ∫Ÿäÿ± ŸÑŸÉŸÑ ŸÜÿ∑ÿßŸÇ ÿ™ÿ±ÿØÿØŸä\r\n    const lowDiff = Math.abs(current.lowRange - baseline.lowRange) / baseline.lowRange;\r\n    const midDiff = Math.abs(current.midRange - baseline.midRange) / baseline.midRange;\r\n    const highDiff = Math.abs(current.highRange - baseline.highRange) / baseline.highRange;\r\n    const energyDiff = Math.abs(current.totalEnergy - baseline.totalEnergy) / baseline.totalEnergy;\r\n    const peakDiff = Math.abs(current.peakCount - baseline.peakCount);\r\n\r\n    // ÿ¥ÿ±Ÿàÿ∑ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ©\r\n    return (\r\n      (lowDiff > 0.6 || midDiff > 0.6 || highDiff > 0.6) &&\r\n      energyDiff > 0.4 &&\r\n      peakDiff > 15\r\n    );\r\n  };\r\n\r\n  const checkForForbiddenWords = (text) => {\r\n    const words = text.split(/\\s+/);\r\n    let foundWords = [];\r\n    \r\n    words.forEach(word => {\r\n      if (forbiddenWords.includes(word.toLowerCase())) {\r\n        foundWords.push(word);\r\n      }\r\n    });\r\n\r\n    if (foundWords.length > 0) {\r\n      const newViolations = violations + foundWords.length;\r\n      setViolations(newViolations);\r\n      \r\n      alert(`üö® FORBIDDEN WORDS DETECTED: ${foundWords.join(', ')} (Violation ${newViolations}/3)`);\r\n      \r\n      if (newViolations >= 3) {\r\n        setExamTerminated(true);\r\n      }\r\n    }\r\n  };\r\n\r\n  const initializeSpeechRecognition = () => {\r\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n    if (!SpeechRecognition) {\r\n      console.error(\"Speech Recognition API not supported in this browser\");\r\n      return;\r\n    }\r\n\r\n    recognitionRef.current = new SpeechRecognition();\r\n    recognitionRef.current.continuous = true;\r\n    recognitionRef.current.interimResults = false;\r\n    recognitionRef.current.lang = \"ar-SA\";\r\n\r\n    recognitionRef.current.onresult = (event) => {\r\n      const last = event.results.length - 1;\r\n      const text = event.results[last][0].transcript;\r\n      setTranscript(text);\r\n      checkForForbiddenWords(text);\r\n    };\r\n\r\n    recognitionRef.current.onerror = (event) => {\r\n      console.error(\"Speech recognition error\", event.error);\r\n    };\r\n\r\n    recognitionRef.current.start();\r\n    recognitionRef.current.onend = () => {\r\n      recognitionRef.current.start();\r\n    };\r\n  };\r\n\r\n  useEffect(() => {\r\n    if (mediaStream) {\r\n      const tracks = mediaStream.getTracks();\r\n      tracks.forEach((track) => {\r\n        track.enabled = true;\r\n      });\r\n    }\r\n\r\n    return () => {\r\n      if (recognitionRef.current) {\r\n        recognitionRef.current.stop();\r\n      }\r\n      if (audioContextRef.current) {\r\n        audioContextRef.current.close();\r\n      }\r\n    };\r\n  }, [mediaStream]);\r\n\r\n  const detectFace = async () => {\r\n    if (webcamRef.current && webcamRef.current.video.readyState === 4) {\r\n      const video = webcamRef.current.video;\r\n      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\r\n      const isFacePresent = detections.length > 0;\r\n      setFaceDetected(isFacePresent);\r\n      setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\r\n    }\r\n  };\r\n\r\n  useEffect(() => {\r\n    if (permissionsGranted) {\r\n      const interval = setInterval(detectFace, 1000);\r\n      return () => clearInterval(interval);\r\n    }\r\n  }, [permissionsGranted]);\r\n\r\n  useEffect(() => {\r\n    if (noFaceDuration >= 15) {\r\n      alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\r\n      setNoFaceDuration(0);\r\n    }\r\n  }, [noFaceDuration]);\r\n\r\n  const detectSound = useCallback(() => {\r\n    if (!mediaStream) return;\r\n\r\n    const audioContext = new AudioContext();\r\n    const analyser = audioContext.createAnalyser();\r\n    const source = audioContext.createMediaStreamSource(mediaStream);\r\n    source.connect(analyser);\r\n    analyser.fftSize = 256;\r\n    const bufferLength = analyser.frequencyBinCount;\r\n    const dataArray = new Uint8Array(bufferLength);\r\n\r\n    const checkSound = () => {\r\n      analyser.getByteFrequencyData(dataArray);\r\n      const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\r\n      setSoundDetected(volume > 10);\r\n      requestAnimationFrame(checkSound);\r\n    };\r\n    checkSound();\r\n  }, [mediaStream]);\r\n\r\n  useEffect(() => {\r\n    if (permissionsGranted) {\r\n      detectSound();\r\n    }\r\n  }, [permissionsGranted, detectSound]);\r\n\r\n  useEffect(() => {\r\n    if (multipleVoicesDetected) {\r\n      const newViolations = violations + 1;\r\n      setViolations(newViolations);\r\n      \r\n      alert(`üö® MULTIPLE VOICES DETECTED! (Violation ${newViolations}/3)`);\r\n      \r\n      if (newViolations >= 3) {\r\n        setExamTerminated(true);\r\n      }\r\n    }\r\n  }, [multipleVoicesDetected]);\r\n\r\n  return (\r\n    <div className=\"continuous-auth-container\">\r\n      <h2>Exam Proctoring System</h2>\r\n\r\n      {showPermissionMessage && (\r\n        <div className=\"permission-message\">\r\n          <h3>Exam Proctoring Setup</h3>\r\n          <p>This exam requires camera and microphone access for proctoring purposes.</p>\r\n          <div className=\"permission-requirements\">\r\n            <p>‚úì Face detection must be enabled</p>\r\n            <p>‚úì Microphone must be active</p>\r\n            <p>‚úì Forbidden words monitoring is active</p>\r\n          </div>\r\n          <button className=\"permission-button\" onClick={getPermissions}>\r\n            Enable Camera & Microphone\r\n          </button>\r\n        </div>\r\n      )}\r\n\r\n      {permissionsGranted && !examTerminated && (\r\n        <div className=\"monitoring-container\">\r\n          <div className=\"video-section\">\r\n            <Webcam\r\n              audio={true}\r\n              ref={webcamRef}\r\n              screenshotFormat=\"image/jpeg\"\r\n              className=\"webcam\"\r\n              videoConstraints={{\r\n                facingMode: \"user\",\r\n                width: 480,\r\n                height: 360,\r\n              }}\r\n            />\r\n            <div className=\"status-indicators\">\r\n              <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\r\n                {faceDetected ? \"Face Detected\" : \"No Face Detected\"}\r\n              </div>\r\n              <div className={`status-indicator ${soundDetected ? \"active\" : \"\"}`}>\r\n                {soundDetected ? \"Sound Detected\" : \"No Sound Detected\"}\r\n              </div>\r\n              {multipleVoicesDetected && (\r\n                <div className=\"status-indicator warning\">\r\n                  Multiple Voices Detected!\r\n                </div>\r\n              )}\r\n            </div>\r\n          </div>\r\n\r\n          <div className=\"transcript-section\">\r\n            <div className=\"transcript-box\">\r\n              <div className=\"transcript-header\">\r\n                <span>Arabic Speech Transcript</span>\r\n                <span className=\"violation-counter\">Violations: {violations}/3</span>\r\n              </div>\r\n              <div className=\"transcript-content\" dir=\"rtl\">\r\n                {transcript || \"Waiting for audio input...\"}\r\n              </div>\r\n              <div className={`voice-detection-status ${multipleVoicesDetected ? \"multiple\" : \"\"}`}>\r\n                {multipleVoicesDetected \r\n                  ? \"Multiple voices detected!\" \r\n                  : \"Voice analysis active\"}\r\n              </div>\r\n            </div>\r\n          </div>\r\n        </div>\r\n      )}\r\n\r\n      {examTerminated && (\r\n        <div className=\"termination-message\">\r\n          <h3>‚úñ Exam Terminated</h3>\r\n          <p>Due to multiple violations detected. Please contact your instructor.</p>\r\n          <p>Total violations: {violations}</p>\r\n          <p>Termination reason: {multipleVoicesDetected ? \"Multiple voices detected\" : \"Forbidden words detected\"}</p>\r\n        </div>\r\n      )}\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default ContinuousAuth;\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"],"mappings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vE,OAAO,KAAKC,OAAO,MAAM,aAAa;AACtC,OAAOC,MAAM,MAAM,cAAc;AACjC,OAAO,sBAAsB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE9B,MAAMC,cAAc,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC3B,MAAMC,SAAS,GAAGR,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAM,CAACS,YAAY,EAAEC,eAAe,CAAC,GAAGZ,QAAQ,CAAC,KAAK,CAAC;EACvD,MAAM,CAACa,aAAa,EAAEC,gBAAgB,CAAC,GAAGd,QAAQ,CAAC,KAAK,CAAC;EACzD,MAAM,CAACe,YAAY,EAAEC,eAAe,CAAC,GAAGhB,QAAQ,CAAC,IAAI,CAAC;EACtD,MAAM,CAACiB,kBAAkB,EAAEC,qBAAqB,CAAC,GAAGlB,QAAQ,CAAC,KAAK,CAAC;EACnE,MAAM,CAACmB,cAAc,EAAEC,iBAAiB,CAAC,GAAGpB,QAAQ,CAAC,KAAK,CAAC;EAC3D,MAAM,CAACqB,WAAW,EAAEC,cAAc,CAAC,GAAGtB,QAAQ,CAAC,IAAI,CAAC;EACpD,MAAM,CAACuB,qBAAqB,EAAEC,wBAAwB,CAAC,GAAGxB,QAAQ,CAAC,IAAI,CAAC;EACxE,MAAM,CAACyB,cAAc,EAAEC,iBAAiB,CAAC,GAAG1B,QAAQ,CAAC,CAAC,CAAC;EACvD,MAAM,CAAC2B,UAAU,EAAEC,aAAa,CAAC,GAAG5B,QAAQ,CAAC,EAAE,CAAC;EAChD,MAAM,CAAC6B,UAAU,EAAEC,aAAa,CAAC,GAAG9B,QAAQ,CAAC,CAAC,CAAC;EAC/C,MAAM+B,cAAc,GAAG7B,MAAM,CAAC,IAAI,CAAC;;EAEnC;EACA,MAAM,CAAC8B,sBAAsB,EAAEC,yBAAyB,CAAC,GAAGjC,QAAQ,CAAC,KAAK,CAAC;EAC3E,MAAMkC,eAAe,GAAGhC,MAAM,CAAC,IAAI,CAAC;EACpC,MAAMiC,WAAW,GAAGjC,MAAM,CAAC,IAAI,CAAC;EAChC,MAAMkC,eAAe,GAAGlC,MAAM,CAAC;IAC7BmC,QAAQ,EAAE,IAAI;IACdC,SAAS,EAAE,CAAC;IACZC,MAAM,EAAE;EACV,CAAC,CAAC;;EAEF;EACA,MAAMC,cAAc,GAAG,CACrB,SAAS,EAAE,MAAM,EAAE,QAAQ,EAAE,MAAM,EAAE,IAAI,EAAE,OAAO,EAAE,QAAQ,EAC5D,UAAU,EAAE,SAAS,EAAE,IAAI,EAAE,MAAM,EAAE,QAAQ,EAAE,MAAM,EAAE,MAAM,EAC7D,IAAI,EAAE,UAAU,EAAE,QAAQ,EAAE,MAAM,EAAE,QAAQ,EAAE,KAAK,EAAE,OAAO,EAC5D,MAAM,EAAE,QAAQ,EAAE,QAAQ,EAAE,OAAO,EAAE,OAAO,EAAE,OAAO,EAAE,MAAM,EAC7D,KAAK,EAAE,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,MAAM,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAC1D,IAAI,EAAE,KAAK,EAAE,MAAM,EAAE,KAAK,EAAE,UAAU,EAAE,QAAQ,EAAE,OAAO,EACzD,YAAY,EAAE,UAAU,EAAE,QAAQ,EAAE,MAAM,EAAE,UAAU,EAAE,QAAQ,EAChE,QAAQ,EAAE,MAAM,EAAE,OAAO,EAAE,KAAK,EAAE,QAAQ,EAAE,MAAM,EAAE,SAAS,EAC7D,OAAO,EAAE,KAAK,EAAE,MAAM,EAAE,QAAQ,EAAE,MAAM,EAAE,WAAW,EAAE,WAAW,EAClE,MAAM,EAAE,QAAQ,EAAE,QAAQ,EAAE,MAAM,EAAE,SAAS,EAAE,OAAO,EAAE,QAAQ,EAChE,MAAM,EAAE,QAAQ,EAAE,MAAM,EAAE,SAAS,EAAE,OAAO,EAAE,WAAW,EAAE,SAAS,EACpE,QAAQ,EAAE,MAAM,EAAE,UAAU,EAAE,QAAQ,EAAE,SAAS,EAAE,OAAO,EAAE,SAAS,EACrE,OAAO,EAAE,YAAY,EAAE,UAAU,EAAE,WAAW,EAAE,SAAS,EAAE,UAAU,EACrE,QAAQ,EAAE,SAAS,EAAE,OAAO,EAAE,UAAU,EAAE,QAAQ,EAAE,QAAQ,EAAE,MAAM,EACpE,WAAW,EAAE,SAAS,EAAE,OAAO,EAAE,KAAK,EAAE,OAAO,EAAE,KAAK,EAAE,SAAS,EAAE,OAAO,EAC1E,SAAS,EAAE,OAAO,EAAE,WAAW,EAAE,SAAS,EAAE,UAAU,EAAE,QAAQ,EAAE,OAAO,EACzE,KAAK,EAAE,UAAU,EAAE,QAAQ,EAAE,WAAW,EAAE,SAAS,EAAE,SAAS,EAAE,OAAO,EACvE,SAAS,EAAE,OAAO,EAAE,OAAO,EAAE,KAAK,EAAE,OAAO,EAAE,KAAK,EAAE,OAAO,EAAE,KAAK,EAAE,OAAO,EAC3E,OAAO,EAAE,OAAO,EAAE,OAAO,EAAE,OAAO,EAAE,OAAO,EAAE,OAAO,EAAE,OAAO,EAAE,OAAO,CACvE;EAEDvC,SAAS,CAAC,MAAM;IACd,MAAMwC,UAAU,GAAG,MAAAA,CAAA,KAAY;MAC7B,MAAMrC,OAAO,CAACsC,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAAC,SAAS,CAAC;MAC1DC,OAAO,CAACC,GAAG,CAAC,6BAA6B,CAAC;IAC5C,CAAC;IACDL,UAAU,CAAC,CAAC;EACd,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMM,cAAc,GAAG,MAAAA,CAAA,KAAY;IACjC,IAAI;MACF,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAAEC,KAAK,EAAE,IAAI;QAAEC,KAAK,EAAE;MAAK,CAAC,CAAC;MACtF/B,cAAc,CAAC0B,MAAM,CAAC;MACtB9B,qBAAqB,CAAC,IAAI,CAAC;MAC3BM,wBAAwB,CAAC,KAAK,CAAC;MAC/B8B,2BAA2B,CAAC,CAAC;MAC7BC,kBAAkB,CAACP,MAAM,CAAC;IAC5B,CAAC,CAAC,OAAOQ,KAAK,EAAE;MACdC,KAAK,CAAC,+CAA+C,CAAC;MACtDjC,wBAAwB,CAAC,IAAI,CAAC;IAChC;EACF,CAAC;;EAED;EACA,MAAM+B,kBAAkB,GAAIP,MAAM,IAAK;IACrC,IAAI;MACFd,eAAe,CAACwB,OAAO,GAAG,KAAKC,MAAM,CAACC,YAAY,IAAID,MAAM,CAACE,kBAAkB,EAAE,CAAC;MAClF1B,WAAW,CAACuB,OAAO,GAAGxB,eAAe,CAACwB,OAAO,CAACI,cAAc,CAAC,CAAC;MAC9D3B,WAAW,CAACuB,OAAO,CAACK,OAAO,GAAG,IAAI;MAElC,MAAMC,MAAM,GAAG9B,eAAe,CAACwB,OAAO,CAACO,uBAAuB,CAACjB,MAAM,CAAC;MACtEgB,MAAM,CAACE,OAAO,CAAC/B,WAAW,CAACuB,OAAO,CAAC;;MAEnC;MACAS,UAAU,CAAC,MAAM;QACf/B,eAAe,CAACsB,OAAO,CAACrB,QAAQ,GAAG+B,kBAAkB,CAAC,CAAC;QACvDhC,eAAe,CAACsB,OAAO,CAACnB,MAAM,GAAG,IAAI;MACvC,CAAC,EAAE,IAAI,CAAC;MAER,MAAM8B,YAAY,GAAGA,CAAA,KAAM;QACzB,IAAI,CAACjC,eAAe,CAACsB,OAAO,CAACnB,MAAM,EAAE;UACnC+B,qBAAqB,CAACD,YAAY,CAAC;UACnC;QACF;QAEA,MAAME,cAAc,GAAGH,kBAAkB,CAAC,CAAC;QAC3C,MAAMI,UAAU,GAAGC,oBAAoB,CAACrC,eAAe,CAACsB,OAAO,CAACrB,QAAQ,EAAEkC,cAAc,CAAC;QAEzF,IAAIC,UAAU,IAAIE,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGvC,eAAe,CAACsB,OAAO,CAACpB,SAAS,GAAG,IAAI,EAAE;UACvEL,yBAAyB,CAAC,IAAI,CAAC;UAC/BG,eAAe,CAACsB,OAAO,CAACpB,SAAS,GAAGoC,IAAI,CAACC,GAAG,CAAC,CAAC;QAChD,CAAC,MAAM;UACL1C,yBAAyB,CAAC,KAAK,CAAC;QAClC;QAEAqC,qBAAqB,CAACD,YAAY,CAAC;MACrC,CAAC;MAEDA,YAAY,CAAC,CAAC;IAChB,CAAC,CAAC,OAAOb,KAAK,EAAE;MACdX,OAAO,CAACW,KAAK,CAAC,uBAAuB,EAAEA,KAAK,CAAC;IAC/C;EACF,CAAC;EAED,MAAMY,kBAAkB,GAAGA,CAAA,KAAM;IAC/B,MAAMQ,YAAY,GAAGzC,WAAW,CAACuB,OAAO,CAACmB,iBAAiB;IAC1D,MAAMC,SAAS,GAAG,IAAIC,YAAY,CAACH,YAAY,CAAC;IAChDzC,WAAW,CAACuB,OAAO,CAACsB,qBAAqB,CAACF,SAAS,CAAC;IAEpD,MAAMG,OAAO,GAAG;MACdC,QAAQ,EAAE,CAAC;MAAK;MAChBC,QAAQ,EAAE,CAAC;MAAK;MAChBC,SAAS,EAAE,CAAC;MAAI;MAChBC,SAAS,EAAE,CAAC;MACZC,WAAW,EAAE;IACf,CAAC;IAED,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGX,YAAY,EAAEW,CAAC,EAAE,EAAE;MACrC,MAAMC,IAAI,GAAGD,CAAC,GAAGrD,eAAe,CAACwB,OAAO,CAAC+B,UAAU,GAAGtD,WAAW,CAACuB,OAAO,CAACK,OAAO;MACjF,MAAM2B,KAAK,GAAGC,IAAI,CAACC,GAAG,CAAC,EAAE,EAAEd,SAAS,CAACS,CAAC,CAAC,GAAC,EAAE,CAAC,CAAC,CAAC;;MAE7C,IAAIC,IAAI,IAAI,EAAE,IAAIA,IAAI,GAAG,GAAG,EAAE;QAC5BP,OAAO,CAACC,QAAQ,IAAIQ,KAAK;MAC3B,CAAC,MAAM,IAAIF,IAAI,IAAI,GAAG,IAAIA,IAAI,GAAG,IAAI,EAAE;QACrCP,OAAO,CAACE,QAAQ,IAAIO,KAAK;MAC3B,CAAC,MAAM,IAAIF,IAAI,IAAI,IAAI,IAAIA,IAAI,GAAG,IAAI,EAAE;QACtCP,OAAO,CAACG,SAAS,IAAIM,KAAK;MAC5B;MAEA,IAAIZ,SAAS,CAACS,CAAC,CAAC,GAAG,CAAC,EAAE,EAAEN,OAAO,CAACI,SAAS,EAAE;MAC3CJ,OAAO,CAACK,WAAW,IAAII,KAAK;IAC9B;IAEA,OAAOT,OAAO;EAChB,CAAC;EAED,MAAMR,oBAAoB,GAAGA,CAACpC,QAAQ,EAAEqB,OAAO,KAAK;IAClD;IACA,MAAMmC,OAAO,GAAGF,IAAI,CAACG,GAAG,CAACpC,OAAO,CAACwB,QAAQ,GAAG7C,QAAQ,CAAC6C,QAAQ,CAAC,GAAG7C,QAAQ,CAAC6C,QAAQ;IAClF,MAAMa,OAAO,GAAGJ,IAAI,CAACG,GAAG,CAACpC,OAAO,CAACyB,QAAQ,GAAG9C,QAAQ,CAAC8C,QAAQ,CAAC,GAAG9C,QAAQ,CAAC8C,QAAQ;IAClF,MAAMa,QAAQ,GAAGL,IAAI,CAACG,GAAG,CAACpC,OAAO,CAAC0B,SAAS,GAAG/C,QAAQ,CAAC+C,SAAS,CAAC,GAAG/C,QAAQ,CAAC+C,SAAS;IACtF,MAAMa,UAAU,GAAGN,IAAI,CAACG,GAAG,CAACpC,OAAO,CAAC4B,WAAW,GAAGjD,QAAQ,CAACiD,WAAW,CAAC,GAAGjD,QAAQ,CAACiD,WAAW;IAC9F,MAAMY,QAAQ,GAAGP,IAAI,CAACG,GAAG,CAACpC,OAAO,CAAC2B,SAAS,GAAGhD,QAAQ,CAACgD,SAAS,CAAC;;IAEjE;IACA,OACE,CAACQ,OAAO,GAAG,GAAG,IAAIE,OAAO,GAAG,GAAG,IAAIC,QAAQ,GAAG,GAAG,KACjDC,UAAU,GAAG,GAAG,IAChBC,QAAQ,GAAG,EAAE;EAEjB,CAAC;EAED,MAAMC,sBAAsB,GAAIC,IAAI,IAAK;IACvC,MAAMC,KAAK,GAAGD,IAAI,CAACE,KAAK,CAAC,KAAK,CAAC;IAC/B,IAAIC,UAAU,GAAG,EAAE;IAEnBF,KAAK,CAACG,OAAO,CAACC,IAAI,IAAI;MACpB,IAAIjE,cAAc,CAACkE,QAAQ,CAACD,IAAI,CAACE,WAAW,CAAC,CAAC,CAAC,EAAE;QAC/CJ,UAAU,CAACK,IAAI,CAACH,IAAI,CAAC;MACvB;IACF,CAAC,CAAC;IAEF,IAAIF,UAAU,CAACM,MAAM,GAAG,CAAC,EAAE;MACzB,MAAMC,aAAa,GAAGjF,UAAU,GAAG0E,UAAU,CAACM,MAAM;MACpD/E,aAAa,CAACgF,aAAa,CAAC;MAE5BrD,KAAK,CAAC,gCAAgC8C,UAAU,CAACQ,IAAI,CAAC,IAAI,CAAC,eAAeD,aAAa,KAAK,CAAC;MAE7F,IAAIA,aAAa,IAAI,CAAC,EAAE;QACtB1F,iBAAiB,CAAC,IAAI,CAAC;MACzB;IACF;EACF,CAAC;EAED,MAAMkC,2BAA2B,GAAGA,CAAA,KAAM;IACxC,MAAM0D,iBAAiB,GAAGrD,MAAM,CAACqD,iBAAiB,IAAIrD,MAAM,CAACsD,uBAAuB;IACpF,IAAI,CAACD,iBAAiB,EAAE;MACtBnE,OAAO,CAACW,KAAK,CAAC,sDAAsD,CAAC;MACrE;IACF;IAEAzB,cAAc,CAAC2B,OAAO,GAAG,IAAIsD,iBAAiB,CAAC,CAAC;IAChDjF,cAAc,CAAC2B,OAAO,CAACwD,UAAU,GAAG,IAAI;IACxCnF,cAAc,CAAC2B,OAAO,CAACyD,cAAc,GAAG,KAAK;IAC7CpF,cAAc,CAAC2B,OAAO,CAAC0D,IAAI,GAAG,OAAO;IAErCrF,cAAc,CAAC2B,OAAO,CAAC2D,QAAQ,GAAIC,KAAK,IAAK;MAC3C,MAAMC,IAAI,GAAGD,KAAK,CAACE,OAAO,CAACX,MAAM,GAAG,CAAC;MACrC,MAAMT,IAAI,GAAGkB,KAAK,CAACE,OAAO,CAACD,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC5F,UAAU;MAC9CC,aAAa,CAACwE,IAAI,CAAC;MACnBD,sBAAsB,CAACC,IAAI,CAAC;IAC9B,CAAC;IAEDrE,cAAc,CAAC2B,OAAO,CAAC+D,OAAO,GAAIH,KAAK,IAAK;MAC1CzE,OAAO,CAACW,KAAK,CAAC,0BAA0B,EAAE8D,KAAK,CAAC9D,KAAK,CAAC;IACxD,CAAC;IAEDzB,cAAc,CAAC2B,OAAO,CAACgE,KAAK,CAAC,CAAC;IAC9B3F,cAAc,CAAC2B,OAAO,CAACiE,KAAK,GAAG,MAAM;MACnC5F,cAAc,CAAC2B,OAAO,CAACgE,KAAK,CAAC,CAAC;IAChC,CAAC;EACH,CAAC;EAEDzH,SAAS,CAAC,MAAM;IACd,IAAIoB,WAAW,EAAE;MACf,MAAMuG,MAAM,GAAGvG,WAAW,CAACwG,SAAS,CAAC,CAAC;MACtCD,MAAM,CAACpB,OAAO,CAAEsB,KAAK,IAAK;QACxBA,KAAK,CAACC,OAAO,GAAG,IAAI;MACtB,CAAC,CAAC;IACJ;IAEA,OAAO,MAAM;MACX,IAAIhG,cAAc,CAAC2B,OAAO,EAAE;QAC1B3B,cAAc,CAAC2B,OAAO,CAACsE,IAAI,CAAC,CAAC;MAC/B;MACA,IAAI9F,eAAe,CAACwB,OAAO,EAAE;QAC3BxB,eAAe,CAACwB,OAAO,CAACuE,KAAK,CAAC,CAAC;MACjC;IACF,CAAC;EACH,CAAC,EAAE,CAAC5G,WAAW,CAAC,CAAC;EAEjB,MAAM6G,UAAU,GAAG,MAAAA,CAAA,KAAY;IAC7B,IAAIxH,SAAS,CAACgD,OAAO,IAAIhD,SAAS,CAACgD,OAAO,CAACN,KAAK,CAAC+E,UAAU,KAAK,CAAC,EAAE;MACjE,MAAM/E,KAAK,GAAG1C,SAAS,CAACgD,OAAO,CAACN,KAAK;MACrC,MAAMgF,UAAU,GAAG,MAAMhI,OAAO,CAACiI,cAAc,CAACjF,KAAK,EAAE,IAAIhD,OAAO,CAACkI,uBAAuB,CAAC,CAAC,CAAC;MAC7F,MAAMC,aAAa,GAAGH,UAAU,CAACvB,MAAM,GAAG,CAAC;MAC3CjG,eAAe,CAAC2H,aAAa,CAAC;MAC9B7G,iBAAiB,CAAE8G,IAAI,IAAMD,aAAa,GAAG,CAAC,GAAGC,IAAI,GAAG,CAAE,CAAC;IAC7D;EACF,CAAC;EAEDvI,SAAS,CAAC,MAAM;IACd,IAAIgB,kBAAkB,EAAE;MACtB,MAAMwH,QAAQ,GAAGC,WAAW,CAACR,UAAU,EAAE,IAAI,CAAC;MAC9C,OAAO,MAAMS,aAAa,CAACF,QAAQ,CAAC;IACtC;EACF,CAAC,EAAE,CAACxH,kBAAkB,CAAC,CAAC;EAExBhB,SAAS,CAAC,MAAM;IACd,IAAIwB,cAAc,IAAI,EAAE,EAAE;MACxBgC,KAAK,CAAC,oFAAoF,CAAC;MAC3F/B,iBAAiB,CAAC,CAAC,CAAC;IACtB;EACF,CAAC,EAAE,CAACD,cAAc,CAAC,CAAC;EAEpB,MAAMmH,WAAW,GAAGzI,WAAW,CAAC,MAAM;IACpC,IAAI,CAACkB,WAAW,EAAE;IAElB,MAAMwH,YAAY,GAAG,IAAIjF,YAAY,CAAC,CAAC;IACvC,MAAMkF,QAAQ,GAAGD,YAAY,CAAC/E,cAAc,CAAC,CAAC;IAC9C,MAAME,MAAM,GAAG6E,YAAY,CAAC5E,uBAAuB,CAAC5C,WAAW,CAAC;IAChE2C,MAAM,CAACE,OAAO,CAAC4E,QAAQ,CAAC;IACxBA,QAAQ,CAAC/E,OAAO,GAAG,GAAG;IACtB,MAAMa,YAAY,GAAGkE,QAAQ,CAACjE,iBAAiB;IAC/C,MAAMC,SAAS,GAAG,IAAIiE,UAAU,CAACnE,YAAY,CAAC;IAE9C,MAAMoE,UAAU,GAAGA,CAAA,KAAM;MACvBF,QAAQ,CAACG,oBAAoB,CAACnE,SAAS,CAAC;MACxC,MAAMoE,MAAM,GAAGpE,SAAS,CAACqE,MAAM,CAAC,CAACC,GAAG,EAAE1D,KAAK,KAAK0D,GAAG,GAAG1D,KAAK,EAAE,CAAC,CAAC,GAAGd,YAAY;MAC9E9D,gBAAgB,CAACoI,MAAM,GAAG,EAAE,CAAC;MAC7B5E,qBAAqB,CAAC0E,UAAU,CAAC;IACnC,CAAC;IACDA,UAAU,CAAC,CAAC;EACd,CAAC,EAAE,CAAC3H,WAAW,CAAC,CAAC;EAEjBpB,SAAS,CAAC,MAAM;IACd,IAAIgB,kBAAkB,EAAE;MACtB2H,WAAW,CAAC,CAAC;IACf;EACF,CAAC,EAAE,CAAC3H,kBAAkB,EAAE2H,WAAW,CAAC,CAAC;EAErC3I,SAAS,CAAC,MAAM;IACd,IAAI+B,sBAAsB,EAAE;MAC1B,MAAM8E,aAAa,GAAGjF,UAAU,GAAG,CAAC;MACpCC,aAAa,CAACgF,aAAa,CAAC;MAE5BrD,KAAK,CAAC,2CAA2CqD,aAAa,KAAK,CAAC;MAEpE,IAAIA,aAAa,IAAI,CAAC,EAAE;QACtB1F,iBAAiB,CAAC,IAAI,CAAC;MACzB;IACF;EACF,CAAC,EAAE,CAACY,sBAAsB,CAAC,CAAC;EAE5B,oBACEzB,OAAA;IAAK8I,SAAS,EAAC,2BAA2B;IAAAC,QAAA,gBACxC/I,OAAA;MAAA+I,QAAA,EAAI;IAAsB;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,EAE9BnI,qBAAqB,iBACpBhB,OAAA;MAAK8I,SAAS,EAAC,oBAAoB;MAAAC,QAAA,gBACjC/I,OAAA;QAAA+I,QAAA,EAAI;MAAqB;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eAC9BnJ,OAAA;QAAA+I,QAAA,EAAG;MAAwE;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAC/EnJ,OAAA;QAAK8I,SAAS,EAAC,yBAAyB;QAAAC,QAAA,gBACtC/I,OAAA;UAAA+I,QAAA,EAAG;QAAgC;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAG,CAAC,eACvCnJ,OAAA;UAAA+I,QAAA,EAAG;QAA2B;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAG,CAAC,eAClCnJ,OAAA;UAAA+I,QAAA,EAAG;QAAsC;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAG,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAC1C,CAAC,eACNnJ,OAAA;QAAQ8I,SAAS,EAAC,mBAAmB;QAACM,OAAO,EAAE5G,cAAe;QAAAuG,QAAA,EAAC;MAE/D;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACN,CACN,EAEAzI,kBAAkB,IAAI,CAACE,cAAc,iBACpCZ,OAAA;MAAK8I,SAAS,EAAC,sBAAsB;MAAAC,QAAA,gBACnC/I,OAAA;QAAK8I,SAAS,EAAC,eAAe;QAAAC,QAAA,gBAC5B/I,OAAA,CAACF,MAAM;UACLgD,KAAK,EAAE,IAAK;UACZuG,GAAG,EAAElJ,SAAU;UACfmJ,gBAAgB,EAAC,YAAY;UAC7BR,SAAS,EAAC,QAAQ;UAClBS,gBAAgB,EAAE;YAChBC,UAAU,EAAE,MAAM;YAClBC,KAAK,EAAE,GAAG;YACVC,MAAM,EAAE;UACV;QAAE;UAAAV,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACH,CAAC,eACFnJ,OAAA;UAAK8I,SAAS,EAAC,mBAAmB;UAAAC,QAAA,gBAChC/I,OAAA;YAAK8I,SAAS,EAAE,oBAAoB1I,YAAY,GAAG,QAAQ,GAAG,EAAE,EAAG;YAAA2I,QAAA,EAChE3I,YAAY,GAAG,eAAe,GAAG;UAAkB;YAAA4I,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACjD,CAAC,eACNnJ,OAAA;YAAK8I,SAAS,EAAE,oBAAoBxI,aAAa,GAAG,QAAQ,GAAG,EAAE,EAAG;YAAAyI,QAAA,EACjEzI,aAAa,GAAG,gBAAgB,GAAG;UAAmB;YAAA0I,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACpD,CAAC,EACL1H,sBAAsB,iBACrBzB,OAAA;YAAK8I,SAAS,EAAC,0BAA0B;YAAAC,QAAA,EAAC;UAE1C;YAAAC,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAK,CACN;QAAA;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACE,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACH,CAAC,eAENnJ,OAAA;QAAK8I,SAAS,EAAC,oBAAoB;QAAAC,QAAA,eACjC/I,OAAA;UAAK8I,SAAS,EAAC,gBAAgB;UAAAC,QAAA,gBAC7B/I,OAAA;YAAK8I,SAAS,EAAC,mBAAmB;YAAAC,QAAA,gBAChC/I,OAAA;cAAA+I,QAAA,EAAM;YAAwB;cAAAC,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAM,CAAC,eACrCnJ,OAAA;cAAM8I,SAAS,EAAC,mBAAmB;cAAAC,QAAA,GAAC,cAAY,EAACzH,UAAU,EAAC,IAAE;YAAA;cAAA0H,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OAAM,CAAC;UAAA;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAClE,CAAC,eACNnJ,OAAA;YAAK8I,SAAS,EAAC,oBAAoB;YAACa,GAAG,EAAC,KAAK;YAAAZ,QAAA,EAC1C3H,UAAU,IAAI;UAA4B;YAAA4H,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACxC,CAAC,eACNnJ,OAAA;YAAK8I,SAAS,EAAE,0BAA0BrH,sBAAsB,GAAG,UAAU,GAAG,EAAE,EAAG;YAAAsH,QAAA,EAClFtH,sBAAsB,GACnB,2BAA2B,GAC3B;UAAuB;YAAAuH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACxB,CAAC;QAAA;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACH;MAAC;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACH,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACH,CACN,EAEAvI,cAAc,iBACbZ,OAAA;MAAK8I,SAAS,EAAC,qBAAqB;MAAAC,QAAA,gBAClC/I,OAAA;QAAA+I,QAAA,EAAI;MAAiB;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eAC1BnJ,OAAA;QAAA+I,QAAA,EAAG;MAAoE;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eAC3EnJ,OAAA;QAAA+I,QAAA,GAAG,oBAAkB,EAACzH,UAAU;MAAA;QAAA0H,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eACrCnJ,OAAA;QAAA+I,QAAA,GAAG,sBAAoB,EAACtH,sBAAsB,GAAG,0BAA0B,GAAG,0BAA0B;MAAA;QAAAuH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC1G,CACN;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV,CAAC;AAACjJ,EAAA,CA/WID,cAAc;AAAA2J,EAAA,GAAd3J,cAAc;AAiXpB,eAAeA,cAAc;AAAC,IAAA2J,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}