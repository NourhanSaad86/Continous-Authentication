{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\HP\\\\Desktop\\\\continous-authentication1\\\\continous-authentication1\\\\continous-authentication\\\\continous-authentication\\\\src\\\\ContinuousAuth.js\",\n  _s = $RefreshSig$();\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\n// import * as faceapi from \"face-api.js\";\n// import Webcam from \"react-webcam\";\n// import axios from \"axios\";\n// import \"./ContinuousAuth.css\";\n\n// const ContinuousAuth = () => {\n//   const webcamRef = useRef(null);\n//   const [faceDetected, setFaceDetected] = useState(false);\n//   const [soundDetected, setSoundDetected] = useState(false);\n//   const [currentImage, setCurrentImage] = useState(null);\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\n//   const [examTerminated, setExamTerminated] = useState(false);\n//   const [mediaStream, setMediaStream] = useState(null);\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\n\n//   useEffect(() => {\n//     const loadModels = async () => {\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\n//       console.log(\"Face Detection Model Loaded\");\n//     };\n//     loadModels();\n//   }, []);\n\n//   const getPermissions = async () => {\n//     try {\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\n//       setMediaStream(stream);\n//       setPermissionsGranted(true);\n//       setShowPermissionMessage(false);\n//       fetchIpAddress(); // Call to fetch IP address when permissions are granted\n//     } catch (error) {\n//       alert(\"Please allow access to camera and microphone.\");\n//       setShowPermissionMessage(true);\n//     }\n//   };\n\n//   const fetchIpAddress = async () => {\n//     try {\n//       const response = await fetch(\"https://api.ipify.org?format=json\");\n//       const data = await response.json();\n//       alert(`Your IP Address: ${data.ip}`);\n//     } catch (error) {\n//       console.error(\"Error fetching IP address:\", error);\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (mediaStream) {\n//       const tracks = mediaStream.getTracks();\n//       tracks.forEach((track) => {\n//         track.enabled = true;\n//       });\n//     }\n//   }, [mediaStream]);\n\n//   const detectFace = async () => {\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\n//       const video = webcamRef.current.video;\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n//       const isFacePresent = detections.length > 0;\n//       setFaceDetected(isFacePresent);\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       const interval = setInterval(detectFace, 1000);\n//       return () => clearInterval(interval);\n//     }\n//   }, [permissionsGranted]);\n\n//   useEffect(() => {\n//     if (noFaceDuration >= 15) {\n//       alert(\"‚ö†Ô∏è Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\n//       setNoFaceDuration(0);\n//     }\n//   }, [noFaceDuration]);\n\n//   const detectSound = useCallback(() => {\n//     if (!mediaStream) return;\n\n//     const audioContext = new AudioContext();\n//     const analyser = audioContext.createAnalyser();\n//     const source = audioContext.createMediaStreamSource(mediaStream);\n//     source.connect(analyser);\n//     analyser.fftSize = 256;\n//     const bufferLength = analyser.frequencyBinCount;\n//     const dataArray = new Uint8Array(bufferLength);\n\n//     const checkSound = () => {\n//       analyser.getByteFrequencyData(dataArray);\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\n//       setSoundDetected(volume > 10);\n//       requestAnimationFrame(checkSound);\n//     };\n//     checkSound();\n//   }, [mediaStream]);\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       detectSound();\n//     }\n//   }, [permissionsGranted, detectSound]);\n\n//   return (\n//     <div className=\"continuous-auth-container\">\n//       <h2>Continuous Authentication</h2>\n\n//       {showPermissionMessage && (\n//         <div className=\"permission-message\">\n//           <p>Please allow access to your camera and microphone to start the exam.</p>\n//           <button onClick={getPermissions}>Allow Camera and Microphone</button>\n//         </div>\n//       )}\n\n//       {permissionsGranted ? (\n//         <>\n//           <Webcam\n//             audio={true}\n//             ref={webcamRef}\n//             screenshotFormat=\"image/jpeg\"\n//             className=\"webcam\"\n//             videoConstraints={{\n//               facingMode: \"user\",\n//               width: 720,\n//               height: 400,\n//             }}\n//           />\n//           <p>Camera and microphone are active for proctoring.</p>\n\n//           <div className=\"status-buttons-container\">\n//             <div className=\"status-buttons\">\n//               <button className={faceDetected ? \"detected-btn\" : \"not-detected-btn\"}>\n//                 {faceDetected ? \"Face Detected ‚úÖ\" : \"No Face Detected ‚ùå\"}\n//               </button>\n//               <button className={soundDetected ? \"detected-btn\" : \"not-detected-btn\"}>\n//                 {soundDetected ? \"Sound Detected üîä\" : \"No Sound Detected üîá\"}\n//               </button>\n//             </div>\n\n//             <div className=\"captured-images\">\n//               {currentImage && <img src={currentImage} alt=\"Captured\" className=\"small-image\" />}\n//             </div>\n//           </div>\n//         </>\n//       ) : (\n//         <p>Waiting for camera and microphone access...</p>\n//       )}\n\n//       {examTerminated && <p className=\"mismatch-count\">Exam Terminated due to 3 mismatches.</p>}\n//     </div>\n//   );\n// };\n\n// export default ContinuousAuth;\n\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\n// import * as faceapi from \"face-api.js\";\n// import Webcam from \"react-webcam\";\n// import \"./ContinuousAuth.css\";\n\n// const ContinuousAuth = () => {\n//   const webcamRef = useRef(null);\n//   const [faceDetected, setFaceDetected] = useState(false);\n//   const [soundDetected, setSoundDetected] = useState(false);\n//   const [currentImage, setCurrentImage] = useState(null);\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\n//   const [examTerminated, setExamTerminated] = useState(false);\n//   const [mediaStream, setMediaStream] = useState(null);\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\n//   const [transcript, setTranscript] = useState(\"\");\n//   const [violations, setViolations] = useState(0);\n//   const recognitionRef = useRef(null);\n\n//   // ŸÜÿ∏ÿßŸÖ ŸÉÿ¥ŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\n//   const [multipleVoicesDetected, setMultipleVoicesDetected] = useState(false);\n//   const audioContextRef = useRef(null);\n//   const analyserRef = useRef(null);\n//   const voiceProfileRef = useRef({\n//     baseline: null,\n//     lastAlert: 0,\n//     active: false\n//   });\n\n//   useEffect(() => {\n//     const loadModels = async () => {\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\n//       console.log(\"Face Detection Model Loaded\");\n//     };\n//     loadModels();\n//   }, []);\n\n//   const getPermissions = async () => {\n//     try {\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\n//       setMediaStream(stream);\n//       setPermissionsGranted(true);\n//       setShowPermissionMessage(false);\n//       initializeSpeechRecognition();\n//       setupVoiceAnalysis(stream);\n//     } catch (error) {\n//       alert(\"Please allow access to camera and microphone.\");\n//       setShowPermissionMessage(true);\n//     }\n//   };\n\n//   // ŸÜÿ∏ÿßŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\n//   const setupVoiceAnalysis = (stream) => {\n//     try {\n//       audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n//       analyserRef.current = audioContextRef.current.createAnalyser();\n//       analyserRef.current.fftSize = 4096;\n\n//       const source = audioContextRef.current.createMediaStreamSource(stream);\n//       source.connect(analyserRef.current);\n\n//       // ÿ•ŸÜÿ¥ÿßÿ° ÿ®ÿµŸÖÿ© ÿµŸàÿ™Ÿäÿ© ÿ£ŸàŸÑŸäÿ© ÿ®ÿπÿØ 3 ÿ´ŸàÿßŸÜŸä\n//       setTimeout(() => {\n//         voiceProfileRef.current.baseline = createVoiceProfile();\n//         voiceProfileRef.current.active = true;\n//       }, 3000);\n\n//       const analyzeVoice = () => {\n//         if (!voiceProfileRef.current.active) {\n//           requestAnimationFrame(analyzeVoice);\n//           return;\n//         }\n\n//         const currentProfile = createVoiceProfile();\n//         const isMultiple = compareVoiceProfiles(voiceProfileRef.current.baseline, currentProfile);\n\n//         if (isMultiple && Date.now() - voiceProfileRef.current.lastAlert > 5000) {\n//           setMultipleVoicesDetected(true);\n//           voiceProfileRef.current.lastAlert = Date.now();\n//         } else {\n//           setMultipleVoicesDetected(false);\n//         }\n\n//         requestAnimationFrame(analyzeVoice);\n//       };\n\n//       analyzeVoice();\n//     } catch (error) {\n//       console.error(\"Voice analysis error:\", error);\n//     }\n//   };\n\n//   const createVoiceProfile = () => {\n//     const bufferLength = analyserRef.current.frequencyBinCount;\n//     const dataArray = new Float32Array(bufferLength);\n//     analyserRef.current.getFloatFrequencyData(dataArray);\n\n//     const profile = {\n//       lowRange: 0,    // 85-300Hz\n//       midRange: 0,    // 300-1000Hz\n//       highRange: 0,   // 1000-4000Hz\n//       peakCount: 0,\n//       totalEnergy: 0\n//     };\n\n//     for (let i = 0; i < bufferLength; i++) {\n//       const freq = i * audioContextRef.current.sampleRate / analyserRef.current.fftSize;\n//       const value = Math.pow(10, dataArray[i]/20); // Convert dB to linear\n\n//       if (freq >= 85 && freq < 300) {\n//         profile.lowRange += value;\n//       } else if (freq >= 300 && freq < 1000) {\n//         profile.midRange += value;\n//       } else if (freq >= 1000 && freq < 4000) {\n//         profile.highRange += value;\n//       }\n\n//       if (dataArray[i] > -40) profile.peakCount++;\n//       profile.totalEnergy += value;\n//     }\n\n//     return profile;\n//   };\n\n//   const compareVoiceProfiles = (baseline, current) => {\n//     // ÿ≠ÿ≥ÿßÿ® ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ™ÿ∫Ÿäÿ± ŸÑŸÉŸÑ ŸÜÿ∑ÿßŸÇ ÿ™ÿ±ÿØÿØŸä\n//     const lowDiff = Math.abs(current.lowRange - baseline.lowRange) / baseline.lowRange;\n//     const midDiff = Math.abs(current.midRange - baseline.midRange) / baseline.midRange;\n//     const highDiff = Math.abs(current.highRange - baseline.highRange) / baseline.highRange;\n//     const energyDiff = Math.abs(current.totalEnergy - baseline.totalEnergy) / baseline.totalEnergy;\n//     const peakDiff = Math.abs(current.peakCount - baseline.peakCount);\n\n//     // ÿ¥ÿ±Ÿàÿ∑ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ©\n//     return (\n//       (lowDiff > 0.6 || midDiff > 0.6 || highDiff > 0.6) &&\n//       energyDiff > 0.4 &&\n//       peakDiff > 15\n//     );\n//   };\n\n//   const initializeSpeechRecognition = () => {\n//     const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n//     if (!SpeechRecognition) {\n//       console.error(\"Speech Recognition API not supported in this browser\");\n//       return;\n//     }\n\n//     recognitionRef.current = new SpeechRecognition();\n//     recognitionRef.current.continuous = true;\n//     recognitionRef.current.interimResults = false;\n//     recognitionRef.current.lang = \"ar-SA\";\n\n//     recognitionRef.current.onresult = (event) => {\n//       const last = event.results.length - 1;\n//       const text = event.results[last][0].transcript;\n//       setTranscript(text);\n//     };\n\n//     recognitionRef.current.onerror = (event) => {\n//       console.error(\"Speech recognition error\", event.error);\n//     };\n\n//     recognitionRef.current.start();\n//     recognitionRef.current.onend = () => {\n//       recognitionRef.current.start();\n//     };\n//   };\n\n//   useEffect(() => {\n//     if (mediaStream) {\n//       const tracks = mediaStream.getTracks();\n//       tracks.forEach((track) => {\n//         track.enabled = true;\n//       });\n//     }\n\n//     return () => {\n//       if (recognitionRef.current) {\n//         recognitionRef.current.stop();\n//       }\n//       if (audioContextRef.current) {\n//         audioContextRef.current.close();\n//       }\n//     };\n//   }, [mediaStream]);\n\n//   const detectFace = async () => {\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\n//       const video = webcamRef.current.video;\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n//       const isFacePresent = detections.length > 0;\n//       setFaceDetected(isFacePresent);\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       const interval = setInterval(detectFace, 1000);\n//       return () => clearInterval(interval);\n//     }\n//   }, [permissionsGranted]);\n\n//   useEffect(() => {\n//     if (noFaceDuration >= 15) {\n//       alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\n//       setNoFaceDuration(0);\n//     }\n//   }, [noFaceDuration]);\n\n//   const detectSound = useCallback(() => {\n//     if (!mediaStream) return;\n\n//     const audioContext = new AudioContext();\n//     const analyser = audioContext.createAnalyser();\n//     const source = audioContext.createMediaStreamSource(mediaStream);\n//     source.connect(analyser);\n//     analyser.fftSize = 256;\n//     const bufferLength = analyser.frequencyBinCount;\n//     const dataArray = new Uint8Array(bufferLength);\n\n//     const checkSound = () => {\n//       analyser.getByteFrequencyData(dataArray);\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\n//       setSoundDetected(volume > 10);\n//       requestAnimationFrame(checkSound);\n//     };\n//     checkSound();\n//   }, [mediaStream]);\n\n//   useEffect(() => {\n//     if (permissionsGranted) {\n//       detectSound();\n//     }\n//   }, [permissionsGranted, detectSound]);\n\n//   useEffect(() => {\n//     if (multipleVoicesDetected) {\n//       const newViolations = violations + 1;\n//       setViolations(newViolations);\n\n//       alert(`üö® MULTIPLE VOICES DETECTED! (Violation ${newViolations}/3)`);\n\n//       if (newViolations >= 3) {\n//         setExamTerminated(true);\n//       }\n//     }\n//   }, [multipleVoicesDetected]);\n\n//   return (\n//     <div className=\"continuous-auth-container\">\n//       <h2>Exam Proctoring System</h2>\n\n//       {showPermissionMessage && (\n//         <div className=\"permission-message\">\n//           <h3>Exam Proctoring Setup</h3>\n//           <p>This exam requires camera and microphone access for proctoring purposes.</p>\n//           <div className=\"permission-requirements\">\n//             <p>‚úì Face detection must be enabled</p>\n//             <p>‚úì Microphone must be active</p>\n//           </div>\n//           <button className=\"permission-button\" onClick={getPermissions}>\n//             Enable Camera & Microphone\n//           </button>\n//         </div>\n//       )}\n\n//       {permissionsGranted && !examTerminated && (\n//         <div className=\"monitoring-container\">\n//           <div className=\"video-section\">\n//             <Webcam\n//               audio={true}\n//               ref={webcamRef}\n//               screenshotFormat=\"image/jpeg\"\n//               className=\"webcam\"\n//               videoConstraints={{\n//                 facingMode: \"user\",\n//                 width: 480,\n//                 height: 360,\n//               }}\n//             />\n//             <div className=\"status-indicators\">\n//               <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\n//                 {faceDetected ? \"Face Detected\" : \"No Face Detected\"}\n//               </div>\n//               <div className={`status-indicator ${soundDetected ? \"active\" : \"\"}`}>\n//                 {soundDetected ? \"Sound Detected\" : \"No Sound Detected\"}\n//               </div>\n//               {multipleVoicesDetected && (\n//                 <div className=\"status-indicator warning\">\n//                   Multiple Voices Detected!\n//                 </div>\n//               )}\n//             </div>\n//           </div>\n\n//           <div className=\"transcript-section\">\n//             <div className=\"transcript-box\">\n//               <div className=\"transcript-header\">\n//                 <span>Arabic Speech Transcript</span>\n//                 <span className=\"violation-counter\">Violations: {violations}/3</span>\n//               </div>\n//               <div className=\"transcript-content\" dir=\"rtl\">\n//                 {transcript || \"Waiting for audio input...\"}\n//               </div>\n//               <div className={`voice-detection-status ${multipleVoicesDetected ? \"multiple\" : \"\"}`}>\n//                 {multipleVoicesDetected \n//                   ? \"Multiple voices detected!\" \n//                   : \"Voice analysis active\"}\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//       )}\n\n//       {examTerminated && (\n//         <div className=\"termination-message\">\n//           <h3>‚úñ Exam Terminated</h3>\n//           <p>Due to multiple violations detected. Please contact your instructor.</p>\n//           <p>Total violations: {violations}</p>\n//         </div>\n//       )}\n//     </div>\n//   );\n// };\n\n// export default ContinuousAuth;\n\n//////////////////////////////////////////////////////////////////////////////////// \n\nimport React, { useState, useEffect, useRef, useCallback } from \"react\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst VoiceDetection = () => {\n  _s();\n  const [multipleVoicesDetected, setMultipleVoicesDetected] = useState(false);\n  const [violations, setViolations] = useState(0);\n  const [isReady, setIsReady] = useState(false);\n  const [status, setStatus] = useState(\"ÿßŸÜŸÇÿ± ÿπŸÑŸâ ÿ®ÿØÿ° ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ± ŸÑÿ®ÿØÿ° ÿßŸÑŸÖÿ±ÿßŸÇÿ®ÿ©\");\n  const [volumeLevel, setVolumeLevel] = useState(0);\n  const audioContextRef = useRef(null);\n  const analyserRef = useRef(null);\n  const lastEnergyLevelRef = useRef(0);\n  const lastTimestampRef = useRef(0);\n  const streamRef = useRef(null);\n  const animationFrameRef = useRef(null);\n\n  // ÿ•ŸÜÿ¥ÿßÿ° ÿ®ÿµŸÖÿ© ÿµŸàÿ™Ÿäÿ©\n  const createVoiceProfile = () => {\n    if (!analyserRef.current) return null;\n    const bufferLength = analyserRef.current.frequencyBinCount;\n    const dataArray = new Float32Array(bufferLength);\n    analyserRef.current.getFloatFrequencyData(dataArray);\n    let totalEnergy = 0;\n    let peakCount = 0;\n    for (let i = 0; i < bufferLength; i++) {\n      const value = Math.pow(10, dataArray[i] / 20);\n      totalEnergy += value;\n      if (dataArray[i] > -40) peakCount++;\n    }\n    return {\n      totalEnergy,\n      peakCount\n    };\n  };\n\n  // ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™\n  const analyzeVoice = useCallback(() => {\n    if (!analyserRef.current) return;\n    const currentProfile = createVoiceProfile();\n    if (!currentProfile) return;\n    const energyLevel = currentProfile.totalEnergy;\n    const energyDifference = Math.abs(energyLevel - lastEnergyLevelRef.current);\n    const timeDifference = Date.now() - lastTimestampRef.current;\n    setVolumeLevel(Math.min(100, Math.max(0, energyLevel / 10)));\n\n    // ÿ¥ÿ±Ÿàÿ∑ ÿßŸÑŸÉÿ¥ŸÅ ÿßŸÑŸÖÿ≠ÿ≥ŸÜÿ©\n    const isVoiceDetected = energyLevel > 5; // ŸÖÿ≥ÿ™ŸàŸâ ÿ∑ÿßŸÇÿ© ÿ£ÿ≥ÿßÿ≥Ÿä\n    const isSuddenChange = energyDifference > 10 && timeDifference < 300;\n    const isNewVoice = isVoiceDetected && (isSuddenChange || energyLevel > lastEnergyLevelRef.current * 1.5);\n    if (isNewVoice) {\n      setMultipleVoicesDetected(true);\n      setStatus(\"ÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿµŸàÿ™ ÿ¨ÿØŸäÿØ!\");\n      lastEnergyLevelRef.current = energyLevel;\n      lastTimestampRef.current = Date.now();\n    } else {\n      setMultipleVoicesDetected(false);\n      setStatus(\"ÿ¨ÿßÿ±Ÿä ÿßŸÑŸÖÿ±ÿßŸÇÿ®ÿ©...\");\n    }\n    animationFrameRef.current = requestAnimationFrame(analyzeVoice);\n  }, []);\n\n  // ÿ•ÿπÿØÿßÿØ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™Ÿä\n  const setupVoiceAnalysis = useCallback(stream => {\n    try {\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n      analyserRef.current = audioContextRef.current.createAnalyser();\n      analyserRef.current.fftSize = 2048;\n      const source = audioContextRef.current.createMediaStreamSource(stream);\n      source.connect(analyserRef.current);\n      setStatus(\"ÿ¨ÿßÿ±Ÿä ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™...\");\n      animationFrameRef.current = requestAnimationFrame(analyzeVoice);\n    } catch (error) {\n      console.error(\"ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™:\", error);\n      setStatus(\"ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™\");\n    }\n  }, [analyzeVoice]);\n\n  // ÿ®ÿØÿ° ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±\n  const startTest = async () => {\n    try {\n      setStatus(\"ÿ¨ÿßÿ±Ÿä ÿ∑ŸÑÿ® ÿ•ÿ∞ŸÜ ÿßŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ...\");\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: {\n          echoCancellation: false,\n          noiseSuppression: false,\n          autoGainControl: false\n        }\n      });\n      streamRef.current = stream;\n      setupVoiceAnalysis(stream);\n      setIsReady(true);\n      setStatus(\"ÿ¨ÿßÿ±Ÿä ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑÿµŸàÿ™...\");\n    } catch (error) {\n      console.error(\"ÿÆÿ∑ÿ£ ŸÅŸä ÿßŸÑŸàÿµŸàŸÑ ÿ•ŸÑŸâ ÿßŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ:\", error);\n      setStatus(\"ŸÅÿ¥ŸÑ ŸÅŸä ÿßŸÑŸàÿµŸàŸÑ ÿ•ŸÑŸâ ÿßŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿßŸÑÿ£ÿ∞ŸàŸÜÿßÿ™\");\n    }\n  };\n\n  // ÿ•ŸäŸÇÿßŸÅ ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±\n  const stopTest = () => {\n    if (animationFrameRef.current) {\n      cancelAnimationFrame(animationFrameRef.current);\n    }\n    if (streamRef.current) {\n      streamRef.current.getTracks().forEach(track => track.stop());\n    }\n    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {\n      audioContextRef.current.close();\n    }\n    setIsReady(false);\n    setStatus(\"ÿ™ŸÖ ÿ•ŸäŸÇÿßŸÅ ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±\");\n    setVolumeLevel(0);\n  };\n\n  // ÿ™ÿ£ÿ´Ÿäÿ± ŸÑŸÑŸÉÿ¥ŸÅ ÿπŸÜ ÿßŸÑÿßŸÜÿ™ŸáÿßŸÉÿßÿ™\n  useEffect(() => {\n    if (multipleVoicesDetected) {\n      const newViolations = violations + 1;\n      setViolations(newViolations);\n      alert(`üö® ÿßŸÜÿ™ÿ®ÿßŸá! ÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿµŸàÿ™ ÿ•ÿ∂ÿßŸÅŸä (ÿßŸÜÿ™ŸáÿßŸÉ ${newViolations}/3)`);\n      if (newViolations >= 3) {\n        alert(\"‚úñ ÿ™ŸÖ ÿ•ŸÜŸáÿßÿ° ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ± ÿ®ÿ≥ÿ®ÿ® ÿßŸÉÿ™ÿ¥ÿßŸÅ 3 ÿßŸÜÿ™ŸáÿßŸÉÿßÿ™\");\n        stopTest();\n      }\n    }\n  }, [multipleVoicesDetected, violations]);\n\n  // ÿ™ŸÜÿ∏ŸäŸÅ ÿßŸÑŸÖŸàÿßÿ±ÿØ ÿπŸÜÿØ unmount\n  useEffect(() => {\n    return () => {\n      stopTest();\n    };\n  }, []);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    style: {\n      maxWidth: '600px',\n      margin: '0 auto',\n      padding: '20px',\n      fontFamily: 'Arial, sans-serif',\n      textAlign: 'center'\n    },\n    children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n      style: {\n        color: '#333'\n      },\n      children: \"\\u0646\\u0638\\u0627\\u0645 \\u0643\\u0634\\u0641 \\u0627\\u0644\\u0623\\u0635\\u0648\\u0627\\u062A \\u0627\\u0644\\u0645\\u062A\\u0639\\u062F\\u062F\\u0629\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 667,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        margin: '20px 0',\n        padding: '15px',\n        backgroundColor: multipleVoicesDetected ? '#ffebee' : '#e8f5e9',\n        borderRadius: '8px',\n        border: `2px solid ${multipleVoicesDetected ? '#f44336' : '#4caf50'}`\n      },\n      children: [/*#__PURE__*/_jsxDEV(\"p\", {\n        style: {\n          fontSize: '18px',\n          fontWeight: 'bold',\n          color: multipleVoicesDetected ? '#f44336' : '#2e7d32'\n        },\n        children: status\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 676,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: [\"\\u0645\\u0633\\u062A\\u0648\\u0649 \\u0627\\u0644\\u0635\\u0648\\u062A: \", volumeLevel.toFixed(1)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 683,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        style: {\n          width: '100%',\n          height: '20px',\n          backgroundColor: '#ddd',\n          borderRadius: '10px',\n          marginTop: '10px',\n          overflow: 'hidden'\n        },\n        children: /*#__PURE__*/_jsxDEV(\"div\", {\n          style: {\n            width: `${volumeLevel}%`,\n            height: '100%',\n            backgroundColor: multipleVoicesDetected ? '#f44336' : '#4caf50',\n            transition: 'width 0.3s'\n          }\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 692,\n          columnNumber: 11\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 684,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 669,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        margin: '20px 0'\n      },\n      children: /*#__PURE__*/_jsxDEV(\"p\", {\n        style: {\n          fontSize: '16px'\n        },\n        children: [\"\\u0639\\u062F\\u062F \\u0627\\u0644\\u0627\\u0646\\u062A\\u0647\\u0627\\u0643\\u0627\\u062A: \", /*#__PURE__*/_jsxDEV(\"strong\", {\n          children: violations\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 702,\n          columnNumber: 57\n        }, this), \"/3\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 702,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 701,\n      columnNumber: 7\n    }, this), !isReady ? /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: startTest,\n      style: {\n        padding: '12px 24px',\n        fontSize: '16px',\n        backgroundColor: '#4caf50',\n        color: 'white',\n        border: 'none',\n        borderRadius: '4px',\n        cursor: 'pointer',\n        transition: 'background-color 0.3s'\n      },\n      children: \"\\u0628\\u062F\\u0621 \\u0627\\u0644\\u0627\\u062E\\u062A\\u0628\\u0627\\u0631\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 706,\n      columnNumber: 9\n    }, this) : /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: stopTest,\n      style: {\n        padding: '12px 24px',\n        fontSize: '16px',\n        backgroundColor: '#f44336',\n        color: 'white',\n        border: 'none',\n        borderRadius: '4px',\n        cursor: 'pointer',\n        transition: 'background-color 0.3s'\n      },\n      children: \"\\u0625\\u064A\\u0642\\u0627\\u0641 \\u0627\\u0644\\u0627\\u062E\\u062A\\u0628\\u0627\\u0631\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 722,\n      columnNumber: 9\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        marginTop: '30px',\n        padding: '15px',\n        backgroundColor: '#f5f5f5',\n        borderRadius: '8px',\n        textAlign: 'right'\n      },\n      children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n        style: {\n          marginTop: '0'\n        },\n        children: \"\\u062A\\u0639\\u0644\\u064A\\u0645\\u0627\\u062A \\u0627\\u0644\\u0627\\u0633\\u062A\\u062E\\u062F\\u0627\\u0645:\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 746,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"ol\", {\n        style: {\n          paddingRight: '20px'\n        },\n        children: [/*#__PURE__*/_jsxDEV(\"li\", {\n          children: \"\\u0627\\u0636\\u063A\\u0637 \\u0639\\u0644\\u0649 \\\"\\u0628\\u062F\\u0621 \\u0627\\u0644\\u0627\\u062E\\u062A\\u0628\\u0627\\u0631\\\" \\u0648\\u0627\\u0644\\u0633\\u0645\\u0627\\u062D \\u0628\\u0627\\u0633\\u062A\\u062E\\u062F\\u0627\\u0645 \\u0627\\u0644\\u0645\\u064A\\u0643\\u0631\\u0648\\u0641\\u0648\\u0646\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 748,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: \"\\u062A\\u062D\\u062F\\u062B \\u0628\\u0634\\u0643\\u0644 \\u0637\\u0628\\u064A\\u0639\\u064A \\u0644\\u0627\\u062E\\u062A\\u0628\\u0627\\u0631 \\u0627\\u0644\\u0646\\u0638\\u0627\\u0645\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 749,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: \"\\u0633\\u064A\\u062A\\u0645 \\u0627\\u0643\\u062A\\u0634\\u0627\\u0641 \\u0623\\u064A \\u062A\\u063A\\u064A\\u064A\\u0631 \\u0645\\u0641\\u0627\\u062C\\u0626 \\u0641\\u064A \\u0627\\u0644\\u0635\\u0648\\u062A\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 750,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: \"3 \\u0627\\u0646\\u062A\\u0647\\u0627\\u0643\\u0627\\u062A \\u0633\\u062A\\u0624\\u062F\\u064A \\u0644\\u0625\\u0646\\u0647\\u0627\\u0621 \\u0627\\u0644\\u0627\\u062E\\u062A\\u0628\\u0627\\u0631 \\u062A\\u0644\\u0642\\u0627\\u0626\\u064A\\u0627\\u064B\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 751,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n          children: \"\\u0627\\u0636\\u063A\\u0637 \\\"\\u0625\\u064A\\u0642\\u0627\\u0641 \\u0627\\u0644\\u0627\\u062E\\u062A\\u0628\\u0627\\u0631\\\" \\u0644\\u0625\\u0646\\u0647\\u0627\\u0621 \\u0627\\u0644\\u0645\\u0631\\u0627\\u0642\\u0628\\u0629\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 752,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 747,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 739,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 660,\n    columnNumber: 5\n  }, this);\n};\n_s(VoiceDetection, \"w9IJxsSgm5eKaDqZ8K0xmc9ArP0=\");\n_c = VoiceDetection;\nexport default VoiceDetection;\nvar _c;\n$RefreshReg$(_c, \"VoiceDetection\");","map":{"version":3,"names":["React","useState","useEffect","useRef","useCallback","jsxDEV","_jsxDEV","VoiceDetection","_s","multipleVoicesDetected","setMultipleVoicesDetected","violations","setViolations","isReady","setIsReady","status","setStatus","volumeLevel","setVolumeLevel","audioContextRef","analyserRef","lastEnergyLevelRef","lastTimestampRef","streamRef","animationFrameRef","createVoiceProfile","current","bufferLength","frequencyBinCount","dataArray","Float32Array","getFloatFrequencyData","totalEnergy","peakCount","i","value","Math","pow","analyzeVoice","currentProfile","energyLevel","energyDifference","abs","timeDifference","Date","now","min","max","isVoiceDetected","isSuddenChange","isNewVoice","requestAnimationFrame","setupVoiceAnalysis","stream","window","AudioContext","webkitAudioContext","createAnalyser","fftSize","source","createMediaStreamSource","connect","error","console","startTest","navigator","mediaDevices","getUserMedia","audio","echoCancellation","noiseSuppression","autoGainControl","stopTest","cancelAnimationFrame","getTracks","forEach","track","stop","state","close","newViolations","alert","style","maxWidth","margin","padding","fontFamily","textAlign","children","color","fileName","_jsxFileName","lineNumber","columnNumber","backgroundColor","borderRadius","border","fontSize","fontWeight","toFixed","width","height","marginTop","overflow","transition","onClick","cursor","paddingRight","_c","$RefreshReg$"],"sources":["C:/Users/HP/Desktop/continous-authentication1/continous-authentication1/continous-authentication/continous-authentication/src/ContinuousAuth.js"],"sourcesContent":["// import React, { useState, useEffect, useRef, useCallback } from \"react\";\r\n// import * as faceapi from \"face-api.js\";\r\n// import Webcam from \"react-webcam\";\r\n// import axios from \"axios\";\r\n// import \"./ContinuousAuth.css\";\r\n\r\n// const ContinuousAuth = () => {\r\n//   const webcamRef = useRef(null);\r\n//   const [faceDetected, setFaceDetected] = useState(false);\r\n//   const [soundDetected, setSoundDetected] = useState(false);\r\n//   const [currentImage, setCurrentImage] = useState(null);\r\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\r\n//   const [examTerminated, setExamTerminated] = useState(false);\r\n//   const [mediaStream, setMediaStream] = useState(null);\r\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\r\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\r\n\r\n//   useEffect(() => {\r\n//     const loadModels = async () => {\r\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\r\n//       console.log(\"Face Detection Model Loaded\");\r\n//     };\r\n//     loadModels();\r\n//   }, []);\r\n\r\n//   const getPermissions = async () => {\r\n//     try {\r\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\r\n//       setMediaStream(stream);\r\n//       setPermissionsGranted(true);\r\n//       setShowPermissionMessage(false);\r\n//       fetchIpAddress(); // Call to fetch IP address when permissions are granted\r\n//     } catch (error) {\r\n//       alert(\"Please allow access to camera and microphone.\");\r\n//       setShowPermissionMessage(true);\r\n//     }\r\n//   };\r\n\r\n//   const fetchIpAddress = async () => {\r\n//     try {\r\n//       const response = await fetch(\"https://api.ipify.org?format=json\");\r\n//       const data = await response.json();\r\n//       alert(`Your IP Address: ${data.ip}`);\r\n//     } catch (error) {\r\n//       console.error(\"Error fetching IP address:\", error);\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (mediaStream) {\r\n//       const tracks = mediaStream.getTracks();\r\n//       tracks.forEach((track) => {\r\n//         track.enabled = true;\r\n//       });\r\n//     }\r\n//   }, [mediaStream]);\r\n\r\n//   const detectFace = async () => {\r\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\r\n//       const video = webcamRef.current.video;\r\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\r\n//       const isFacePresent = detections.length > 0;\r\n//       setFaceDetected(isFacePresent);\r\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       const interval = setInterval(detectFace, 1000);\r\n//       return () => clearInterval(interval);\r\n//     }\r\n//   }, [permissionsGranted]);\r\n\r\n//   useEffect(() => {\r\n//     if (noFaceDuration >= 15) {\r\n//       alert(\"‚ö†Ô∏è Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\r\n//       setNoFaceDuration(0);\r\n//     }\r\n//   }, [noFaceDuration]);\r\n\r\n//   const detectSound = useCallback(() => {\r\n//     if (!mediaStream) return;\r\n\r\n//     const audioContext = new AudioContext();\r\n//     const analyser = audioContext.createAnalyser();\r\n//     const source = audioContext.createMediaStreamSource(mediaStream);\r\n//     source.connect(analyser);\r\n//     analyser.fftSize = 256;\r\n//     const bufferLength = analyser.frequencyBinCount;\r\n//     const dataArray = new Uint8Array(bufferLength);\r\n\r\n//     const checkSound = () => {\r\n//       analyser.getByteFrequencyData(dataArray);\r\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\r\n//       setSoundDetected(volume > 10);\r\n//       requestAnimationFrame(checkSound);\r\n//     };\r\n//     checkSound();\r\n//   }, [mediaStream]);\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       detectSound();\r\n//     }\r\n//   }, [permissionsGranted, detectSound]);\r\n\r\n//   return (\r\n//     <div className=\"continuous-auth-container\">\r\n//       <h2>Continuous Authentication</h2>\r\n\r\n//       {showPermissionMessage && (\r\n//         <div className=\"permission-message\">\r\n//           <p>Please allow access to your camera and microphone to start the exam.</p>\r\n//           <button onClick={getPermissions}>Allow Camera and Microphone</button>\r\n//         </div>\r\n//       )}\r\n\r\n//       {permissionsGranted ? (\r\n//         <>\r\n//           <Webcam\r\n//             audio={true}\r\n//             ref={webcamRef}\r\n//             screenshotFormat=\"image/jpeg\"\r\n//             className=\"webcam\"\r\n//             videoConstraints={{\r\n//               facingMode: \"user\",\r\n//               width: 720,\r\n//               height: 400,\r\n//             }}\r\n//           />\r\n//           <p>Camera and microphone are active for proctoring.</p>\r\n\r\n//           <div className=\"status-buttons-container\">\r\n//             <div className=\"status-buttons\">\r\n//               <button className={faceDetected ? \"detected-btn\" : \"not-detected-btn\"}>\r\n//                 {faceDetected ? \"Face Detected ‚úÖ\" : \"No Face Detected ‚ùå\"}\r\n//               </button>\r\n//               <button className={soundDetected ? \"detected-btn\" : \"not-detected-btn\"}>\r\n//                 {soundDetected ? \"Sound Detected üîä\" : \"No Sound Detected üîá\"}\r\n//               </button>\r\n//             </div>\r\n\r\n//             <div className=\"captured-images\">\r\n//               {currentImage && <img src={currentImage} alt=\"Captured\" className=\"small-image\" />}\r\n//             </div>\r\n//           </div>\r\n//         </>\r\n//       ) : (\r\n//         <p>Waiting for camera and microphone access...</p>\r\n//       )}\r\n\r\n//       {examTerminated && <p className=\"mismatch-count\">Exam Terminated due to 3 mismatches.</p>}\r\n//     </div>\r\n//   );\r\n// };\r\n\r\n// export default ContinuousAuth;\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n// import React, { useState, useEffect, useRef, useCallback } from \"react\";\r\n// import * as faceapi from \"face-api.js\";\r\n// import Webcam from \"react-webcam\";\r\n// import \"./ContinuousAuth.css\";\r\n\r\n// const ContinuousAuth = () => {\r\n//   const webcamRef = useRef(null);\r\n//   const [faceDetected, setFaceDetected] = useState(false);\r\n//   const [soundDetected, setSoundDetected] = useState(false);\r\n//   const [currentImage, setCurrentImage] = useState(null);\r\n//   const [permissionsGranted, setPermissionsGranted] = useState(false);\r\n//   const [examTerminated, setExamTerminated] = useState(false);\r\n//   const [mediaStream, setMediaStream] = useState(null);\r\n//   const [showPermissionMessage, setShowPermissionMessage] = useState(true);\r\n//   const [noFaceDuration, setNoFaceDuration] = useState(0);\r\n//   const [transcript, setTranscript] = useState(\"\");\r\n//   const [violations, setViolations] = useState(0);\r\n//   const recognitionRef = useRef(null);\r\n\r\n//   // ŸÜÿ∏ÿßŸÖ ŸÉÿ¥ŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\r\n//   const [multipleVoicesDetected, setMultipleVoicesDetected] = useState(false);\r\n//   const audioContextRef = useRef(null);\r\n//   const analyserRef = useRef(null);\r\n//   const voiceProfileRef = useRef({\r\n//     baseline: null,\r\n//     lastAlert: 0,\r\n//     active: false\r\n//   });\r\n\r\n//   useEffect(() => {\r\n//     const loadModels = async () => {\r\n//       await faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\");\r\n//       console.log(\"Face Detection Model Loaded\");\r\n//     };\r\n//     loadModels();\r\n//   }, []);\r\n\r\n//   const getPermissions = async () => {\r\n//     try {\r\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\r\n//       setMediaStream(stream);\r\n//       setPermissionsGranted(true);\r\n//       setShowPermissionMessage(false);\r\n//       initializeSpeechRecognition();\r\n//       setupVoiceAnalysis(stream);\r\n//     } catch (error) {\r\n//       alert(\"Please allow access to camera and microphone.\");\r\n//       setShowPermissionMessage(true);\r\n//     }\r\n//   };\r\n\r\n//   // ŸÜÿ∏ÿßŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ\r\n//   const setupVoiceAnalysis = (stream) => {\r\n//     try {\r\n//       audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\r\n//       analyserRef.current = audioContextRef.current.createAnalyser();\r\n//       analyserRef.current.fftSize = 4096;\r\n      \r\n//       const source = audioContextRef.current.createMediaStreamSource(stream);\r\n//       source.connect(analyserRef.current);\r\n\r\n//       // ÿ•ŸÜÿ¥ÿßÿ° ÿ®ÿµŸÖÿ© ÿµŸàÿ™Ÿäÿ© ÿ£ŸàŸÑŸäÿ© ÿ®ÿπÿØ 3 ÿ´ŸàÿßŸÜŸä\r\n//       setTimeout(() => {\r\n//         voiceProfileRef.current.baseline = createVoiceProfile();\r\n//         voiceProfileRef.current.active = true;\r\n//       }, 3000);\r\n\r\n//       const analyzeVoice = () => {\r\n//         if (!voiceProfileRef.current.active) {\r\n//           requestAnimationFrame(analyzeVoice);\r\n//           return;\r\n//         }\r\n\r\n//         const currentProfile = createVoiceProfile();\r\n//         const isMultiple = compareVoiceProfiles(voiceProfileRef.current.baseline, currentProfile);\r\n        \r\n//         if (isMultiple && Date.now() - voiceProfileRef.current.lastAlert > 5000) {\r\n//           setMultipleVoicesDetected(true);\r\n//           voiceProfileRef.current.lastAlert = Date.now();\r\n//         } else {\r\n//           setMultipleVoicesDetected(false);\r\n//         }\r\n\r\n//         requestAnimationFrame(analyzeVoice);\r\n//       };\r\n\r\n//       analyzeVoice();\r\n//     } catch (error) {\r\n//       console.error(\"Voice analysis error:\", error);\r\n//     }\r\n//   };\r\n\r\n//   const createVoiceProfile = () => {\r\n//     const bufferLength = analyserRef.current.frequencyBinCount;\r\n//     const dataArray = new Float32Array(bufferLength);\r\n//     analyserRef.current.getFloatFrequencyData(dataArray);\r\n\r\n//     const profile = {\r\n//       lowRange: 0,    // 85-300Hz\r\n//       midRange: 0,    // 300-1000Hz\r\n//       highRange: 0,   // 1000-4000Hz\r\n//       peakCount: 0,\r\n//       totalEnergy: 0\r\n//     };\r\n\r\n//     for (let i = 0; i < bufferLength; i++) {\r\n//       const freq = i * audioContextRef.current.sampleRate / analyserRef.current.fftSize;\r\n//       const value = Math.pow(10, dataArray[i]/20); // Convert dB to linear\r\n\r\n//       if (freq >= 85 && freq < 300) {\r\n//         profile.lowRange += value;\r\n//       } else if (freq >= 300 && freq < 1000) {\r\n//         profile.midRange += value;\r\n//       } else if (freq >= 1000 && freq < 4000) {\r\n//         profile.highRange += value;\r\n//       }\r\n\r\n//       if (dataArray[i] > -40) profile.peakCount++;\r\n//       profile.totalEnergy += value;\r\n//     }\r\n\r\n//     return profile;\r\n//   };\r\n\r\n//   const compareVoiceProfiles = (baseline, current) => {\r\n//     // ÿ≠ÿ≥ÿßÿ® ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ™ÿ∫Ÿäÿ± ŸÑŸÉŸÑ ŸÜÿ∑ÿßŸÇ ÿ™ÿ±ÿØÿØŸä\r\n//     const lowDiff = Math.abs(current.lowRange - baseline.lowRange) / baseline.lowRange;\r\n//     const midDiff = Math.abs(current.midRange - baseline.midRange) / baseline.midRange;\r\n//     const highDiff = Math.abs(current.highRange - baseline.highRange) / baseline.highRange;\r\n//     const energyDiff = Math.abs(current.totalEnergy - baseline.totalEnergy) / baseline.totalEnergy;\r\n//     const peakDiff = Math.abs(current.peakCount - baseline.peakCount);\r\n\r\n//     // ÿ¥ÿ±Ÿàÿ∑ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ©\r\n//     return (\r\n//       (lowDiff > 0.6 || midDiff > 0.6 || highDiff > 0.6) &&\r\n//       energyDiff > 0.4 &&\r\n//       peakDiff > 15\r\n//     );\r\n//   };\r\n\r\n//   const initializeSpeechRecognition = () => {\r\n//     const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n//     if (!SpeechRecognition) {\r\n//       console.error(\"Speech Recognition API not supported in this browser\");\r\n//       return;\r\n//     }\r\n\r\n//     recognitionRef.current = new SpeechRecognition();\r\n//     recognitionRef.current.continuous = true;\r\n//     recognitionRef.current.interimResults = false;\r\n//     recognitionRef.current.lang = \"ar-SA\";\r\n\r\n//     recognitionRef.current.onresult = (event) => {\r\n//       const last = event.results.length - 1;\r\n//       const text = event.results[last][0].transcript;\r\n//       setTranscript(text);\r\n//     };\r\n\r\n//     recognitionRef.current.onerror = (event) => {\r\n//       console.error(\"Speech recognition error\", event.error);\r\n//     };\r\n\r\n//     recognitionRef.current.start();\r\n//     recognitionRef.current.onend = () => {\r\n//       recognitionRef.current.start();\r\n//     };\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (mediaStream) {\r\n//       const tracks = mediaStream.getTracks();\r\n//       tracks.forEach((track) => {\r\n//         track.enabled = true;\r\n//       });\r\n//     }\r\n\r\n//     return () => {\r\n//       if (recognitionRef.current) {\r\n//         recognitionRef.current.stop();\r\n//       }\r\n//       if (audioContextRef.current) {\r\n//         audioContextRef.current.close();\r\n//       }\r\n//     };\r\n//   }, [mediaStream]);\r\n\r\n//   const detectFace = async () => {\r\n//     if (webcamRef.current && webcamRef.current.video.readyState === 4) {\r\n//       const video = webcamRef.current.video;\r\n//       const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\r\n//       const isFacePresent = detections.length > 0;\r\n//       setFaceDetected(isFacePresent);\r\n//       setNoFaceDuration((prev) => (isFacePresent ? 0 : prev + 1));\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       const interval = setInterval(detectFace, 1000);\r\n//       return () => clearInterval(interval);\r\n//     }\r\n//   }, [permissionsGranted]);\r\n\r\n//   useEffect(() => {\r\n//     if (noFaceDuration >= 15) {\r\n//       alert(\"‚ö† Face not detected for 15 seconds. Please make sure your face is clearly visible.\");\r\n//       setNoFaceDuration(0);\r\n//     }\r\n//   }, [noFaceDuration]);\r\n\r\n//   const detectSound = useCallback(() => {\r\n//     if (!mediaStream) return;\r\n\r\n//     const audioContext = new AudioContext();\r\n//     const analyser = audioContext.createAnalyser();\r\n//     const source = audioContext.createMediaStreamSource(mediaStream);\r\n//     source.connect(analyser);\r\n//     analyser.fftSize = 256;\r\n//     const bufferLength = analyser.frequencyBinCount;\r\n//     const dataArray = new Uint8Array(bufferLength);\r\n\r\n//     const checkSound = () => {\r\n//       analyser.getByteFrequencyData(dataArray);\r\n//       const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\r\n//       setSoundDetected(volume > 10);\r\n//       requestAnimationFrame(checkSound);\r\n//     };\r\n//     checkSound();\r\n//   }, [mediaStream]);\r\n\r\n//   useEffect(() => {\r\n//     if (permissionsGranted) {\r\n//       detectSound();\r\n//     }\r\n//   }, [permissionsGranted, detectSound]);\r\n\r\n//   useEffect(() => {\r\n//     if (multipleVoicesDetected) {\r\n//       const newViolations = violations + 1;\r\n//       setViolations(newViolations);\r\n      \r\n//       alert(`üö® MULTIPLE VOICES DETECTED! (Violation ${newViolations}/3)`);\r\n      \r\n//       if (newViolations >= 3) {\r\n//         setExamTerminated(true);\r\n//       }\r\n//     }\r\n//   }, [multipleVoicesDetected]);\r\n\r\n//   return (\r\n//     <div className=\"continuous-auth-container\">\r\n//       <h2>Exam Proctoring System</h2>\r\n\r\n//       {showPermissionMessage && (\r\n//         <div className=\"permission-message\">\r\n//           <h3>Exam Proctoring Setup</h3>\r\n//           <p>This exam requires camera and microphone access for proctoring purposes.</p>\r\n//           <div className=\"permission-requirements\">\r\n//             <p>‚úì Face detection must be enabled</p>\r\n//             <p>‚úì Microphone must be active</p>\r\n//           </div>\r\n//           <button className=\"permission-button\" onClick={getPermissions}>\r\n//             Enable Camera & Microphone\r\n//           </button>\r\n//         </div>\r\n//       )}\r\n\r\n//       {permissionsGranted && !examTerminated && (\r\n//         <div className=\"monitoring-container\">\r\n//           <div className=\"video-section\">\r\n//             <Webcam\r\n//               audio={true}\r\n//               ref={webcamRef}\r\n//               screenshotFormat=\"image/jpeg\"\r\n//               className=\"webcam\"\r\n//               videoConstraints={{\r\n//                 facingMode: \"user\",\r\n//                 width: 480,\r\n//                 height: 360,\r\n//               }}\r\n//             />\r\n//             <div className=\"status-indicators\">\r\n//               <div className={`status-indicator ${faceDetected ? \"active\" : \"\"}`}>\r\n//                 {faceDetected ? \"Face Detected\" : \"No Face Detected\"}\r\n//               </div>\r\n//               <div className={`status-indicator ${soundDetected ? \"active\" : \"\"}`}>\r\n//                 {soundDetected ? \"Sound Detected\" : \"No Sound Detected\"}\r\n//               </div>\r\n//               {multipleVoicesDetected && (\r\n//                 <div className=\"status-indicator warning\">\r\n//                   Multiple Voices Detected!\r\n//                 </div>\r\n//               )}\r\n//             </div>\r\n//           </div>\r\n\r\n//           <div className=\"transcript-section\">\r\n//             <div className=\"transcript-box\">\r\n//               <div className=\"transcript-header\">\r\n//                 <span>Arabic Speech Transcript</span>\r\n//                 <span className=\"violation-counter\">Violations: {violations}/3</span>\r\n//               </div>\r\n//               <div className=\"transcript-content\" dir=\"rtl\">\r\n//                 {transcript || \"Waiting for audio input...\"}\r\n//               </div>\r\n//               <div className={`voice-detection-status ${multipleVoicesDetected ? \"multiple\" : \"\"}`}>\r\n//                 {multipleVoicesDetected \r\n//                   ? \"Multiple voices detected!\" \r\n//                   : \"Voice analysis active\"}\r\n//               </div>\r\n//             </div>\r\n//           </div>\r\n//         </div>\r\n//       )}\r\n\r\n//       {examTerminated && (\r\n//         <div className=\"termination-message\">\r\n//           <h3>‚úñ Exam Terminated</h3>\r\n//           <p>Due to multiple violations detected. Please contact your instructor.</p>\r\n//           <p>Total violations: {violations}</p>\r\n//         </div>\r\n//       )}\r\n//     </div>\r\n//   );\r\n// };\r\n\r\n// export default ContinuousAuth;\r\n\r\n\r\n\r\n\r\n//////////////////////////////////////////////////////////////////////////////////// \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nimport React, { useState, useEffect, useRef, useCallback } from \"react\";\r\n\r\nconst VoiceDetection = () => {\r\n  const [multipleVoicesDetected, setMultipleVoicesDetected] = useState(false);\r\n  const [violations, setViolations] = useState(0);\r\n  const [isReady, setIsReady] = useState(false);\r\n  const [status, setStatus] = useState(\"ÿßŸÜŸÇÿ± ÿπŸÑŸâ ÿ®ÿØÿ° ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ± ŸÑÿ®ÿØÿ° ÿßŸÑŸÖÿ±ÿßŸÇÿ®ÿ©\");\r\n  const [volumeLevel, setVolumeLevel] = useState(0);\r\n\r\n  const audioContextRef = useRef(null);\r\n  const analyserRef = useRef(null);\r\n  const lastEnergyLevelRef = useRef(0);\r\n  const lastTimestampRef = useRef(0);\r\n  const streamRef = useRef(null);\r\n  const animationFrameRef = useRef(null);\r\n\r\n  // ÿ•ŸÜÿ¥ÿßÿ° ÿ®ÿµŸÖÿ© ÿµŸàÿ™Ÿäÿ©\r\n  const createVoiceProfile = () => {\r\n    if (!analyserRef.current) return null;\r\n\r\n    const bufferLength = analyserRef.current.frequencyBinCount;\r\n    const dataArray = new Float32Array(bufferLength);\r\n    analyserRef.current.getFloatFrequencyData(dataArray);\r\n\r\n    let totalEnergy = 0;\r\n    let peakCount = 0;\r\n\r\n    for (let i = 0; i < bufferLength; i++) {\r\n      const value = Math.pow(10, dataArray[i] / 20);\r\n      totalEnergy += value;\r\n      if (dataArray[i] > -40) peakCount++;\r\n    }\r\n\r\n    return { totalEnergy, peakCount };\r\n  };\r\n\r\n  // ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™\r\n  const analyzeVoice = useCallback(() => {\r\n    if (!analyserRef.current) return;\r\n\r\n    const currentProfile = createVoiceProfile();\r\n    if (!currentProfile) return;\r\n\r\n    const energyLevel = currentProfile.totalEnergy;\r\n    const energyDifference = Math.abs(energyLevel - lastEnergyLevelRef.current);\r\n    const timeDifference = Date.now() - lastTimestampRef.current;\r\n\r\n    setVolumeLevel(Math.min(100, Math.max(0, energyLevel / 10)));\r\n\r\n    // ÿ¥ÿ±Ÿàÿ∑ ÿßŸÑŸÉÿ¥ŸÅ ÿßŸÑŸÖÿ≠ÿ≥ŸÜÿ©\r\n    const isVoiceDetected = energyLevel > 5; // ŸÖÿ≥ÿ™ŸàŸâ ÿ∑ÿßŸÇÿ© ÿ£ÿ≥ÿßÿ≥Ÿä\r\n    const isSuddenChange = energyDifference > 10 && timeDifference < 300;\r\n    const isNewVoice = isVoiceDetected && (isSuddenChange || energyLevel > lastEnergyLevelRef.current * 1.5);\r\n\r\n    if (isNewVoice) {\r\n      setMultipleVoicesDetected(true);\r\n      setStatus(\"ÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿµŸàÿ™ ÿ¨ÿØŸäÿØ!\");\r\n      lastEnergyLevelRef.current = energyLevel;\r\n      lastTimestampRef.current = Date.now();\r\n    } else {\r\n      setMultipleVoicesDetected(false);\r\n      setStatus(\"ÿ¨ÿßÿ±Ÿä ÿßŸÑŸÖÿ±ÿßŸÇÿ®ÿ©...\");\r\n    }\r\n\r\n    animationFrameRef.current = requestAnimationFrame(analyzeVoice);\r\n  }, []);\r\n\r\n  // ÿ•ÿπÿØÿßÿØ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™Ÿä\r\n  const setupVoiceAnalysis = useCallback((stream) => {\r\n    try {\r\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\r\n      analyserRef.current = audioContextRef.current.createAnalyser();\r\n      analyserRef.current.fftSize = 2048;\r\n      \r\n      const source = audioContextRef.current.createMediaStreamSource(stream);\r\n      source.connect(analyserRef.current);\r\n      \r\n      setStatus(\"ÿ¨ÿßÿ±Ÿä ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™...\");\r\n      animationFrameRef.current = requestAnimationFrame(analyzeVoice);\r\n    } catch (error) {\r\n      console.error(\"ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™:\", error);\r\n      setStatus(\"ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ™\");\r\n    }\r\n  }, [analyzeVoice]);\r\n\r\n  // ÿ®ÿØÿ° ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±\r\n  const startTest = async () => {\r\n    try {\r\n      setStatus(\"ÿ¨ÿßÿ±Ÿä ÿ∑ŸÑÿ® ÿ•ÿ∞ŸÜ ÿßŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ...\");\r\n      const stream = await navigator.mediaDevices.getUserMedia({ \r\n        audio: {\r\n          echoCancellation: false,\r\n          noiseSuppression: false,\r\n          autoGainControl: false\r\n        }\r\n      });\r\n      streamRef.current = stream;\r\n      \r\n      setupVoiceAnalysis(stream);\r\n      setIsReady(true);\r\n      setStatus(\"ÿ¨ÿßÿ±Ÿä ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑÿµŸàÿ™...\");\r\n    } catch (error) {\r\n      console.error(\"ÿÆÿ∑ÿ£ ŸÅŸä ÿßŸÑŸàÿµŸàŸÑ ÿ•ŸÑŸâ ÿßŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ:\", error);\r\n      setStatus(\"ŸÅÿ¥ŸÑ ŸÅŸä ÿßŸÑŸàÿµŸàŸÑ ÿ•ŸÑŸâ ÿßŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿßŸÑÿ£ÿ∞ŸàŸÜÿßÿ™\");\r\n    }\r\n  };\r\n\r\n  // ÿ•ŸäŸÇÿßŸÅ ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±\r\n  const stopTest = () => {\r\n    if (animationFrameRef.current) {\r\n      cancelAnimationFrame(animationFrameRef.current);\r\n    }\r\n    \r\n    if (streamRef.current) {\r\n      streamRef.current.getTracks().forEach(track => track.stop());\r\n    }\r\n    \r\n    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {\r\n      audioContextRef.current.close();\r\n    }\r\n    \r\n    setIsReady(false);\r\n    setStatus(\"ÿ™ŸÖ ÿ•ŸäŸÇÿßŸÅ ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±\");\r\n    setVolumeLevel(0);\r\n  };\r\n\r\n  // ÿ™ÿ£ÿ´Ÿäÿ± ŸÑŸÑŸÉÿ¥ŸÅ ÿπŸÜ ÿßŸÑÿßŸÜÿ™ŸáÿßŸÉÿßÿ™\r\n  useEffect(() => {\r\n    if (multipleVoicesDetected) {\r\n      const newViolations = violations + 1;\r\n      setViolations(newViolations);\r\n      \r\n      alert(`üö® ÿßŸÜÿ™ÿ®ÿßŸá! ÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿµŸàÿ™ ÿ•ÿ∂ÿßŸÅŸä (ÿßŸÜÿ™ŸáÿßŸÉ ${newViolations}/3)`);\r\n\r\n      if (newViolations >= 3) {\r\n        alert(\"‚úñ ÿ™ŸÖ ÿ•ŸÜŸáÿßÿ° ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ± ÿ®ÿ≥ÿ®ÿ® ÿßŸÉÿ™ÿ¥ÿßŸÅ 3 ÿßŸÜÿ™ŸáÿßŸÉÿßÿ™\");\r\n        stopTest();\r\n      }\r\n    }\r\n  }, [multipleVoicesDetected, violations]);\r\n\r\n  // ÿ™ŸÜÿ∏ŸäŸÅ ÿßŸÑŸÖŸàÿßÿ±ÿØ ÿπŸÜÿØ unmount\r\n  useEffect(() => {\r\n    return () => {\r\n      stopTest();\r\n    };\r\n  }, []);\r\n\r\n  return (\r\n    <div style={{\r\n      maxWidth: '600px',\r\n      margin: '0 auto',\r\n      padding: '20px',\r\n      fontFamily: 'Arial, sans-serif',\r\n      textAlign: 'center'\r\n    }}>\r\n      <h2 style={{ color: '#333' }}>ŸÜÿ∏ÿßŸÖ ŸÉÿ¥ŸÅ ÿßŸÑÿ£ÿµŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿπÿØÿØÿ©</h2>\r\n      \r\n      <div style={{\r\n        margin: '20px 0',\r\n        padding: '15px',\r\n        backgroundColor: multipleVoicesDetected ? '#ffebee' : '#e8f5e9',\r\n        borderRadius: '8px',\r\n        border: `2px solid ${multipleVoicesDetected ? '#f44336' : '#4caf50'}`\r\n      }}>\r\n        <p style={{\r\n          fontSize: '18px',\r\n          fontWeight: 'bold',\r\n          color: multipleVoicesDetected ? '#f44336' : '#2e7d32'\r\n        }}>\r\n          {status}\r\n        </p>\r\n        <p>ŸÖÿ≥ÿ™ŸàŸâ ÿßŸÑÿµŸàÿ™: {volumeLevel.toFixed(1)}</p>\r\n        <div style={{\r\n          width: '100%',\r\n          height: '20px',\r\n          backgroundColor: '#ddd',\r\n          borderRadius: '10px',\r\n          marginTop: '10px',\r\n          overflow: 'hidden'\r\n        }}>\r\n          <div style={{\r\n            width: `${volumeLevel}%`,\r\n            height: '100%',\r\n            backgroundColor: multipleVoicesDetected ? '#f44336' : '#4caf50',\r\n            transition: 'width 0.3s'\r\n          }}></div>\r\n        </div>\r\n      </div>\r\n      \r\n      <div style={{ margin: '20px 0' }}>\r\n        <p style={{ fontSize: '16px' }}>ÿπÿØÿØ ÿßŸÑÿßŸÜÿ™ŸáÿßŸÉÿßÿ™: <strong>{violations}</strong>/3</p>\r\n      </div>\r\n      \r\n      {!isReady ? (\r\n        <button \r\n          onClick={startTest}\r\n          style={{\r\n            padding: '12px 24px',\r\n            fontSize: '16px',\r\n            backgroundColor: '#4caf50',\r\n            color: 'white',\r\n            border: 'none',\r\n            borderRadius: '4px',\r\n            cursor: 'pointer',\r\n            transition: 'background-color 0.3s'\r\n          }}\r\n        >\r\n          ÿ®ÿØÿ° ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±\r\n        </button>\r\n      ) : (\r\n        <button \r\n          onClick={stopTest}\r\n          style={{\r\n            padding: '12px 24px',\r\n            fontSize: '16px',\r\n            backgroundColor: '#f44336',\r\n            color: 'white',\r\n            border: 'none',\r\n            borderRadius: '4px',\r\n            cursor: 'pointer',\r\n            transition: 'background-color 0.3s'\r\n          }}\r\n        >\r\n          ÿ•ŸäŸÇÿßŸÅ ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±\r\n        </button>\r\n      )}\r\n      \r\n      <div style={{\r\n        marginTop: '30px',\r\n        padding: '15px',\r\n        backgroundColor: '#f5f5f5',\r\n        borderRadius: '8px',\r\n        textAlign: 'right'\r\n      }}>\r\n        <h3 style={{ marginTop: '0' }}>ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:</h3>\r\n        <ol style={{ paddingRight: '20px' }}>\r\n          <li>ÿßÿ∂ÿ∫ÿ∑ ÿπŸÑŸâ \"ÿ®ÿØÿ° ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±\" ŸàÿßŸÑÿ≥ŸÖÿßÿ≠ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ</li>\r\n          <li>ÿ™ÿ≠ÿØÿ´ ÿ®ÿ¥ŸÉŸÑ ÿ∑ÿ®ŸäÿπŸä ŸÑÿßÿÆÿ™ÿ®ÿßÿ± ÿßŸÑŸÜÿ∏ÿßŸÖ</li>\r\n          <li>ÿ≥Ÿäÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿ£Ÿä ÿ™ÿ∫ŸäŸäÿ± ŸÖŸÅÿßÿ¨ÿ¶ ŸÅŸä ÿßŸÑÿµŸàÿ™</li>\r\n          <li>3 ÿßŸÜÿ™ŸáÿßŸÉÿßÿ™ ÿ≥ÿ™ÿ§ÿØŸä ŸÑÿ•ŸÜŸáÿßÿ° ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ± ÿ™ŸÑŸÇÿßÿ¶ŸäÿßŸã</li>\r\n          <li>ÿßÿ∂ÿ∫ÿ∑ \"ÿ•ŸäŸÇÿßŸÅ ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±\" ŸÑÿ•ŸÜŸáÿßÿ° ÿßŸÑŸÖÿ±ÿßŸÇÿ®ÿ©</li>\r\n        </ol>\r\n      </div>\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default VoiceDetection;\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"],"mappings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xE,MAAMC,cAAc,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC3B,MAAM,CAACC,sBAAsB,EAAEC,yBAAyB,CAAC,GAAGT,QAAQ,CAAC,KAAK,CAAC;EAC3E,MAAM,CAACU,UAAU,EAAEC,aAAa,CAAC,GAAGX,QAAQ,CAAC,CAAC,CAAC;EAC/C,MAAM,CAACY,OAAO,EAAEC,UAAU,CAAC,GAAGb,QAAQ,CAAC,KAAK,CAAC;EAC7C,MAAM,CAACc,MAAM,EAAEC,SAAS,CAAC,GAAGf,QAAQ,CAAC,qCAAqC,CAAC;EAC3E,MAAM,CAACgB,WAAW,EAAEC,cAAc,CAAC,GAAGjB,QAAQ,CAAC,CAAC,CAAC;EAEjD,MAAMkB,eAAe,GAAGhB,MAAM,CAAC,IAAI,CAAC;EACpC,MAAMiB,WAAW,GAAGjB,MAAM,CAAC,IAAI,CAAC;EAChC,MAAMkB,kBAAkB,GAAGlB,MAAM,CAAC,CAAC,CAAC;EACpC,MAAMmB,gBAAgB,GAAGnB,MAAM,CAAC,CAAC,CAAC;EAClC,MAAMoB,SAAS,GAAGpB,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMqB,iBAAiB,GAAGrB,MAAM,CAAC,IAAI,CAAC;;EAEtC;EACA,MAAMsB,kBAAkB,GAAGA,CAAA,KAAM;IAC/B,IAAI,CAACL,WAAW,CAACM,OAAO,EAAE,OAAO,IAAI;IAErC,MAAMC,YAAY,GAAGP,WAAW,CAACM,OAAO,CAACE,iBAAiB;IAC1D,MAAMC,SAAS,GAAG,IAAIC,YAAY,CAACH,YAAY,CAAC;IAChDP,WAAW,CAACM,OAAO,CAACK,qBAAqB,CAACF,SAAS,CAAC;IAEpD,IAAIG,WAAW,GAAG,CAAC;IACnB,IAAIC,SAAS,GAAG,CAAC;IAEjB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGP,YAAY,EAAEO,CAAC,EAAE,EAAE;MACrC,MAAMC,KAAK,GAAGC,IAAI,CAACC,GAAG,CAAC,EAAE,EAAER,SAAS,CAACK,CAAC,CAAC,GAAG,EAAE,CAAC;MAC7CF,WAAW,IAAIG,KAAK;MACpB,IAAIN,SAAS,CAACK,CAAC,CAAC,GAAG,CAAC,EAAE,EAAED,SAAS,EAAE;IACrC;IAEA,OAAO;MAAED,WAAW;MAAEC;IAAU,CAAC;EACnC,CAAC;;EAED;EACA,MAAMK,YAAY,GAAGlC,WAAW,CAAC,MAAM;IACrC,IAAI,CAACgB,WAAW,CAACM,OAAO,EAAE;IAE1B,MAAMa,cAAc,GAAGd,kBAAkB,CAAC,CAAC;IAC3C,IAAI,CAACc,cAAc,EAAE;IAErB,MAAMC,WAAW,GAAGD,cAAc,CAACP,WAAW;IAC9C,MAAMS,gBAAgB,GAAGL,IAAI,CAACM,GAAG,CAACF,WAAW,GAAGnB,kBAAkB,CAACK,OAAO,CAAC;IAC3E,MAAMiB,cAAc,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGvB,gBAAgB,CAACI,OAAO;IAE5DR,cAAc,CAACkB,IAAI,CAACU,GAAG,CAAC,GAAG,EAAEV,IAAI,CAACW,GAAG,CAAC,CAAC,EAAEP,WAAW,GAAG,EAAE,CAAC,CAAC,CAAC;;IAE5D;IACA,MAAMQ,eAAe,GAAGR,WAAW,GAAG,CAAC,CAAC,CAAC;IACzC,MAAMS,cAAc,GAAGR,gBAAgB,GAAG,EAAE,IAAIE,cAAc,GAAG,GAAG;IACpE,MAAMO,UAAU,GAAGF,eAAe,KAAKC,cAAc,IAAIT,WAAW,GAAGnB,kBAAkB,CAACK,OAAO,GAAG,GAAG,CAAC;IAExG,IAAIwB,UAAU,EAAE;MACdxC,yBAAyB,CAAC,IAAI,CAAC;MAC/BM,SAAS,CAAC,qBAAqB,CAAC;MAChCK,kBAAkB,CAACK,OAAO,GAAGc,WAAW;MACxClB,gBAAgB,CAACI,OAAO,GAAGkB,IAAI,CAACC,GAAG,CAAC,CAAC;IACvC,CAAC,MAAM;MACLnC,yBAAyB,CAAC,KAAK,CAAC;MAChCM,SAAS,CAAC,kBAAkB,CAAC;IAC/B;IAEAQ,iBAAiB,CAACE,OAAO,GAAGyB,qBAAqB,CAACb,YAAY,CAAC;EACjE,CAAC,EAAE,EAAE,CAAC;;EAEN;EACA,MAAMc,kBAAkB,GAAGhD,WAAW,CAAEiD,MAAM,IAAK;IACjD,IAAI;MACFlC,eAAe,CAACO,OAAO,GAAG,KAAK4B,MAAM,CAACC,YAAY,IAAID,MAAM,CAACE,kBAAkB,EAAE,CAAC;MAClFpC,WAAW,CAACM,OAAO,GAAGP,eAAe,CAACO,OAAO,CAAC+B,cAAc,CAAC,CAAC;MAC9DrC,WAAW,CAACM,OAAO,CAACgC,OAAO,GAAG,IAAI;MAElC,MAAMC,MAAM,GAAGxC,eAAe,CAACO,OAAO,CAACkC,uBAAuB,CAACP,MAAM,CAAC;MACtEM,MAAM,CAACE,OAAO,CAACzC,WAAW,CAACM,OAAO,CAAC;MAEnCV,SAAS,CAAC,qBAAqB,CAAC;MAChCQ,iBAAiB,CAACE,OAAO,GAAGyB,qBAAqB,CAACb,YAAY,CAAC;IACjE,CAAC,CAAC,OAAOwB,KAAK,EAAE;MACdC,OAAO,CAACD,KAAK,CAAC,qBAAqB,EAAEA,KAAK,CAAC;MAC3C9C,SAAS,CAAC,wBAAwB,CAAC;IACrC;EACF,CAAC,EAAE,CAACsB,YAAY,CAAC,CAAC;;EAElB;EACA,MAAM0B,SAAS,GAAG,MAAAA,CAAA,KAAY;IAC5B,IAAI;MACFhD,SAAS,CAAC,4BAA4B,CAAC;MACvC,MAAMqC,MAAM,GAAG,MAAMY,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QACvDC,KAAK,EAAE;UACLC,gBAAgB,EAAE,KAAK;UACvBC,gBAAgB,EAAE,KAAK;UACvBC,eAAe,EAAE;QACnB;MACF,CAAC,CAAC;MACFhD,SAAS,CAACG,OAAO,GAAG2B,MAAM;MAE1BD,kBAAkB,CAACC,MAAM,CAAC;MAC1BvC,UAAU,CAAC,IAAI,CAAC;MAChBE,SAAS,CAAC,sBAAsB,CAAC;IACnC,CAAC,CAAC,OAAO8C,KAAK,EAAE;MACdC,OAAO,CAACD,KAAK,CAAC,+BAA+B,EAAEA,KAAK,CAAC;MACrD9C,SAAS,CAAC,uDAAuD,CAAC;IACpE;EACF,CAAC;;EAED;EACA,MAAMwD,QAAQ,GAAGA,CAAA,KAAM;IACrB,IAAIhD,iBAAiB,CAACE,OAAO,EAAE;MAC7B+C,oBAAoB,CAACjD,iBAAiB,CAACE,OAAO,CAAC;IACjD;IAEA,IAAIH,SAAS,CAACG,OAAO,EAAE;MACrBH,SAAS,CAACG,OAAO,CAACgD,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;IAC9D;IAEA,IAAI1D,eAAe,CAACO,OAAO,IAAIP,eAAe,CAACO,OAAO,CAACoD,KAAK,KAAK,QAAQ,EAAE;MACzE3D,eAAe,CAACO,OAAO,CAACqD,KAAK,CAAC,CAAC;IACjC;IAEAjE,UAAU,CAAC,KAAK,CAAC;IACjBE,SAAS,CAAC,mBAAmB,CAAC;IAC9BE,cAAc,CAAC,CAAC,CAAC;EACnB,CAAC;;EAED;EACAhB,SAAS,CAAC,MAAM;IACd,IAAIO,sBAAsB,EAAE;MAC1B,MAAMuE,aAAa,GAAGrE,UAAU,GAAG,CAAC;MACpCC,aAAa,CAACoE,aAAa,CAAC;MAE5BC,KAAK,CAAC,0CAA0CD,aAAa,KAAK,CAAC;MAEnE,IAAIA,aAAa,IAAI,CAAC,EAAE;QACtBC,KAAK,CAAC,4CAA4C,CAAC;QACnDT,QAAQ,CAAC,CAAC;MACZ;IACF;EACF,CAAC,EAAE,CAAC/D,sBAAsB,EAAEE,UAAU,CAAC,CAAC;;EAExC;EACAT,SAAS,CAAC,MAAM;IACd,OAAO,MAAM;MACXsE,QAAQ,CAAC,CAAC;IACZ,CAAC;EACH,CAAC,EAAE,EAAE,CAAC;EAEN,oBACElE,OAAA;IAAK4E,KAAK,EAAE;MACVC,QAAQ,EAAE,OAAO;MACjBC,MAAM,EAAE,QAAQ;MAChBC,OAAO,EAAE,MAAM;MACfC,UAAU,EAAE,mBAAmB;MAC/BC,SAAS,EAAE;IACb,CAAE;IAAAC,QAAA,gBACAlF,OAAA;MAAI4E,KAAK,EAAE;QAAEO,KAAK,EAAE;MAAO,CAAE;MAAAD,QAAA,EAAC;IAAyB;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAE5DvF,OAAA;MAAK4E,KAAK,EAAE;QACVE,MAAM,EAAE,QAAQ;QAChBC,OAAO,EAAE,MAAM;QACfS,eAAe,EAAErF,sBAAsB,GAAG,SAAS,GAAG,SAAS;QAC/DsF,YAAY,EAAE,KAAK;QACnBC,MAAM,EAAE,aAAavF,sBAAsB,GAAG,SAAS,GAAG,SAAS;MACrE,CAAE;MAAA+E,QAAA,gBACAlF,OAAA;QAAG4E,KAAK,EAAE;UACRe,QAAQ,EAAE,MAAM;UAChBC,UAAU,EAAE,MAAM;UAClBT,KAAK,EAAEhF,sBAAsB,GAAG,SAAS,GAAG;QAC9C,CAAE;QAAA+E,QAAA,EACCzE;MAAM;QAAA2E,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACN,CAAC,eACJvF,OAAA;QAAAkF,QAAA,GAAG,iEAAa,EAACvE,WAAW,CAACkF,OAAO,CAAC,CAAC,CAAC;MAAA;QAAAT,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eAC5CvF,OAAA;QAAK4E,KAAK,EAAE;UACVkB,KAAK,EAAE,MAAM;UACbC,MAAM,EAAE,MAAM;UACdP,eAAe,EAAE,MAAM;UACvBC,YAAY,EAAE,MAAM;UACpBO,SAAS,EAAE,MAAM;UACjBC,QAAQ,EAAE;QACZ,CAAE;QAAAf,QAAA,eACAlF,OAAA;UAAK4E,KAAK,EAAE;YACVkB,KAAK,EAAE,GAAGnF,WAAW,GAAG;YACxBoF,MAAM,EAAE,MAAM;YACdP,eAAe,EAAErF,sBAAsB,GAAG,SAAS,GAAG,SAAS;YAC/D+F,UAAU,EAAE;UACd;QAAE;UAAAd,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAM;MAAC;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACN,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACH,CAAC,eAENvF,OAAA;MAAK4E,KAAK,EAAE;QAAEE,MAAM,EAAE;MAAS,CAAE;MAAAI,QAAA,eAC/BlF,OAAA;QAAG4E,KAAK,EAAE;UAAEe,QAAQ,EAAE;QAAO,CAAE;QAAAT,QAAA,GAAC,mFAAgB,eAAAlF,OAAA;UAAAkF,QAAA,EAAS7E;QAAU;UAAA+E,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAS,CAAC,MAAE;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAChF,CAAC,EAEL,CAAChF,OAAO,gBACPP,OAAA;MACEmG,OAAO,EAAEzC,SAAU;MACnBkB,KAAK,EAAE;QACLG,OAAO,EAAE,WAAW;QACpBY,QAAQ,EAAE,MAAM;QAChBH,eAAe,EAAE,SAAS;QAC1BL,KAAK,EAAE,OAAO;QACdO,MAAM,EAAE,MAAM;QACdD,YAAY,EAAE,KAAK;QACnBW,MAAM,EAAE,SAAS;QACjBF,UAAU,EAAE;MACd,CAAE;MAAAhB,QAAA,EACH;IAED;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,gBAETvF,OAAA;MACEmG,OAAO,EAAEjC,QAAS;MAClBU,KAAK,EAAE;QACLG,OAAO,EAAE,WAAW;QACpBY,QAAQ,EAAE,MAAM;QAChBH,eAAe,EAAE,SAAS;QAC1BL,KAAK,EAAE,OAAO;QACdO,MAAM,EAAE,MAAM;QACdD,YAAY,EAAE,KAAK;QACnBW,MAAM,EAAE,SAAS;QACjBF,UAAU,EAAE;MACd,CAAE;MAAAhB,QAAA,EACH;IAED;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CACT,eAEDvF,OAAA;MAAK4E,KAAK,EAAE;QACVoB,SAAS,EAAE,MAAM;QACjBjB,OAAO,EAAE,MAAM;QACfS,eAAe,EAAE,SAAS;QAC1BC,YAAY,EAAE,KAAK;QACnBR,SAAS,EAAE;MACb,CAAE;MAAAC,QAAA,gBACAlF,OAAA;QAAI4E,KAAK,EAAE;UAAEoB,SAAS,EAAE;QAAI,CAAE;QAAAd,QAAA,EAAC;MAAkB;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eACtDvF,OAAA;QAAI4E,KAAK,EAAE;UAAEyB,YAAY,EAAE;QAAO,CAAE;QAAAnB,QAAA,gBAClClF,OAAA;UAAAkF,QAAA,EAAI;QAAmD;UAAAE,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eAC5DvF,OAAA;UAAAkF,QAAA,EAAI;QAA8B;UAAAE,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eACvCvF,OAAA;UAAAkF,QAAA,EAAI;QAAmC;UAAAE,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eAC5CvF,OAAA;UAAAkF,QAAA,EAAI;QAAyC;UAAAE,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eAClDvF,OAAA;UAAAkF,QAAA,EAAI;QAAqC;UAAAE,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAC5C,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACF,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV,CAAC;AAACrF,EAAA,CApPID,cAAc;AAAAqG,EAAA,GAAdrG,cAAc;AAsPpB,eAAeA,cAAc;AAAC,IAAAqG,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}